{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cosmotech Acceleration library Acceleration library for CosmoTech cloud based solution development Code organisation In project root directory you'll find 4 main directories: CosmoTech_Acceleration_Library: containing all Cosmo Tech libraries to accelerate interaction with Cosmo Tech solutions data: a bunch of csv files on which samples are based samples: a bunch of python scripts to demonstrate how to use the library doc: for schema or specific documentation Accelerators TODO Modelops library The aim of this library is to simplify the model accesses via python code. The library can be used by Data Scientists, Modelers, Developers, ... Utility classes ModelImporter(host: str, port: int, name: str, version: int, graph_rotation:int = 1) : will allow you to bulk import data from csv files with schema enforced ( samples/Modelops/Bulk_Import_from_CSV_with_schema.py ) or not ( samples/Modelops/Bulk_Import_from_CSV_without_schema.py ) (see documentation for further details) ModelExporter(host: str, port: int, name: str, version: int, export_dir: str = '/') : will allow you to export data from a model cache instance ModelReader(host: str, port: int, name: str, version: int) : will allow you to read data from a model cache instance ( object returned ) ModelWriter(host: str, port: int, name: str, version: int, graph_rotation:int = 1) : will allow you to write data into a model instance ModelUtil : a bunch of utilities to manipulate and facilitate interaction with model instance (result_set_to_json, print_query_result, ... ) ModelMetadata : will allow you to management graph metadata How-to python setup.py install --user","title":"Home"},{"location":"#cosmotech-acceleration-library","text":"Acceleration library for CosmoTech cloud based solution development","title":"Cosmotech Acceleration library"},{"location":"#code-organisation","text":"In project root directory you'll find 4 main directories: CosmoTech_Acceleration_Library: containing all Cosmo Tech libraries to accelerate interaction with Cosmo Tech solutions data: a bunch of csv files on which samples are based samples: a bunch of python scripts to demonstrate how to use the library doc: for schema or specific documentation","title":"Code organisation"},{"location":"#accelerators","text":"TODO","title":"Accelerators"},{"location":"#modelops-library","text":"The aim of this library is to simplify the model accesses via python code. The library can be used by Data Scientists, Modelers, Developers, ...","title":"Modelops library"},{"location":"#utility-classes","text":"ModelImporter(host: str, port: int, name: str, version: int, graph_rotation:int = 1) : will allow you to bulk import data from csv files with schema enforced ( samples/Modelops/Bulk_Import_from_CSV_with_schema.py ) or not ( samples/Modelops/Bulk_Import_from_CSV_without_schema.py ) (see documentation for further details) ModelExporter(host: str, port: int, name: str, version: int, export_dir: str = '/') : will allow you to export data from a model cache instance ModelReader(host: str, port: int, name: str, version: int) : will allow you to read data from a model cache instance ( object returned ) ModelWriter(host: str, port: int, name: str, version: int, graph_rotation:int = 1) : will allow you to write data into a model instance ModelUtil : a bunch of utilities to manipulate and facilitate interaction with model instance (result_set_to_json, print_query_result, ... ) ModelMetadata : will allow you to management graph metadata","title":"Utility classes"},{"location":"#how-to","text":"python setup.py install --user","title":"How-to"},{"location":"dependencies/","text":"List of dependencies Azure connection requirements Modelops requirements Cosmotech specific requirements Other requirements Documentation generation","title":"Dependencies"},{"location":"dependencies/#list-of-dependencies","text":"Azure connection requirements Modelops requirements Cosmotech specific requirements Other requirements Documentation generation","title":"List of dependencies"},{"location":"references/SUMMARY/","text":"References Modelops core common graph_handler redis_handler writer CsvWriter decorators model_decorators io model_importer model_reader model_exporter model_writer model_metadata utils model_util tests model_util_test Accelerators adx_wrapper cosmo_api csm_engine scenario_download azure_function_main scenario_downloader utils multi_environment","title":"SUMMARY"},{"location":"references/Accelerators/adx_wrapper/","text":"CosmoTech_Acceleration_Library.Accelerators.adx_wrapper ADXQueriesWrapper Wrapping class to ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 class ADXQueriesWrapper : \"\"\" Wrapping class to ADX \"\"\" def __init__ ( self , database : str , cluster_url : Union [ str , None ] = None , ingest_url : Union [ str , None ] = None , cluster_name : Union [ str , None ] = None , cluster_region : Union [ str , None ] = None ): if cluster_name and cluster_region : cluster_url = f \"https:// { cluster_name } . { cluster_region } .kusto.windows.net\" ingest_url = f \"https://ingest- { cluster_name } . { cluster_region } .kusto.windows.net\" try : az_client_id = os . environ [ 'AZURE_CLIENT_ID' ] az_client_secret = os . environ [ 'AZURE_CLIENT_SECRET' ] az_tenant_id = os . environ [ 'AZURE_TENANT_ID' ] self . cluster_kcsb = KustoConnectionStringBuilder . with_aad_application_key_authentication ( cluster_url , az_client_id , az_client_secret , az_tenant_id ) self . ingest_kcsb = KustoConnectionStringBuilder . with_aad_application_key_authentication ( ingest_url , az_client_id , az_client_secret , az_tenant_id ) except KeyError : self . cluster_kcsb = KustoConnectionStringBuilder . with_az_cli_authentication ( cluster_url ) self . ingest_kcsb = KustoConnectionStringBuilder . with_az_cli_authentication ( ingest_url ) self . kusto_client = KustoClient ( self . cluster_kcsb ) self . ingest_client = QueuedIngestClient ( self . ingest_kcsb ) self . database = database self . timeout = 900 self . ingest_status = dict () self . ingest_times = dict () @staticmethod def type_mapping ( key : str , key_example_value ) -> str : \"\"\" This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX \"\"\" if key == \"SimulationRun\" : return \"guid\" try : # Use dateutil parser to test if the value could be a date, in case of error it is not dateutil . parser . parse ( key_example_value , fuzzy = False ) return \"datetime\" except ( ValueError , TypeError ): pass if type ( key_example_value ) is float : return \"real\" if type ( key_example_value ) is int : return \"long\" # Default case to string return \"string\" def send_to_adx ( self , dict_list : list , table_name : str , ignore_table_creation : bool = True , drop_by_tag : str = None ): \"\"\" Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX \"\"\" if not ignore_table_creation : # If the target table does not exist create it # First create the columns types needed for the table types = { k : self . type_mapping ( k , dict_list [ 0 ][ k ]) for k in dict_list [ 0 ] . keys ()} # Then try to create the table if not self . create_table ( table_name , types ): print ( f \"Error creating table { table_name } .\" ) return False # Create a dataframe with the data to write and send them to ADX df = pd . DataFrame ( dict_list ) ingestion_result = self . ingest_dataframe ( table_name , df , drop_by_tag ) return ingestion_result def ingest_dataframe ( self , table_name : str , dataframe : pd . DataFrame , drop_by_tag : str = None ): \"\"\" Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None \"\"\" drop_by_tags = [ drop_by_tag ] if ( drop_by_tag is not None ) else None properties = IngestionProperties ( database = self . database , table = table_name , data_format = DataFormat . CSV , drop_by_tags = drop_by_tags , report_level = ReportLevel . FailuresAndSuccesses ) client = self . ingest_client ingestion_result = client . ingest_from_dataframe ( dataframe , ingestion_properties = properties ) self . ingest_status [ str ( ingestion_result . source_id )] = IngestionStatus . QUEUED self . ingest_times [ str ( ingestion_result . source_id )] = time . time () return ingestion_result def check_ingestion_status ( self , source_ids : list [ str ], timeout : int = None , logs : bool = False ) -> Iterator [ tuple [ str , IngestionStatus ]]: remaining_ids = [] for source_id in source_ids : if source_id not in self . ingest_status : self . ingest_status [ source_id ] = IngestionStatus . UNKNOWN self . ingest_times [ source_id ] = time . time () if self . ingest_status [ source_id ] not in [ IngestionStatus . QUEUED , IngestionStatus . UNKNOWN ]: yield source_id , self . ingest_status [ source_id ] else : remaining_ids . append ( source_id ) qs = KustoIngestStatusQueues ( self . ingest_client ) def get_messages ( queues ): _r = [] for q in queues : _r . extend ((( q , m ) for m in q . receive_messages ( messages_per_page = 32 , visibility_timeout = 1 ))) return _r successes = get_messages ( qs . success . _get_queues ()) failures = get_messages ( qs . failure . _get_queues ()) if logs : print ( f \"Success messages: { len ( successes ) } \" ) print ( f \"Failure messages: { len ( failures ) } \" ) non_sent_ids = remaining_ids [:] for messages , cast_func , status in [( successes , SuccessMessage , IngestionStatus . SUCCESS ), ( failures , FailureMessage , IngestionStatus . FAILURE )]: for _q , _m in messages : dm = cast_func ( _m . content ) to_check_ids = remaining_ids [:] for source_id in to_check_ids : if dm . IngestionSourceId == str ( source_id ): self . ingest_status [ source_id ] = status if logs : print ( f \"Found status for { source_id } : { status . value } \" ) _q . delete_message ( _m ) remaining_ids . remove ( source_id ) break else : # The message did not correspond to a known ID continue break else : # No message was found on the current list of messages for the given IDs continue break else : for source_id in remaining_ids : if time . time () - self . ingest_times [ source_id ] > ([ timeout , self . timeout ][ timeout is None ]): self . ingest_status [ source_id ] = IngestionStatus . TIMEOUT for source_id in non_sent_ids : yield source_id , self . ingest_status [ source_id ] def _clear_ingestion_status_queues ( self , confirmation : bool = False ): \"\"\" Dangerous operation that will fully clear all data in the ingestion status queues Those queues are common to all databases in the ADX Cluster so don't ut this unless you know what you are doing :param confirmation: Unless confirmation is set to True, won't do anything :return: \"\"\" if confirmation : qs = KustoIngestStatusQueues ( self . ingest_client ) while not qs . success . is_empty (): qs . success . pop ( 32 ) while not qs . failure . is_empty (): qs . failure . pop ( 32 ) def run_command_query ( self , query : str ): \"\"\" Execute a command query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute_mgmt ( self . database , query ) def run_query ( self , query : str ): \"\"\" Execute a simple query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute ( self . database , query ) def table_exists ( self , table_name : str ) -> bool : \"\"\" Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? \"\"\" get_tables_query = f \".show database [' { self . database } '] schema| distinct TableName\" tables = self . run_query ( get_tables_query ) for r in tables . primary_results [ 0 ]: if table_name == r [ 0 ]: return True return False def create_table ( self , table_name : str , schema : dict ) -> bool : \"\"\" Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? \"\"\" create_query = f \".create-merge table { table_name } (\" for column_name , column_type in schema . items (): create_query += f \" { column_name } : { column_type } ,\" create_query = create_query [: - 1 ] + \")\" try : self . run_query ( create_query ) except Exception as e : print ( e ) return False return True create_table ( table_name , schema ) Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def create_table ( self , table_name : str , schema : dict ) -> bool : \"\"\" Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? \"\"\" create_query = f \".create-merge table { table_name } (\" for column_name , column_type in schema . items (): create_query += f \" { column_name } : { column_type } ,\" create_query = create_query [: - 1 ] + \")\" try : self . run_query ( create_query ) except Exception as e : print ( e ) return False return True ingest_dataframe ( table_name , dataframe , drop_by_tag = None ) Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def ingest_dataframe ( self , table_name : str , dataframe : pd . DataFrame , drop_by_tag : str = None ): \"\"\" Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None \"\"\" drop_by_tags = [ drop_by_tag ] if ( drop_by_tag is not None ) else None properties = IngestionProperties ( database = self . database , table = table_name , data_format = DataFormat . CSV , drop_by_tags = drop_by_tags , report_level = ReportLevel . FailuresAndSuccesses ) client = self . ingest_client ingestion_result = client . ingest_from_dataframe ( dataframe , ingestion_properties = properties ) self . ingest_status [ str ( ingestion_result . source_id )] = IngestionStatus . QUEUED self . ingest_times [ str ( ingestion_result . source_id )] = time . time () return ingestion_result run_command_query ( query ) Execute a command query on the database :param query: the query to execute :return: the results of the query Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 205 206 207 208 209 210 211 212 def run_command_query ( self , query : str ): \"\"\" Execute a command query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute_mgmt ( self . database , query ) run_query ( query ) Execute a simple query on the database :param query: the query to execute :return: the results of the query Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 214 215 216 217 218 219 220 221 def run_query ( self , query : str ): \"\"\" Execute a simple query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute ( self . database , query ) send_to_adx ( dict_list , table_name , ignore_table_creation = True , drop_by_tag = None ) Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_to_adx ( self , dict_list : list , table_name : str , ignore_table_creation : bool = True , drop_by_tag : str = None ): \"\"\" Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX \"\"\" if not ignore_table_creation : # If the target table does not exist create it # First create the columns types needed for the table types = { k : self . type_mapping ( k , dict_list [ 0 ][ k ]) for k in dict_list [ 0 ] . keys ()} # Then try to create the table if not self . create_table ( table_name , types ): print ( f \"Error creating table { table_name } .\" ) return False # Create a dataframe with the data to write and send them to ADX df = pd . DataFrame ( dict_list ) ingestion_result = self . ingest_dataframe ( table_name , df , drop_by_tag ) return ingestion_result table_exists ( table_name ) Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 223 224 225 226 227 228 229 230 231 232 233 234 def table_exists ( self , table_name : str ) -> bool : \"\"\" Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? \"\"\" get_tables_query = f \".show database [' { self . database } '] schema| distinct TableName\" tables = self . run_query ( get_tables_query ) for r in tables . primary_results [ 0 ]: if table_name == r [ 0 ]: return True return False type_mapping ( key , key_example_value ) staticmethod This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @staticmethod def type_mapping ( key : str , key_example_value ) -> str : \"\"\" This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX \"\"\" if key == \"SimulationRun\" : return \"guid\" try : # Use dateutil parser to test if the value could be a date, in case of error it is not dateutil . parser . parse ( key_example_value , fuzzy = False ) return \"datetime\" except ( ValueError , TypeError ): pass if type ( key_example_value ) is float : return \"real\" if type ( key_example_value ) is int : return \"long\" # Default case to string return \"string\" IngestionStatus Bases: Enum Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 16 17 18 19 20 21 class IngestionStatus ( Enum ): QUEUED = 'QUEUED' SUCCESS = 'SUCCESS' FAILURE = 'FAILURE' UNKNOWN = 'UNKNOWN' TIMEOUT = 'TIMED OUT'","title":"adx_wrapper"},{"location":"references/Accelerators/adx_wrapper/#cosmotech_acceleration_libraryacceleratorsadx_wrapper","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.adx_wrapper"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper","text":"Wrapping class to ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 class ADXQueriesWrapper : \"\"\" Wrapping class to ADX \"\"\" def __init__ ( self , database : str , cluster_url : Union [ str , None ] = None , ingest_url : Union [ str , None ] = None , cluster_name : Union [ str , None ] = None , cluster_region : Union [ str , None ] = None ): if cluster_name and cluster_region : cluster_url = f \"https:// { cluster_name } . { cluster_region } .kusto.windows.net\" ingest_url = f \"https://ingest- { cluster_name } . { cluster_region } .kusto.windows.net\" try : az_client_id = os . environ [ 'AZURE_CLIENT_ID' ] az_client_secret = os . environ [ 'AZURE_CLIENT_SECRET' ] az_tenant_id = os . environ [ 'AZURE_TENANT_ID' ] self . cluster_kcsb = KustoConnectionStringBuilder . with_aad_application_key_authentication ( cluster_url , az_client_id , az_client_secret , az_tenant_id ) self . ingest_kcsb = KustoConnectionStringBuilder . with_aad_application_key_authentication ( ingest_url , az_client_id , az_client_secret , az_tenant_id ) except KeyError : self . cluster_kcsb = KustoConnectionStringBuilder . with_az_cli_authentication ( cluster_url ) self . ingest_kcsb = KustoConnectionStringBuilder . with_az_cli_authentication ( ingest_url ) self . kusto_client = KustoClient ( self . cluster_kcsb ) self . ingest_client = QueuedIngestClient ( self . ingest_kcsb ) self . database = database self . timeout = 900 self . ingest_status = dict () self . ingest_times = dict () @staticmethod def type_mapping ( key : str , key_example_value ) -> str : \"\"\" This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX \"\"\" if key == \"SimulationRun\" : return \"guid\" try : # Use dateutil parser to test if the value could be a date, in case of error it is not dateutil . parser . parse ( key_example_value , fuzzy = False ) return \"datetime\" except ( ValueError , TypeError ): pass if type ( key_example_value ) is float : return \"real\" if type ( key_example_value ) is int : return \"long\" # Default case to string return \"string\" def send_to_adx ( self , dict_list : list , table_name : str , ignore_table_creation : bool = True , drop_by_tag : str = None ): \"\"\" Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX \"\"\" if not ignore_table_creation : # If the target table does not exist create it # First create the columns types needed for the table types = { k : self . type_mapping ( k , dict_list [ 0 ][ k ]) for k in dict_list [ 0 ] . keys ()} # Then try to create the table if not self . create_table ( table_name , types ): print ( f \"Error creating table { table_name } .\" ) return False # Create a dataframe with the data to write and send them to ADX df = pd . DataFrame ( dict_list ) ingestion_result = self . ingest_dataframe ( table_name , df , drop_by_tag ) return ingestion_result def ingest_dataframe ( self , table_name : str , dataframe : pd . DataFrame , drop_by_tag : str = None ): \"\"\" Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None \"\"\" drop_by_tags = [ drop_by_tag ] if ( drop_by_tag is not None ) else None properties = IngestionProperties ( database = self . database , table = table_name , data_format = DataFormat . CSV , drop_by_tags = drop_by_tags , report_level = ReportLevel . FailuresAndSuccesses ) client = self . ingest_client ingestion_result = client . ingest_from_dataframe ( dataframe , ingestion_properties = properties ) self . ingest_status [ str ( ingestion_result . source_id )] = IngestionStatus . QUEUED self . ingest_times [ str ( ingestion_result . source_id )] = time . time () return ingestion_result def check_ingestion_status ( self , source_ids : list [ str ], timeout : int = None , logs : bool = False ) -> Iterator [ tuple [ str , IngestionStatus ]]: remaining_ids = [] for source_id in source_ids : if source_id not in self . ingest_status : self . ingest_status [ source_id ] = IngestionStatus . UNKNOWN self . ingest_times [ source_id ] = time . time () if self . ingest_status [ source_id ] not in [ IngestionStatus . QUEUED , IngestionStatus . UNKNOWN ]: yield source_id , self . ingest_status [ source_id ] else : remaining_ids . append ( source_id ) qs = KustoIngestStatusQueues ( self . ingest_client ) def get_messages ( queues ): _r = [] for q in queues : _r . extend ((( q , m ) for m in q . receive_messages ( messages_per_page = 32 , visibility_timeout = 1 ))) return _r successes = get_messages ( qs . success . _get_queues ()) failures = get_messages ( qs . failure . _get_queues ()) if logs : print ( f \"Success messages: { len ( successes ) } \" ) print ( f \"Failure messages: { len ( failures ) } \" ) non_sent_ids = remaining_ids [:] for messages , cast_func , status in [( successes , SuccessMessage , IngestionStatus . SUCCESS ), ( failures , FailureMessage , IngestionStatus . FAILURE )]: for _q , _m in messages : dm = cast_func ( _m . content ) to_check_ids = remaining_ids [:] for source_id in to_check_ids : if dm . IngestionSourceId == str ( source_id ): self . ingest_status [ source_id ] = status if logs : print ( f \"Found status for { source_id } : { status . value } \" ) _q . delete_message ( _m ) remaining_ids . remove ( source_id ) break else : # The message did not correspond to a known ID continue break else : # No message was found on the current list of messages for the given IDs continue break else : for source_id in remaining_ids : if time . time () - self . ingest_times [ source_id ] > ([ timeout , self . timeout ][ timeout is None ]): self . ingest_status [ source_id ] = IngestionStatus . TIMEOUT for source_id in non_sent_ids : yield source_id , self . ingest_status [ source_id ] def _clear_ingestion_status_queues ( self , confirmation : bool = False ): \"\"\" Dangerous operation that will fully clear all data in the ingestion status queues Those queues are common to all databases in the ADX Cluster so don't ut this unless you know what you are doing :param confirmation: Unless confirmation is set to True, won't do anything :return: \"\"\" if confirmation : qs = KustoIngestStatusQueues ( self . ingest_client ) while not qs . success . is_empty (): qs . success . pop ( 32 ) while not qs . failure . is_empty (): qs . failure . pop ( 32 ) def run_command_query ( self , query : str ): \"\"\" Execute a command query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute_mgmt ( self . database , query ) def run_query ( self , query : str ): \"\"\" Execute a simple query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute ( self . database , query ) def table_exists ( self , table_name : str ) -> bool : \"\"\" Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? \"\"\" get_tables_query = f \".show database [' { self . database } '] schema| distinct TableName\" tables = self . run_query ( get_tables_query ) for r in tables . primary_results [ 0 ]: if table_name == r [ 0 ]: return True return False def create_table ( self , table_name : str , schema : dict ) -> bool : \"\"\" Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? \"\"\" create_query = f \".create-merge table { table_name } (\" for column_name , column_type in schema . items (): create_query += f \" { column_name } : { column_type } ,\" create_query = create_query [: - 1 ] + \")\" try : self . run_query ( create_query ) except Exception as e : print ( e ) return False return True","title":"ADXQueriesWrapper"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.create_table","text":"Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def create_table ( self , table_name : str , schema : dict ) -> bool : \"\"\" Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ? \"\"\" create_query = f \".create-merge table { table_name } (\" for column_name , column_type in schema . items (): create_query += f \" { column_name } : { column_type } ,\" create_query = create_query [: - 1 ] + \")\" try : self . run_query ( create_query ) except Exception as e : print ( e ) return False return True","title":"create_table()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.ingest_dataframe","text":"Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def ingest_dataframe ( self , table_name : str , dataframe : pd . DataFrame , drop_by_tag : str = None ): \"\"\" Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None \"\"\" drop_by_tags = [ drop_by_tag ] if ( drop_by_tag is not None ) else None properties = IngestionProperties ( database = self . database , table = table_name , data_format = DataFormat . CSV , drop_by_tags = drop_by_tags , report_level = ReportLevel . FailuresAndSuccesses ) client = self . ingest_client ingestion_result = client . ingest_from_dataframe ( dataframe , ingestion_properties = properties ) self . ingest_status [ str ( ingestion_result . source_id )] = IngestionStatus . QUEUED self . ingest_times [ str ( ingestion_result . source_id )] = time . time () return ingestion_result","title":"ingest_dataframe()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_command_query","text":"Execute a command query on the database :param query: the query to execute :return: the results of the query Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 205 206 207 208 209 210 211 212 def run_command_query ( self , query : str ): \"\"\" Execute a command query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute_mgmt ( self . database , query )","title":"run_command_query()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_query","text":"Execute a simple query on the database :param query: the query to execute :return: the results of the query Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 214 215 216 217 218 219 220 221 def run_query ( self , query : str ): \"\"\" Execute a simple query on the database :param query: the query to execute :return: the results of the query \"\"\" client = self . kusto_client return client . execute ( self . database , query )","title":"run_query()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.send_to_adx","text":"Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def send_to_adx ( self , dict_list : list , table_name : str , ignore_table_creation : bool = True , drop_by_tag : str = None ): \"\"\" Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX \"\"\" if not ignore_table_creation : # If the target table does not exist create it # First create the columns types needed for the table types = { k : self . type_mapping ( k , dict_list [ 0 ][ k ]) for k in dict_list [ 0 ] . keys ()} # Then try to create the table if not self . create_table ( table_name , types ): print ( f \"Error creating table { table_name } .\" ) return False # Create a dataframe with the data to write and send them to ADX df = pd . DataFrame ( dict_list ) ingestion_result = self . ingest_dataframe ( table_name , df , drop_by_tag ) return ingestion_result","title":"send_to_adx()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.table_exists","text":"Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 223 224 225 226 227 228 229 230 231 232 233 234 def table_exists ( self , table_name : str ) -> bool : \"\"\" Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ? \"\"\" get_tables_query = f \".show database [' { self . database } '] schema| distinct TableName\" tables = self . run_query ( get_tables_query ) for r in tables . primary_results [ 0 ]: if table_name == r [ 0 ]: return True return False","title":"table_exists()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.type_mapping","text":"This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 @staticmethod def type_mapping ( key : str , key_example_value ) -> str : \"\"\" This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX \"\"\" if key == \"SimulationRun\" : return \"guid\" try : # Use dateutil parser to test if the value could be a date, in case of error it is not dateutil . parser . parse ( key_example_value , fuzzy = False ) return \"datetime\" except ( ValueError , TypeError ): pass if type ( key_example_value ) is float : return \"real\" if type ( key_example_value ) is int : return \"long\" # Default case to string return \"string\"","title":"type_mapping()"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.IngestionStatus","text":"Bases: Enum Source code in CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py 16 17 18 19 20 21 class IngestionStatus ( Enum ): QUEUED = 'QUEUED' SUCCESS = 'SUCCESS' FAILURE = 'FAILURE' UNKNOWN = 'UNKNOWN' TIMEOUT = 'TIMED OUT'","title":"IngestionStatus"},{"location":"references/Accelerators/cosmo_api/","text":"CosmoTech_Acceleration_Library.Accelerators.cosmo_api cosmo_api get_current_scenario_data () Uses environment vars to find the current scenario data from the cosmotech api :return: a dict containing the data of the scenario from the API or None in another context Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def get_current_scenario_data (): \"\"\" Uses environment vars to find the current scenario data from the cosmotech api :return: a dict containing the data of the scenario from the API or None in another context \"\"\" organization_id = os . environ . get ( \"CSM_ORGANIZATION_ID\" ) workspace_id = os . environ . get ( \"CSM_WORKSPACE_ID\" ) scenario_id = os . environ . get ( \"CSM_SCENARIO_ID\" ) if not all ([ organization_id , workspace_id , scenario_id ]): return None with cosmotech_api . ApiClient ( __get_configuration ()) as api_client : api_instance = ScenarioApi ( api_client ) scenario_data = api_instance . find_scenario_by_id ( organization_id = organization_id , workspace_id = workspace_id , scenario_id = scenario_id ) return scenario_data send_dataframe_to_api ( dataframe , file_name ) Send a dataframe to the API Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 45 46 47 48 49 50 51 def send_dataframe_to_api ( dataframe , file_name : str ): \"\"\"Send a dataframe to the API\"\"\" file_content = io . StringIO () dataframe . to_csv ( file_content , index = False ) file_content . seek ( 0 ) file_content . name = file_name . split ( '/' )[ - 1 ] send_file_to_api ( file_content , file_name ) send_file_to_api ( file_content , file_name ) Send a file to the api Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 31 32 33 34 35 36 37 38 39 40 41 42 def send_file_to_api ( file_content , file_name : str ): \"\"\"Send a file to the api\"\"\" organization_id = os . environ . get ( \"CSM_ORGANIZATION_ID\" ) workspace_id = os . environ . get ( \"CSM_WORKSPACE_ID\" ) with cosmotech_api . ApiClient ( __get_configuration ()) as api_client : api_ws = WorkspaceApi ( api_client ) api_ws . upload_workspace_file ( organization_id = organization_id , workspace_id = workspace_id , file = file_content , overwrite = True , destination = file_name )","title":"cosmo_api"},{"location":"references/Accelerators/cosmo_api/#cosmotech_acceleration_libraryacceleratorscosmo_api","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.cosmo_api"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api","text":"","title":"cosmo_api"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.get_current_scenario_data","text":"Uses environment vars to find the current scenario data from the cosmotech api :return: a dict containing the data of the scenario from the API or None in another context Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def get_current_scenario_data (): \"\"\" Uses environment vars to find the current scenario data from the cosmotech api :return: a dict containing the data of the scenario from the API or None in another context \"\"\" organization_id = os . environ . get ( \"CSM_ORGANIZATION_ID\" ) workspace_id = os . environ . get ( \"CSM_WORKSPACE_ID\" ) scenario_id = os . environ . get ( \"CSM_SCENARIO_ID\" ) if not all ([ organization_id , workspace_id , scenario_id ]): return None with cosmotech_api . ApiClient ( __get_configuration ()) as api_client : api_instance = ScenarioApi ( api_client ) scenario_data = api_instance . find_scenario_by_id ( organization_id = organization_id , workspace_id = workspace_id , scenario_id = scenario_id ) return scenario_data","title":"get_current_scenario_data()"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.send_dataframe_to_api","text":"Send a dataframe to the API Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 45 46 47 48 49 50 51 def send_dataframe_to_api ( dataframe , file_name : str ): \"\"\"Send a dataframe to the API\"\"\" file_content = io . StringIO () dataframe . to_csv ( file_content , index = False ) file_content . seek ( 0 ) file_content . name = file_name . split ( '/' )[ - 1 ] send_file_to_api ( file_content , file_name )","title":"send_dataframe_to_api()"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.send_file_to_api","text":"Send a file to the api Source code in CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py 31 32 33 34 35 36 37 38 39 40 41 42 def send_file_to_api ( file_content , file_name : str ): \"\"\"Send a file to the api\"\"\" organization_id = os . environ . get ( \"CSM_ORGANIZATION_ID\" ) workspace_id = os . environ . get ( \"CSM_WORKSPACE_ID\" ) with cosmotech_api . ApiClient ( __get_configuration ()) as api_client : api_ws = WorkspaceApi ( api_client ) api_ws . upload_workspace_file ( organization_id = organization_id , workspace_id = workspace_id , file = file_content , overwrite = True , destination = file_name )","title":"send_file_to_api()"},{"location":"references/Accelerators/csm_engine/","text":"CosmoTech_Acceleration_Library.Accelerators.csm_engine csm_engine apply_simple_csv_parameter_to_simulator ( simulator , parameter_name , target_attribute_name , csv_id_column = 'id' , csv_value_column = 'value' ) Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None Source code in CosmoTech_Acceleration_Library/Accelerators/csm_engine.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def apply_simple_csv_parameter_to_simulator ( simulator , parameter_name : str , target_attribute_name : str , csv_id_column : str = \"id\" , csv_value_column : str = \"value\" ): \"\"\" Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None \"\"\" parameter_path = os . path . join ( parametersPath , parameter_name ) if os . path . exists ( parameter_path ): csv_files = glob . glob ( os . path . join ( parameter_path , \"*.csv\" )) for csv_filename in csv_files : model = simulator . GetModel () with open ( csv_filename , \"r\" ) as csv_file : for row in csv . DictReader ( csv_file ): entity_name = row . get ( csv_id_column ) value = json . loads ( row . get ( csv_value_column )) entity = model . FindEntityByName ( entity_name ) if entity : entity . SetAttributeAsString ( target_attribute_name , json . dumps ( value )) else : raise ValueError ( f \"Parameter { parameter_name } does not exists.\" )","title":"csm_engine"},{"location":"references/Accelerators/csm_engine/#cosmotech_acceleration_libraryacceleratorscsm_engine","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.csm_engine"},{"location":"references/Accelerators/csm_engine/#CosmoTech_Acceleration_Library.Accelerators.csm_engine","text":"","title":"csm_engine"},{"location":"references/Accelerators/csm_engine/#CosmoTech_Acceleration_Library.Accelerators.csm_engine.apply_simple_csv_parameter_to_simulator","text":"Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None Source code in CosmoTech_Acceleration_Library/Accelerators/csm_engine.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def apply_simple_csv_parameter_to_simulator ( simulator , parameter_name : str , target_attribute_name : str , csv_id_column : str = \"id\" , csv_value_column : str = \"value\" ): \"\"\" Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None \"\"\" parameter_path = os . path . join ( parametersPath , parameter_name ) if os . path . exists ( parameter_path ): csv_files = glob . glob ( os . path . join ( parameter_path , \"*.csv\" )) for csv_filename in csv_files : model = simulator . GetModel () with open ( csv_filename , \"r\" ) as csv_file : for row in csv . DictReader ( csv_file ): entity_name = row . get ( csv_id_column ) value = json . loads ( row . get ( csv_value_column )) entity = model . FindEntityByName ( entity_name ) if entity : entity . SetAttributeAsString ( target_attribute_name , json . dumps ( value )) else : raise ValueError ( f \"Parameter { parameter_name } does not exists.\" )","title":"apply_simple_csv_parameter_to_simulator()"},{"location":"references/Accelerators/scenario_download/azure_function_main/","text":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main azure_function_main","title":"azure_function_main"},{"location":"references/Accelerators/scenario_download/azure_function_main/#cosmotech_acceleration_libraryacceleratorsscenario_downloadazure_function_main","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main"},{"location":"references/Accelerators/scenario_download/azure_function_main/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main","text":"","title":"azure_function_main"},{"location":"references/Accelerators/scenario_download/scenario_downloader/","text":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader ScenarioDownloader Source code in CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 class ScenarioDownloader : def __init__ ( self , workspace_id : str , organization_id : str ): self . credentials = DefaultAzureCredential () scope = env . api_scope token = self . credentials . get_token ( scope ) self . configuration = cosmotech_api . Configuration ( host = env . api_host , discard_unknown_keys = True , access_token = token . token ) self . workspace_id = workspace_id self . organization_id = organization_id def get_scenario_data ( self , scenario_id : str ): with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_instance = ScenarioApi ( api_client ) scenario_data = api_instance . find_scenario_by_id ( organization_id = self . organization_id , workspace_id = self . workspace_id , scenario_id = scenario_id ) return scenario_data def download_dataset ( self , dataset_id : str ) -> ( str , str , Union [ str , None ]): with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_instance = DatasetApi ( api_client ) dataset = api_instance . find_dataset_by_id ( organization_id = self . organization_id , dataset_id = dataset_id ) is_adt = 'AZURE_DIGITAL_TWINS_URL' in dataset [ 'connector' ][ 'parameters_values' ] if is_adt : return { \"type\" : 'adt' , \"content\" : self . _download_adt_content ( adt_adress = dataset [ 'connector' ][ 'parameters_values' ][ 'AZURE_DIGITAL_TWINS_URL' ]), \"name\" : dataset [ 'name' ]} else : _file_name = dataset [ 'connector' ][ 'parameters_values' ][ 'AZURE_STORAGE_CONTAINER_BLOB_PREFIX' ] . replace ( '%WORKSPACE_FILE%/' , '' ) return { \"type\" : _file_name . split ( '.' )[ - 1 ], \"content\" : self . _download_file ( _file_name ), \"name\" : dataset [ 'name' ]} def _download_file ( self , file_name : str ): tmp_dataset_dir = tempfile . mkdtemp () with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_ws = WorkspaceApi ( api_client ) all_api_files = api_ws . find_all_workspace_files ( self . organization_id , self . workspace_id ) existing_files = list ( _f . to_dict () . get ( 'file_name' ) for _f in all_api_files if _f . to_dict () . get ( 'file_name' , '' ) . startswith ( file_name )) content = dict () for _file_name in existing_files : dl_file = api_ws . download_workspace_file ( organization_id = self . organization_id , workspace_id = self . workspace_id , file_name = _file_name ) target_file = os . path . join ( tmp_dataset_dir , _file_name . split ( '/' )[ - 1 ]) with open ( target_file , \"wb\" ) as tmp_file : tmp_file . write ( dl_file . read ()) if \".xls\" in _file_name : wb = load_workbook ( target_file , data_only = True ) for sheet_name in wb . sheetnames : sheet = wb [ sheet_name ] content [ sheet_name ] = list () headers = next ( sheet . iter_rows ( max_row = 1 , values_only = True )) def item ( _row : tuple ) -> dict : return { k : v for k , v in zip ( headers , _row )} for r in sheet . iter_rows ( min_row = 2 , values_only = True ): row = item ( r ) new_row = dict () for key , value in row . items (): try : converted_value = json . load ( io . StringIO ( value )) except ( json . decoder . JSONDecodeError , TypeError ): converted_value = value if converted_value is not None : new_row [ key ] = converted_value if new_row : content [ sheet_name ] . append ( new_row ) elif \".csv\" in _file_name : with open ( target_file , \"r\" ) as file : # Read every file in the input folder current_filename = os . path . basename ( target_file )[: - len ( \".csv\" )] content [ current_filename ] = list () for row in csv . DictReader ( file ): new_row = dict () for key , value in row . items (): try : # Try to convert any json row to dict object converted_value = json . load ( io . StringIO ( value )) except json . decoder . JSONDecodeError : converted_value = value if converted_value == '' : converted_value = None if converted_value is not None : new_row [ key ] = converted_value content [ current_filename ] . append ( new_row ) elif \".json\" in _file_name : with open ( target_file , \"r\" ) as _file : current_filename = os . path . basename ( target_file ) content [ current_filename ] = json . load ( _file ) else : with open ( target_file , \"r\" ) as _file : current_filename = os . path . basename ( target_file ) content [ current_filename ] = \" \\n \" . join ( line for line in _file ) return content def _download_adt_content ( self , adt_adress : str ) -> dict : client = DigitalTwinsClient ( adt_adress , self . credentials ) query_expression = 'SELECT * FROM digitaltwins' query_result = client . query_twins ( query_expression ) json_content = dict () for twin in query_result : entity_type = twin . get ( '$metadata' ) . get ( '$model' ) . split ( ':' )[ - 1 ] . split ( ';' )[ 0 ] t_content = { k : v for k , v in twin . items ()} t_content [ 'id' ] = t_content [ '$dtId' ] for k in twin . keys (): if k [ 0 ] == '$' : del t_content [ k ] json_content . setdefault ( entity_type , []) json_content [ entity_type ] . append ( t_content ) relations_query = 'SELECT * FROM relationships' query_result = client . query_twins ( relations_query ) for relation in query_result : tr = { \"$relationshipId\" : \"id\" , \"$sourceId\" : \"source\" , \"$targetId\" : \"target\" } r_content = { k : v for k , v in relation . items ()} for k , v in tr . items (): r_content [ v ] = r_content [ k ] for k in relation . keys (): if k [ 0 ] == '$' : del r_content [ k ] json_content . setdefault ( relation [ '$relationshipName' ], []) json_content [ relation [ '$relationshipName' ]] . append ( r_content ) return json_content def get_all_parameters ( self , scenario_id ) -> dict : scenario_data = self . get_scenario_data ( scenario_id = scenario_id ) content = dict () for parameter in scenario_data [ 'parameters_values' ]: content [ parameter [ 'parameter_id' ]] = parameter [ 'value' ] return content def get_all_datasets ( self , scenario_id : str ) -> dict : scenario_data = self . get_scenario_data ( scenario_id = scenario_id ) datasets = scenario_data [ 'dataset_list' ] content = dict () for dataset_id in datasets : content [ dataset_id ] = self . download_dataset ( dataset_id ) for parameter in scenario_data [ 'parameters_values' ]: if parameter [ 'var_type' ] == '%DATASETID%' : dataset_id = parameter [ 'value' ] content [ dataset_id ] = self . download_dataset ( dataset_id ) return content","title":"scenario_downloader"},{"location":"references/Accelerators/scenario_download/scenario_downloader/#cosmotech_acceleration_libraryacceleratorsscenario_downloadscenario_downloader","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader"},{"location":"references/Accelerators/scenario_download/scenario_downloader/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader.ScenarioDownloader","text":"Source code in CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 class ScenarioDownloader : def __init__ ( self , workspace_id : str , organization_id : str ): self . credentials = DefaultAzureCredential () scope = env . api_scope token = self . credentials . get_token ( scope ) self . configuration = cosmotech_api . Configuration ( host = env . api_host , discard_unknown_keys = True , access_token = token . token ) self . workspace_id = workspace_id self . organization_id = organization_id def get_scenario_data ( self , scenario_id : str ): with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_instance = ScenarioApi ( api_client ) scenario_data = api_instance . find_scenario_by_id ( organization_id = self . organization_id , workspace_id = self . workspace_id , scenario_id = scenario_id ) return scenario_data def download_dataset ( self , dataset_id : str ) -> ( str , str , Union [ str , None ]): with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_instance = DatasetApi ( api_client ) dataset = api_instance . find_dataset_by_id ( organization_id = self . organization_id , dataset_id = dataset_id ) is_adt = 'AZURE_DIGITAL_TWINS_URL' in dataset [ 'connector' ][ 'parameters_values' ] if is_adt : return { \"type\" : 'adt' , \"content\" : self . _download_adt_content ( adt_adress = dataset [ 'connector' ][ 'parameters_values' ][ 'AZURE_DIGITAL_TWINS_URL' ]), \"name\" : dataset [ 'name' ]} else : _file_name = dataset [ 'connector' ][ 'parameters_values' ][ 'AZURE_STORAGE_CONTAINER_BLOB_PREFIX' ] . replace ( '%WORKSPACE_FILE%/' , '' ) return { \"type\" : _file_name . split ( '.' )[ - 1 ], \"content\" : self . _download_file ( _file_name ), \"name\" : dataset [ 'name' ]} def _download_file ( self , file_name : str ): tmp_dataset_dir = tempfile . mkdtemp () with cosmotech_api . ApiClient ( self . configuration ) as api_client : api_ws = WorkspaceApi ( api_client ) all_api_files = api_ws . find_all_workspace_files ( self . organization_id , self . workspace_id ) existing_files = list ( _f . to_dict () . get ( 'file_name' ) for _f in all_api_files if _f . to_dict () . get ( 'file_name' , '' ) . startswith ( file_name )) content = dict () for _file_name in existing_files : dl_file = api_ws . download_workspace_file ( organization_id = self . organization_id , workspace_id = self . workspace_id , file_name = _file_name ) target_file = os . path . join ( tmp_dataset_dir , _file_name . split ( '/' )[ - 1 ]) with open ( target_file , \"wb\" ) as tmp_file : tmp_file . write ( dl_file . read ()) if \".xls\" in _file_name : wb = load_workbook ( target_file , data_only = True ) for sheet_name in wb . sheetnames : sheet = wb [ sheet_name ] content [ sheet_name ] = list () headers = next ( sheet . iter_rows ( max_row = 1 , values_only = True )) def item ( _row : tuple ) -> dict : return { k : v for k , v in zip ( headers , _row )} for r in sheet . iter_rows ( min_row = 2 , values_only = True ): row = item ( r ) new_row = dict () for key , value in row . items (): try : converted_value = json . load ( io . StringIO ( value )) except ( json . decoder . JSONDecodeError , TypeError ): converted_value = value if converted_value is not None : new_row [ key ] = converted_value if new_row : content [ sheet_name ] . append ( new_row ) elif \".csv\" in _file_name : with open ( target_file , \"r\" ) as file : # Read every file in the input folder current_filename = os . path . basename ( target_file )[: - len ( \".csv\" )] content [ current_filename ] = list () for row in csv . DictReader ( file ): new_row = dict () for key , value in row . items (): try : # Try to convert any json row to dict object converted_value = json . load ( io . StringIO ( value )) except json . decoder . JSONDecodeError : converted_value = value if converted_value == '' : converted_value = None if converted_value is not None : new_row [ key ] = converted_value content [ current_filename ] . append ( new_row ) elif \".json\" in _file_name : with open ( target_file , \"r\" ) as _file : current_filename = os . path . basename ( target_file ) content [ current_filename ] = json . load ( _file ) else : with open ( target_file , \"r\" ) as _file : current_filename = os . path . basename ( target_file ) content [ current_filename ] = \" \\n \" . join ( line for line in _file ) return content def _download_adt_content ( self , adt_adress : str ) -> dict : client = DigitalTwinsClient ( adt_adress , self . credentials ) query_expression = 'SELECT * FROM digitaltwins' query_result = client . query_twins ( query_expression ) json_content = dict () for twin in query_result : entity_type = twin . get ( '$metadata' ) . get ( '$model' ) . split ( ':' )[ - 1 ] . split ( ';' )[ 0 ] t_content = { k : v for k , v in twin . items ()} t_content [ 'id' ] = t_content [ '$dtId' ] for k in twin . keys (): if k [ 0 ] == '$' : del t_content [ k ] json_content . setdefault ( entity_type , []) json_content [ entity_type ] . append ( t_content ) relations_query = 'SELECT * FROM relationships' query_result = client . query_twins ( relations_query ) for relation in query_result : tr = { \"$relationshipId\" : \"id\" , \"$sourceId\" : \"source\" , \"$targetId\" : \"target\" } r_content = { k : v for k , v in relation . items ()} for k , v in tr . items (): r_content [ v ] = r_content [ k ] for k in relation . keys (): if k [ 0 ] == '$' : del r_content [ k ] json_content . setdefault ( relation [ '$relationshipName' ], []) json_content [ relation [ '$relationshipName' ]] . append ( r_content ) return json_content def get_all_parameters ( self , scenario_id ) -> dict : scenario_data = self . get_scenario_data ( scenario_id = scenario_id ) content = dict () for parameter in scenario_data [ 'parameters_values' ]: content [ parameter [ 'parameter_id' ]] = parameter [ 'value' ] return content def get_all_datasets ( self , scenario_id : str ) -> dict : scenario_data = self . get_scenario_data ( scenario_id = scenario_id ) datasets = scenario_data [ 'dataset_list' ] content = dict () for dataset_id in datasets : content [ dataset_id ] = self . download_dataset ( dataset_id ) for parameter in scenario_data [ 'parameters_values' ]: if parameter [ 'var_type' ] == '%DATASETID%' : dataset_id = parameter [ 'value' ] content [ dataset_id ] = self . download_dataset ( dataset_id ) return content","title":"ScenarioDownloader"},{"location":"references/Accelerators/utils/multi_environment/","text":"CosmoTech_Acceleration_Library.Accelerators.utils.multi_environment MultiEnvironment Source code in CosmoTech_Acceleration_Library/Accelerators/utils/multi_environment.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class MultiEnvironment : def __init__ ( self ): self . api_host = None self . api_scope = None for host_var in [ 'COSMOTECH_API_SCOPE' , 'CSM_API_SCOPE' ]: if host_var in os . environ : self . api_scope = os . environ . get ( host_var ) break for host_var in [ 'COSMOTECH_API_HOST' , 'COSMOTECH_API_URL' , 'CSM_API_HOST' , 'CSM_API_URL' ]: if host_var in os . environ : self . api_host = os . environ . get ( host_var ) break","title":"multi_environment"},{"location":"references/Accelerators/utils/multi_environment/#cosmotech_acceleration_libraryacceleratorsutilsmulti_environment","text":"","title":"CosmoTech_Acceleration_Library.Accelerators.utils.multi_environment"},{"location":"references/Accelerators/utils/multi_environment/#CosmoTech_Acceleration_Library.Accelerators.utils.multi_environment.MultiEnvironment","text":"Source code in CosmoTech_Acceleration_Library/Accelerators/utils/multi_environment.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class MultiEnvironment : def __init__ ( self ): self . api_host = None self . api_scope = None for host_var in [ 'COSMOTECH_API_SCOPE' , 'CSM_API_SCOPE' ]: if host_var in os . environ : self . api_scope = os . environ . get ( host_var ) break for host_var in [ 'COSMOTECH_API_HOST' , 'COSMOTECH_API_URL' , 'CSM_API_HOST' , 'CSM_API_URL' ]: if host_var in os . environ : self . api_host = os . environ . get ( host_var ) break","title":"MultiEnvironment"},{"location":"references/Modelops/core/common/graph_handler/","text":"CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler ExportableGraphHandler Bases: VersionedGraphHandler Class that handle Exportable Versioned Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 100 101 102 103 104 105 106 107 108 109 110 111 112 class ExportableGraphHandler ( VersionedGraphHandler ): \"\"\" Class that handle Exportable Versioned Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , source_url : str = \"\" , export_dir : str = \"/\" ): super () . __init__ ( host = host , port = port , name = name , version = version , password = password , source_url = source_url ) logger . debug ( \"ExportableGraphHandler init\" ) if export_dir != \"\" : Path ( export_dir ) . mkdir ( parents = True , exist_ok = True ) self . export_dir = export_dir else : self . export_dir = self . default_export_dir GraphHandler Bases: RedisHandler Class that handle Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class GraphHandler ( RedisHandler ): \"\"\" Class that handle Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password ) logger . debug ( \"GraphHandler init\" ) self . graph = self . r . graph ( name ) self . m_metadata = ModelMetadata ( host = host , port = port , name = name , password = password ) current_metadata = self . m_metadata . get_metadata () if not current_metadata : logger . debug ( \"Create metadata key\" ) self . m_metadata . set_metadata ( last_graph_version = 0 , graph_source_url = source_url , graph_rotation = graph_rotation ) RotatedGraphHandler Bases: VersionedGraphHandler Class that handle Rotated Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class RotatedGraphHandler ( VersionedGraphHandler ): \"\"\" Class that handle Rotated Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None , version : int = - 1 , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password , source_url = source_url , version = version , graph_rotation = graph_rotation ) logger . debug ( \"RotatedGraphHandler init\" ) self . graph_rotation = graph_rotation new_version = version if version == - 1 : logger . debug ( \"Handle Rotation Graph\" ) new_version = self . handle_graph_rotation ( name , graph_rotation ) self . fill_versioned_graph_data ( name , new_version ) self . m_metadata . set_graph_rotation ( graph_rotation = graph_rotation ) def handle_graph_rotation ( self , graph_name : str , graph_rotation : int ) -> int : \"\"\" Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create \"\"\" matching_keys = self . r . keys ( ModelUtil . build_graph_key_pattern ( graph_name )) graph_versions = [] for graph_key in matching_keys : graph_versions . append ( graph_key . split ( \":\" )[ - 1 ]) min_version = 0 max_version = 0 if len ( graph_versions ) > 0 : min_version = min ([ int ( x ) for x in graph_versions if x . isnumeric ()]) max_version = max ([ int ( x ) for x in graph_versions if x . isnumeric ()]) logger . debug ( f \" { graph_name } minimal version is: { min_version } \" ) logger . debug ( f \" { graph_name } maximal version is: { max_version } \" ) if len ( matching_keys ) >= graph_rotation : oldest_graph_version_to_delete = ModelUtil . build_graph_version_name ( graph_name , min_version ) self . r . delete ( oldest_graph_version_to_delete ) logger . debug ( f \"Graph { oldest_graph_version_to_delete } deleted\" ) return max_version + 1 handle_graph_rotation ( graph_name , graph_rotation ) Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def handle_graph_rotation ( self , graph_name : str , graph_rotation : int ) -> int : \"\"\" Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create \"\"\" matching_keys = self . r . keys ( ModelUtil . build_graph_key_pattern ( graph_name )) graph_versions = [] for graph_key in matching_keys : graph_versions . append ( graph_key . split ( \":\" )[ - 1 ]) min_version = 0 max_version = 0 if len ( graph_versions ) > 0 : min_version = min ([ int ( x ) for x in graph_versions if x . isnumeric ()]) max_version = max ([ int ( x ) for x in graph_versions if x . isnumeric ()]) logger . debug ( f \" { graph_name } minimal version is: { min_version } \" ) logger . debug ( f \" { graph_name } maximal version is: { max_version } \" ) if len ( matching_keys ) >= graph_rotation : oldest_graph_version_to_delete = ModelUtil . build_graph_version_name ( graph_name , min_version ) self . r . delete ( oldest_graph_version_to_delete ) logger . debug ( f \"Graph { oldest_graph_version_to_delete } deleted\" ) return max_version + 1 VersionedGraphHandler Bases: GraphHandler Class that handle Versioned Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class VersionedGraphHandler ( GraphHandler ): \"\"\" Class that handle Versioned Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password , source_url = source_url , graph_rotation = graph_rotation ) logger . debug ( \"VersionedGraphHandler init\" ) self . version = None self . versioned_name = None self . fill_versioned_graph_data ( name , version ) def fill_versioned_graph_data ( self , graph_name : str , version : int ): \"\"\" Fill data about version and create new graph :param graph_name: the graph name :param version: the version \"\"\" versioned_name = ModelUtil . build_graph_version_name ( graph_name , version ) self . versioned_name = versioned_name self . version = version self . graph = self . r . graph ( versioned_name ) self . m_metadata . set_last_graph_version ( version ) fill_versioned_graph_data ( graph_name , version ) Fill data about version and create new graph :param graph_name: the graph name :param version: the version Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 44 45 46 47 48 49 50 51 52 53 54 def fill_versioned_graph_data ( self , graph_name : str , version : int ): \"\"\" Fill data about version and create new graph :param graph_name: the graph name :param version: the version \"\"\" versioned_name = ModelUtil . build_graph_version_name ( graph_name , version ) self . versioned_name = versioned_name self . version = version self . graph = self . r . graph ( versioned_name ) self . m_metadata . set_last_graph_version ( version )","title":"graph_handler"},{"location":"references/Modelops/core/common/graph_handler/#cosmotech_acceleration_librarymodelopscorecommongraph_handler","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.ExportableGraphHandler","text":"Bases: VersionedGraphHandler Class that handle Exportable Versioned Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 100 101 102 103 104 105 106 107 108 109 110 111 112 class ExportableGraphHandler ( VersionedGraphHandler ): \"\"\" Class that handle Exportable Versioned Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , source_url : str = \"\" , export_dir : str = \"/\" ): super () . __init__ ( host = host , port = port , name = name , version = version , password = password , source_url = source_url ) logger . debug ( \"ExportableGraphHandler init\" ) if export_dir != \"\" : Path ( export_dir ) . mkdir ( parents = True , exist_ok = True ) self . export_dir = export_dir else : self . export_dir = self . default_export_dir","title":"ExportableGraphHandler"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler","text":"Bases: RedisHandler Class that handle Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class GraphHandler ( RedisHandler ): \"\"\" Class that handle Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password ) logger . debug ( \"GraphHandler init\" ) self . graph = self . r . graph ( name ) self . m_metadata = ModelMetadata ( host = host , port = port , name = name , password = password ) current_metadata = self . m_metadata . get_metadata () if not current_metadata : logger . debug ( \"Create metadata key\" ) self . m_metadata . set_metadata ( last_graph_version = 0 , graph_source_url = source_url , graph_rotation = graph_rotation )","title":"GraphHandler"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.RotatedGraphHandler","text":"Bases: VersionedGraphHandler Class that handle Rotated Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 class RotatedGraphHandler ( VersionedGraphHandler ): \"\"\" Class that handle Rotated Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None , version : int = - 1 , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password , source_url = source_url , version = version , graph_rotation = graph_rotation ) logger . debug ( \"RotatedGraphHandler init\" ) self . graph_rotation = graph_rotation new_version = version if version == - 1 : logger . debug ( \"Handle Rotation Graph\" ) new_version = self . handle_graph_rotation ( name , graph_rotation ) self . fill_versioned_graph_data ( name , new_version ) self . m_metadata . set_graph_rotation ( graph_rotation = graph_rotation ) def handle_graph_rotation ( self , graph_name : str , graph_rotation : int ) -> int : \"\"\" Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create \"\"\" matching_keys = self . r . keys ( ModelUtil . build_graph_key_pattern ( graph_name )) graph_versions = [] for graph_key in matching_keys : graph_versions . append ( graph_key . split ( \":\" )[ - 1 ]) min_version = 0 max_version = 0 if len ( graph_versions ) > 0 : min_version = min ([ int ( x ) for x in graph_versions if x . isnumeric ()]) max_version = max ([ int ( x ) for x in graph_versions if x . isnumeric ()]) logger . debug ( f \" { graph_name } minimal version is: { min_version } \" ) logger . debug ( f \" { graph_name } maximal version is: { max_version } \" ) if len ( matching_keys ) >= graph_rotation : oldest_graph_version_to_delete = ModelUtil . build_graph_version_name ( graph_name , min_version ) self . r . delete ( oldest_graph_version_to_delete ) logger . debug ( f \"Graph { oldest_graph_version_to_delete } deleted\" ) return max_version + 1","title":"RotatedGraphHandler"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.RotatedGraphHandler.handle_graph_rotation","text":"Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 def handle_graph_rotation ( self , graph_name : str , graph_rotation : int ) -> int : \"\"\" Handle graph rotation (delete the oldest graph if the amount of graph is upper than graph rotation :param graph_name: the graph name :param graph_rotation: the amount of graph to keep :return: the graph version to create \"\"\" matching_keys = self . r . keys ( ModelUtil . build_graph_key_pattern ( graph_name )) graph_versions = [] for graph_key in matching_keys : graph_versions . append ( graph_key . split ( \":\" )[ - 1 ]) min_version = 0 max_version = 0 if len ( graph_versions ) > 0 : min_version = min ([ int ( x ) for x in graph_versions if x . isnumeric ()]) max_version = max ([ int ( x ) for x in graph_versions if x . isnumeric ()]) logger . debug ( f \" { graph_name } minimal version is: { min_version } \" ) logger . debug ( f \" { graph_name } maximal version is: { max_version } \" ) if len ( matching_keys ) >= graph_rotation : oldest_graph_version_to_delete = ModelUtil . build_graph_version_name ( graph_name , min_version ) self . r . delete ( oldest_graph_version_to_delete ) logger . debug ( f \"Graph { oldest_graph_version_to_delete } deleted\" ) return max_version + 1","title":"handle_graph_rotation()"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.VersionedGraphHandler","text":"Bases: GraphHandler Class that handle Versioned Graph Redis information Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class VersionedGraphHandler ( GraphHandler ): \"\"\" Class that handle Versioned Graph Redis information \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , source_url : str = \"\" , graph_rotation : int = 1 ): super () . __init__ ( host = host , port = port , name = name , password = password , source_url = source_url , graph_rotation = graph_rotation ) logger . debug ( \"VersionedGraphHandler init\" ) self . version = None self . versioned_name = None self . fill_versioned_graph_data ( name , version ) def fill_versioned_graph_data ( self , graph_name : str , version : int ): \"\"\" Fill data about version and create new graph :param graph_name: the graph name :param version: the version \"\"\" versioned_name = ModelUtil . build_graph_version_name ( graph_name , version ) self . versioned_name = versioned_name self . version = version self . graph = self . r . graph ( versioned_name ) self . m_metadata . set_last_graph_version ( version )","title":"VersionedGraphHandler"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.VersionedGraphHandler.fill_versioned_graph_data","text":"Fill data about version and create new graph :param graph_name: the graph name :param version: the version Source code in CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py 44 45 46 47 48 49 50 51 52 53 54 def fill_versioned_graph_data ( self , graph_name : str , version : int ): \"\"\" Fill data about version and create new graph :param graph_name: the graph name :param version: the version \"\"\" versioned_name = ModelUtil . build_graph_version_name ( graph_name , version ) self . versioned_name = versioned_name self . version = version self . graph = self . r . graph ( versioned_name ) self . m_metadata . set_last_graph_version ( version )","title":"fill_versioned_graph_data()"},{"location":"references/Modelops/core/common/redis_handler/","text":"CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler RedisHandler Class that handle Redis informations Source code in CosmoTech_Acceleration_Library/Modelops/core/common/redis_handler.py 10 11 12 13 14 15 16 17 18 19 20 21 22 class RedisHandler : \"\"\" Class that handle Redis informations \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None ): logger . debug ( \"RedisHandler init\" ) self . host = host self . port = port self . name = name self . password = password self . r = redis . Redis ( host = host , port = port , password = password , decode_responses = True ) self . metadata_key = name + \"MetaData\"","title":"redis_handler"},{"location":"references/Modelops/core/common/redis_handler/#cosmotech_acceleration_librarymodelopscorecommonredis_handler","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler"},{"location":"references/Modelops/core/common/redis_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler.RedisHandler","text":"Class that handle Redis informations Source code in CosmoTech_Acceleration_Library/Modelops/core/common/redis_handler.py 10 11 12 13 14 15 16 17 18 19 20 21 22 class RedisHandler : \"\"\" Class that handle Redis informations \"\"\" def __init__ ( self , host : str , port : int , name : str , password : str = None ): logger . debug ( \"RedisHandler init\" ) self . host = host self . port = port self . name = name self . password = password self . r = redis . Redis ( host = host , port = port , password = password , decode_responses = True ) self . metadata_key = name + \"MetaData\"","title":"RedisHandler"},{"location":"references/Modelops/core/common/writer/CsvWriter/","text":"CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter CsvWriter Csv Writer class Source code in CosmoTech_Acceleration_Library/Modelops/core/common/writer/CsvWriter.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class CsvWriter : \"\"\" Csv Writer class \"\"\" @staticmethod def write_twin_data ( export_dir : str , file_name : str , query_result : QueryResult , headers : list = [], delimiter : str = ',' , quote_char : str = ' \\\" ' ) -> None : output_file_name = export_dir + file_name + '.csv' logger . debug ( f \"Writing CSV file { output_file_name } \" ) csvfile = open ( output_file_name , 'w' ) writer = csv . writer ( csvfile , delimiter = delimiter , quotechar = quote_char , quoting = csv . QUOTE_ALL ) if headers : writer . writerow ( headers ) for raw_data in query_result . result_set : for i in range ( len ( raw_data )): row = [] for key , val in raw_data [ i ] . properties . items (): if isinstance ( val , bool ): row . append ( str ( val ) . lower ()) elif str ( val ) == 'True' or str ( val ) == 'False' : row . append ( str ( val ) . lower ()) else : row . append ( str ( val )) writer . writerow ( row ) csvfile . close () logger . debug ( f \"... CSV file { output_file_name } has been written\" ) @staticmethod def write_relationship_data ( export_dir : str , file_name : str , query_result : QueryResult , headers : list = [], delimiter : str = ',' , quote_char : str = ' \\\" ' ) -> None : output_file_name = export_dir + file_name + '.csv' logger . debug ( f \"Writing CSV file { output_file_name } \" ) csvfile = open ( output_file_name , 'w' ) writer = csv . writer ( csvfile , delimiter = delimiter , quotechar = quote_char , quoting = csv . QUOTE_ALL ) if headers : writer . writerow ( headers ) for raw_data in query_result . result_set : row = [ raw_data [ 0 ], raw_data [ 1 ]] for key , val in raw_data [ 2 ] . properties . items (): property_name = str ( key ) if property_name != ModelUtil . src_key and property_name != ModelUtil . dest_key : if isinstance ( val , bool ): row . append ( str ( val ) . lower ()) elif str ( val ) == 'True' or str ( val ) == 'False' : row . append ( str ( val ) . lower ()) else : row . append ( str ( val )) writer . writerow ( row ) csvfile . close () logger . debug ( f \"... CSV file { output_file_name } has been written\" )","title":"CsvWriter"},{"location":"references/Modelops/core/common/writer/CsvWriter/#cosmotech_acceleration_librarymodelopscorecommonwritercsvwriter","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter"},{"location":"references/Modelops/core/common/writer/CsvWriter/#CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter.CsvWriter","text":"Csv Writer class Source code in CosmoTech_Acceleration_Library/Modelops/core/common/writer/CsvWriter.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 class CsvWriter : \"\"\" Csv Writer class \"\"\" @staticmethod def write_twin_data ( export_dir : str , file_name : str , query_result : QueryResult , headers : list = [], delimiter : str = ',' , quote_char : str = ' \\\" ' ) -> None : output_file_name = export_dir + file_name + '.csv' logger . debug ( f \"Writing CSV file { output_file_name } \" ) csvfile = open ( output_file_name , 'w' ) writer = csv . writer ( csvfile , delimiter = delimiter , quotechar = quote_char , quoting = csv . QUOTE_ALL ) if headers : writer . writerow ( headers ) for raw_data in query_result . result_set : for i in range ( len ( raw_data )): row = [] for key , val in raw_data [ i ] . properties . items (): if isinstance ( val , bool ): row . append ( str ( val ) . lower ()) elif str ( val ) == 'True' or str ( val ) == 'False' : row . append ( str ( val ) . lower ()) else : row . append ( str ( val )) writer . writerow ( row ) csvfile . close () logger . debug ( f \"... CSV file { output_file_name } has been written\" ) @staticmethod def write_relationship_data ( export_dir : str , file_name : str , query_result : QueryResult , headers : list = [], delimiter : str = ',' , quote_char : str = ' \\\" ' ) -> None : output_file_name = export_dir + file_name + '.csv' logger . debug ( f \"Writing CSV file { output_file_name } \" ) csvfile = open ( output_file_name , 'w' ) writer = csv . writer ( csvfile , delimiter = delimiter , quotechar = quote_char , quoting = csv . QUOTE_ALL ) if headers : writer . writerow ( headers ) for raw_data in query_result . result_set : row = [ raw_data [ 0 ], raw_data [ 1 ]] for key , val in raw_data [ 2 ] . properties . items (): property_name = str ( key ) if property_name != ModelUtil . src_key and property_name != ModelUtil . dest_key : if isinstance ( val , bool ): row . append ( str ( val ) . lower ()) elif str ( val ) == 'True' or str ( val ) == 'False' : row . append ( str ( val ) . lower ()) else : row . append ( str ( val )) writer . writerow ( row ) csvfile . close () logger . debug ( f \"... CSV file { output_file_name } has been written\" )","title":"CsvWriter"},{"location":"references/Modelops/core/decorators/model_decorators/","text":"CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators model_decorators do_if_graph_exist ( function ) Function decorator that run the function annotated if versioned graph exists :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def do_if_graph_exist ( function ): \"\"\" Function decorator that run the function annotated if versioned graph exists :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] version_graph_name = self . versioned_name if isinstance ( self , ExportableGraphHandler ): key_count = self . r . exists ( version_graph_name ) if key_count != 0 : function ( * args , ** kwargs ) else : raise Exception ( f \" { version_graph_name } does not exist!\" ) else : function ( * args , ** kwargs ) return wrapper update_last_modified_date ( function ) Function decorator that update metadata last modified date after calling the function annotated :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def update_last_modified_date ( function ): \"\"\" Function decorator that update metadata last modified date after calling the function annotated :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] if isinstance ( self , GraphHandler ): function ( * args , ** kwargs ) self . m_metadata . update_last_modified_date () else : function ( * args , ** kwargs ) return wrapper update_last_version ( function ) Function decorator that update metadata last version after calling the function annotated :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def update_last_version ( function ): \"\"\" Function decorator that update metadata last version after calling the function annotated :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] if isinstance ( self , GraphHandler ): function ( * args , ** kwargs ) self . m_metadata . update_last_version () else : function ( * args , ** kwargs ) return wrapper","title":"model_decorators"},{"location":"references/Modelops/core/decorators/model_decorators/#cosmotech_acceleration_librarymodelopscoredecoratorsmodel_decorators","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators"},{"location":"references/Modelops/core/decorators/model_decorators/#CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators","text":"","title":"model_decorators"},{"location":"references/Modelops/core/decorators/model_decorators/#CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators.do_if_graph_exist","text":"Function decorator that run the function annotated if versioned graph exists :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def do_if_graph_exist ( function ): \"\"\" Function decorator that run the function annotated if versioned graph exists :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] version_graph_name = self . versioned_name if isinstance ( self , ExportableGraphHandler ): key_count = self . r . exists ( version_graph_name ) if key_count != 0 : function ( * args , ** kwargs ) else : raise Exception ( f \" { version_graph_name } does not exist!\" ) else : function ( * args , ** kwargs ) return wrapper","title":"do_if_graph_exist()"},{"location":"references/Modelops/core/decorators/model_decorators/#CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators.update_last_modified_date","text":"Function decorator that update metadata last modified date after calling the function annotated :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def update_last_modified_date ( function ): \"\"\" Function decorator that update metadata last modified date after calling the function annotated :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] if isinstance ( self , GraphHandler ): function ( * args , ** kwargs ) self . m_metadata . update_last_modified_date () else : function ( * args , ** kwargs ) return wrapper","title":"update_last_modified_date()"},{"location":"references/Modelops/core/decorators/model_decorators/#CosmoTech_Acceleration_Library.Modelops.core.decorators.model_decorators.update_last_version","text":"Function decorator that update metadata last version after calling the function annotated :param function: the function annotated Source code in CosmoTech_Acceleration_Library/Modelops/core/decorators/model_decorators.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def update_last_version ( function ): \"\"\" Function decorator that update metadata last version after calling the function annotated :param function: the function annotated \"\"\" @functools . wraps ( function ) def wrapper ( * args , ** kwargs ): self = args [ 0 ] if isinstance ( self , GraphHandler ): function ( * args , ** kwargs ) self . m_metadata . update_last_version () else : function ( * args , ** kwargs ) return wrapper","title":"update_last_version()"},{"location":"references/Modelops/core/io/model_exporter/","text":"CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter ModelExporter Bases: ExportableGraphHandler Model Exporter for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class ModelExporter ( ExportableGraphHandler ): \"\"\" Model Exporter for cached data \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , export_dir : str = \"/\" ): super () . __init__ ( host = host , port = port , name = name , version = version , password = password , export_dir = export_dir ) self . mr = ModelReader ( host = host , port = port , name = name , password = password , version = version ) @do_if_graph_exist def export_all_twins ( self ): \"\"\" Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" logger . debug ( \"Start exporting twins...\" ) logger . debug ( \"Get twin types...\" ) get_types_start = time . time () twin_names = self . mr . get_twin_types () get_types_end = time . time () - get_types_start logger . debug ( f \"Get twin types took { get_types_end } s\" ) for twin_name in twin_names : logger . debug ( f \"Get twin info for type { twin_name } ...\" ) get_twin_info_start = time . time () headers = self . mr . get_twin_properties_by_type ( twin_name ) twin_results = self . mr . get_twins_by_type ( twin_name ) get_twin_info_end = time . time () - get_twin_info_start logger . debug ( f \"Get twin info for type { twin_name } took { get_twin_info_end } s\" ) logger . debug ( f \"Export twin info for type { twin_name } ...\" ) export_twin_info_start = time . time () CsvWriter . write_twin_data ( self . export_dir , twin_name , twin_results , headers ) export_twin_info_end = time . time () - export_twin_info_start logger . debug ( f \"Export twin info for type { twin_name } took { export_twin_info_end } s\" ) logger . debug ( f \"Twins exported : { twin_name } \" ) logger . debug ( \"... End exporting twins\" ) @do_if_graph_exist def export_all_relationships ( self ): \"\"\" Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type \"\"\" logger . debug ( \"Start exporting relationships...\" ) logger . debug ( \"Get relationship types...\" ) get_relationship_types_start = time . time () relationship_names = self . mr . get_relationship_types () get_relationship_types_end = time . time () - get_relationship_types_start logger . debug ( f \"Get relationship types took { get_relationship_types_end } s\" ) for relationship_name in relationship_names : logger . debug ( f \"Get relationship info for type { relationship_name } ...\" ) get_relationship_info_start = time . time () headers = self . mr . get_relationship_properties_by_type ( relationship_name ) relationship_result = self . mr . get_relationships_by_type ( relationship_name ) get_relationship_info_end = time . time () - get_relationship_info_start logger . debug ( f \"Get relationship info for type { relationship_name } took { get_relationship_info_end } s\" ) logger . debug ( f \"Export relationship info for type { relationship_name } ...\" ) export_relationship_info_start = time . time () CsvWriter . write_relationship_data ( self . export_dir , relationship_name , relationship_result , headers ) export_relationship_info_end = time . time () - export_relationship_info_start logger . debug ( f \"Export relationship info for type { relationship_name } took { export_relationship_info_end } s\" ) logger . debug ( f \"Relationships exported : { relationship_name } \" ) logger . debug ( \"... End exporting relationships\" ) @do_if_graph_exist def export_all_data ( self ): \"\"\" Export all data :return: a bunch of csv files corresponding to graph data \"\"\" self . export_all_twins () self . export_all_relationships () export_all_data () Export all data :return: a bunch of csv files corresponding to graph data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 80 81 82 83 84 85 86 87 @do_if_graph_exist def export_all_data ( self ): \"\"\" Export all data :return: a bunch of csv files corresponding to graph data \"\"\" self . export_all_twins () self . export_all_relationships () export_all_relationships () Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @do_if_graph_exist def export_all_relationships ( self ): \"\"\" Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type \"\"\" logger . debug ( \"Start exporting relationships...\" ) logger . debug ( \"Get relationship types...\" ) get_relationship_types_start = time . time () relationship_names = self . mr . get_relationship_types () get_relationship_types_end = time . time () - get_relationship_types_start logger . debug ( f \"Get relationship types took { get_relationship_types_end } s\" ) for relationship_name in relationship_names : logger . debug ( f \"Get relationship info for type { relationship_name } ...\" ) get_relationship_info_start = time . time () headers = self . mr . get_relationship_properties_by_type ( relationship_name ) relationship_result = self . mr . get_relationships_by_type ( relationship_name ) get_relationship_info_end = time . time () - get_relationship_info_start logger . debug ( f \"Get relationship info for type { relationship_name } took { get_relationship_info_end } s\" ) logger . debug ( f \"Export relationship info for type { relationship_name } ...\" ) export_relationship_info_start = time . time () CsvWriter . write_relationship_data ( self . export_dir , relationship_name , relationship_result , headers ) export_relationship_info_end = time . time () - export_relationship_info_start logger . debug ( f \"Export relationship info for type { relationship_name } took { export_relationship_info_end } s\" ) logger . debug ( f \"Relationships exported : { relationship_name } \" ) logger . debug ( \"... End exporting relationships\" ) export_all_twins () Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @do_if_graph_exist def export_all_twins ( self ): \"\"\" Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" logger . debug ( \"Start exporting twins...\" ) logger . debug ( \"Get twin types...\" ) get_types_start = time . time () twin_names = self . mr . get_twin_types () get_types_end = time . time () - get_types_start logger . debug ( f \"Get twin types took { get_types_end } s\" ) for twin_name in twin_names : logger . debug ( f \"Get twin info for type { twin_name } ...\" ) get_twin_info_start = time . time () headers = self . mr . get_twin_properties_by_type ( twin_name ) twin_results = self . mr . get_twins_by_type ( twin_name ) get_twin_info_end = time . time () - get_twin_info_start logger . debug ( f \"Get twin info for type { twin_name } took { get_twin_info_end } s\" ) logger . debug ( f \"Export twin info for type { twin_name } ...\" ) export_twin_info_start = time . time () CsvWriter . write_twin_data ( self . export_dir , twin_name , twin_results , headers ) export_twin_info_end = time . time () - export_twin_info_start logger . debug ( f \"Export twin info for type { twin_name } took { export_twin_info_end } s\" ) logger . debug ( f \"Twins exported : { twin_name } \" ) logger . debug ( \"... End exporting twins\" )","title":"model_exporter"},{"location":"references/Modelops/core/io/model_exporter/#cosmotech_acceleration_librarymodelopscoreiomodel_exporter","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter","text":"Bases: ExportableGraphHandler Model Exporter for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class ModelExporter ( ExportableGraphHandler ): \"\"\" Model Exporter for cached data \"\"\" def __init__ ( self , host : str , port : int , name : str , version : int , password : str = None , export_dir : str = \"/\" ): super () . __init__ ( host = host , port = port , name = name , version = version , password = password , export_dir = export_dir ) self . mr = ModelReader ( host = host , port = port , name = name , password = password , version = version ) @do_if_graph_exist def export_all_twins ( self ): \"\"\" Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" logger . debug ( \"Start exporting twins...\" ) logger . debug ( \"Get twin types...\" ) get_types_start = time . time () twin_names = self . mr . get_twin_types () get_types_end = time . time () - get_types_start logger . debug ( f \"Get twin types took { get_types_end } s\" ) for twin_name in twin_names : logger . debug ( f \"Get twin info for type { twin_name } ...\" ) get_twin_info_start = time . time () headers = self . mr . get_twin_properties_by_type ( twin_name ) twin_results = self . mr . get_twins_by_type ( twin_name ) get_twin_info_end = time . time () - get_twin_info_start logger . debug ( f \"Get twin info for type { twin_name } took { get_twin_info_end } s\" ) logger . debug ( f \"Export twin info for type { twin_name } ...\" ) export_twin_info_start = time . time () CsvWriter . write_twin_data ( self . export_dir , twin_name , twin_results , headers ) export_twin_info_end = time . time () - export_twin_info_start logger . debug ( f \"Export twin info for type { twin_name } took { export_twin_info_end } s\" ) logger . debug ( f \"Twins exported : { twin_name } \" ) logger . debug ( \"... End exporting twins\" ) @do_if_graph_exist def export_all_relationships ( self ): \"\"\" Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type \"\"\" logger . debug ( \"Start exporting relationships...\" ) logger . debug ( \"Get relationship types...\" ) get_relationship_types_start = time . time () relationship_names = self . mr . get_relationship_types () get_relationship_types_end = time . time () - get_relationship_types_start logger . debug ( f \"Get relationship types took { get_relationship_types_end } s\" ) for relationship_name in relationship_names : logger . debug ( f \"Get relationship info for type { relationship_name } ...\" ) get_relationship_info_start = time . time () headers = self . mr . get_relationship_properties_by_type ( relationship_name ) relationship_result = self . mr . get_relationships_by_type ( relationship_name ) get_relationship_info_end = time . time () - get_relationship_info_start logger . debug ( f \"Get relationship info for type { relationship_name } took { get_relationship_info_end } s\" ) logger . debug ( f \"Export relationship info for type { relationship_name } ...\" ) export_relationship_info_start = time . time () CsvWriter . write_relationship_data ( self . export_dir , relationship_name , relationship_result , headers ) export_relationship_info_end = time . time () - export_relationship_info_start logger . debug ( f \"Export relationship info for type { relationship_name } took { export_relationship_info_end } s\" ) logger . debug ( f \"Relationships exported : { relationship_name } \" ) logger . debug ( \"... End exporting relationships\" ) @do_if_graph_exist def export_all_data ( self ): \"\"\" Export all data :return: a bunch of csv files corresponding to graph data \"\"\" self . export_all_twins () self . export_all_relationships ()","title":"ModelExporter"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_data","text":"Export all data :return: a bunch of csv files corresponding to graph data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 80 81 82 83 84 85 86 87 @do_if_graph_exist def export_all_data ( self ): \"\"\" Export all data :return: a bunch of csv files corresponding to graph data \"\"\" self . export_all_twins () self . export_all_relationships ()","title":"export_all_data()"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_relationships","text":"Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 @do_if_graph_exist def export_all_relationships ( self ): \"\"\" Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type \"\"\" logger . debug ( \"Start exporting relationships...\" ) logger . debug ( \"Get relationship types...\" ) get_relationship_types_start = time . time () relationship_names = self . mr . get_relationship_types () get_relationship_types_end = time . time () - get_relationship_types_start logger . debug ( f \"Get relationship types took { get_relationship_types_end } s\" ) for relationship_name in relationship_names : logger . debug ( f \"Get relationship info for type { relationship_name } ...\" ) get_relationship_info_start = time . time () headers = self . mr . get_relationship_properties_by_type ( relationship_name ) relationship_result = self . mr . get_relationships_by_type ( relationship_name ) get_relationship_info_end = time . time () - get_relationship_info_start logger . debug ( f \"Get relationship info for type { relationship_name } took { get_relationship_info_end } s\" ) logger . debug ( f \"Export relationship info for type { relationship_name } ...\" ) export_relationship_info_start = time . time () CsvWriter . write_relationship_data ( self . export_dir , relationship_name , relationship_result , headers ) export_relationship_info_end = time . time () - export_relationship_info_start logger . debug ( f \"Export relationship info for type { relationship_name } took { export_relationship_info_end } s\" ) logger . debug ( f \"Relationships exported : { relationship_name } \" ) logger . debug ( \"... End exporting relationships\" )","title":"export_all_relationships()"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_twins","text":"Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 @do_if_graph_exist def export_all_twins ( self ): \"\"\" Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" logger . debug ( \"Start exporting twins...\" ) logger . debug ( \"Get twin types...\" ) get_types_start = time . time () twin_names = self . mr . get_twin_types () get_types_end = time . time () - get_types_start logger . debug ( f \"Get twin types took { get_types_end } s\" ) for twin_name in twin_names : logger . debug ( f \"Get twin info for type { twin_name } ...\" ) get_twin_info_start = time . time () headers = self . mr . get_twin_properties_by_type ( twin_name ) twin_results = self . mr . get_twins_by_type ( twin_name ) get_twin_info_end = time . time () - get_twin_info_start logger . debug ( f \"Get twin info for type { twin_name } took { get_twin_info_end } s\" ) logger . debug ( f \"Export twin info for type { twin_name } ...\" ) export_twin_info_start = time . time () CsvWriter . write_twin_data ( self . export_dir , twin_name , twin_results , headers ) export_twin_info_end = time . time () - export_twin_info_start logger . debug ( f \"Export twin info for type { twin_name } took { export_twin_info_end } s\" ) logger . debug ( f \"Twins exported : { twin_name } \" ) logger . debug ( \"... End exporting twins\" )","title":"export_all_twins()"},{"location":"references/Modelops/core/io/model_importer/","text":"CosmoTech_Acceleration_Library.Modelops.core.io.model_importer ModelImporter Bases: RotatedGraphHandler Model Exporter for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class ModelImporter ( RotatedGraphHandler ): \"\"\" Model Exporter for cached data \"\"\" def bulk_import ( self , twin_file_paths : list = [], relationship_file_paths : list = [], enforce_schema : bool = False ): \"\"\" Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) `Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas>`_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" command_parameters = [ '--host' , self . host , '--port' , self . port ] if self . password is not None : command_parameters . append ( '--password' ) command_parameters . append ( self . password ) if enforce_schema : command_parameters . append ( '--enforce-schema' ) for twin_file_path in twin_file_paths : if twin_file_path != \"\" : command_parameters . append ( '--nodes' ) command_parameters . append ( twin_file_path ) for relationship_file_path in relationship_file_paths : if relationship_file_path != \"\" : command_parameters . append ( '--relations' ) command_parameters . append ( relationship_file_path ) command_parameters . append ( ModelUtil . build_graph_version_name ( self . name , self . version )) logger . debug ( command_parameters ) # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties try : bulk_insert ( command_parameters ) except SystemExit : pass bulk_import ( twin_file_paths = [], relationship_file_paths = [], enforce_schema = False ) Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas> _ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def bulk_import ( self , twin_file_paths : list = [], relationship_file_paths : list = [], enforce_schema : bool = False ): \"\"\" Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) `Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas>`_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" command_parameters = [ '--host' , self . host , '--port' , self . port ] if self . password is not None : command_parameters . append ( '--password' ) command_parameters . append ( self . password ) if enforce_schema : command_parameters . append ( '--enforce-schema' ) for twin_file_path in twin_file_paths : if twin_file_path != \"\" : command_parameters . append ( '--nodes' ) command_parameters . append ( twin_file_path ) for relationship_file_path in relationship_file_paths : if relationship_file_path != \"\" : command_parameters . append ( '--relations' ) command_parameters . append ( relationship_file_path ) command_parameters . append ( ModelUtil . build_graph_version_name ( self . name , self . version )) logger . debug ( command_parameters ) # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties try : bulk_insert ( command_parameters ) except SystemExit : pass","title":"model_importer"},{"location":"references/Modelops/core/io/model_importer/#cosmotech_acceleration_librarymodelopscoreiomodel_importer","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_importer"},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter","text":"Bases: RotatedGraphHandler Model Exporter for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class ModelImporter ( RotatedGraphHandler ): \"\"\" Model Exporter for cached data \"\"\" def bulk_import ( self , twin_file_paths : list = [], relationship_file_paths : list = [], enforce_schema : bool = False ): \"\"\" Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) `Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas>`_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" command_parameters = [ '--host' , self . host , '--port' , self . port ] if self . password is not None : command_parameters . append ( '--password' ) command_parameters . append ( self . password ) if enforce_schema : command_parameters . append ( '--enforce-schema' ) for twin_file_path in twin_file_paths : if twin_file_path != \"\" : command_parameters . append ( '--nodes' ) command_parameters . append ( twin_file_path ) for relationship_file_path in relationship_file_paths : if relationship_file_path != \"\" : command_parameters . append ( '--relations' ) command_parameters . append ( relationship_file_path ) command_parameters . append ( ModelUtil . build_graph_version_name ( self . name , self . version )) logger . debug ( command_parameters ) # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties try : bulk_insert ( command_parameters ) except SystemExit : pass","title":"ModelImporter"},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter.bulk_import","text":"Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas> _ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def bulk_import ( self , twin_file_paths : list = [], relationship_file_paths : list = [], enforce_schema : bool = False ): \"\"\" Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) `Enforce_schema documentation <https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas>`_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type \"\"\" command_parameters = [ '--host' , self . host , '--port' , self . port ] if self . password is not None : command_parameters . append ( '--password' ) command_parameters . append ( self . password ) if enforce_schema : command_parameters . append ( '--enforce-schema' ) for twin_file_path in twin_file_paths : if twin_file_path != \"\" : command_parameters . append ( '--nodes' ) command_parameters . append ( twin_file_path ) for relationship_file_path in relationship_file_paths : if relationship_file_path != \"\" : command_parameters . append ( '--relations' ) command_parameters . append ( relationship_file_path ) command_parameters . append ( ModelUtil . build_graph_version_name ( self . name , self . version )) logger . debug ( command_parameters ) # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties try : bulk_insert ( command_parameters ) except SystemExit : pass","title":"bulk_import()"},{"location":"references/Modelops/core/io/model_metadata/","text":"CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata ModelMetadata Bases: RedisHandler Model Metadata management class for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 class ModelMetadata ( RedisHandler ): \"\"\" Model Metadata management class for cached data \"\"\" last_modified_date_key = \"lastModifiedDate\" last_version_key = \"lastVersion\" source_url_key = \"adtUrl\" graph_name_key = \"graphName\" graph_rotation_key = \"graphRotation\" def get_metadata ( self ) -> dict : \"\"\" Get the metadata of the graph :return: the dict containing all graph metadata \"\"\" return self . r . hgetall ( self . metadata_key ) def get_last_graph_version ( self ) -> str : \"\"\" Get the current last version of the graph :return: the graph last version \"\"\" return self . get_metadata ()[ self . last_version_key ] def get_graph_name ( self ) -> str : \"\"\" Get the graph's name :return: the graph's name \"\"\" return self . name def get_graph_source_url ( self ) -> str : \"\"\" Get the datasource of the graph :return: the datasource of the graph \"\"\" return self . get_metadata ()[ self . source_url_key ] def get_graph_rotation ( self ) -> str : \"\"\" Get the graph rotation of the graph :return: the graph rotation of the graph \"\"\" return self . get_metadata ()[ self . graph_rotation_key ] def get_last_modified_date ( self ) -> datetime : \"\"\" Get the last modified date of the graph :return: the last modified date of the graph \"\"\" metadata_last_version = self . get_metadata ()[ self . last_modified_date_key ] return ModelUtil . convert_str_to_datetime ( metadata_last_version ) def set_all_metadata ( self , metadata : dict ): \"\"\" Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) new_version = int ( metadata [ self . last_version_key ]) if new_version > current_version : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) else : raise Exception ( f \"The current version { current_version } is equal or greater than the version to set: { new_version } \" ) else : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) def set_metadata ( self , last_graph_version : int , graph_source_url : str , graph_rotation : int ) -> dict : \"\"\" Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one \"\"\" metadata = { self . last_version_key : str ( last_graph_version ), self . graph_name_key : self . name , self . source_url_key : graph_source_url , self . graph_rotation_key : str ( graph_rotation ), self . last_modified_date_key : ModelUtil . convert_datetime_to_str ( datetime . utcnow ()) } logger . debug ( f \"Metatadata to set : { metadata } \" ) self . set_all_metadata ( metadata = metadata ) def set_last_graph_version ( self , last_graph_version : int ): \"\"\" Set the current last version of the graph :param last_graph_version the new version \"\"\" self . r . hset ( self . metadata_key , self . last_version_key , str ( last_graph_version )) logger . debug ( f \"Graph last_graph_version to set : { str ( last_graph_version ) } \" ) self . update_last_modified_date () def set_graph_source_url ( self , graph_source_url : str ): \"\"\" Set the datasource of the graph :param graph_source_url the source url \"\"\" self . r . hset ( self . metadata_key , self . source_url_key , graph_source_url ) logger . debug ( f \"Graph source_url to set : { str ( graph_source_url ) } \" ) self . update_last_modified_date () def set_graph_rotation ( self , graph_rotation : int ): \"\"\" Set the graph rotation of the graph :param graph_rotation the graph rotation \"\"\" self . r . hset ( self . metadata_key , self . graph_rotation_key , str ( graph_rotation )) logger . debug ( f \"Graph graph_rotation to set : { str ( graph_rotation ) } \" ) self . update_last_modified_date () def update_last_modified_date ( self ): \"\"\" Update the last modified date of the graph \"\"\" self . r . hset ( self . metadata_key , self . last_modified_date_key , ModelUtil . convert_datetime_to_str ( datetime . utcnow ())) def update_last_version ( self ): \"\"\" Update the last version of the graph \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) current_version += 1 self . set_last_graph_version ( str ( current_version )) self . update_last_modified_date () else : self . set_last_graph_version ( \"0\" ) self . update_last_modified_date () get_graph_name () Get the graph's name :return: the graph's name Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 36 37 38 39 40 41 def get_graph_name ( self ) -> str : \"\"\" Get the graph's name :return: the graph's name \"\"\" return self . name get_graph_rotation () Get the graph rotation of the graph :return: the graph rotation of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 50 51 52 53 54 55 def get_graph_rotation ( self ) -> str : \"\"\" Get the graph rotation of the graph :return: the graph rotation of the graph \"\"\" return self . get_metadata ()[ self . graph_rotation_key ] get_graph_source_url () Get the datasource of the graph :return: the datasource of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 43 44 45 46 47 48 def get_graph_source_url ( self ) -> str : \"\"\" Get the datasource of the graph :return: the datasource of the graph \"\"\" return self . get_metadata ()[ self . source_url_key ] get_last_graph_version () Get the current last version of the graph :return: the graph last version Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 29 30 31 32 33 34 def get_last_graph_version ( self ) -> str : \"\"\" Get the current last version of the graph :return: the graph last version \"\"\" return self . get_metadata ()[ self . last_version_key ] get_last_modified_date () Get the last modified date of the graph :return: the last modified date of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 57 58 59 60 61 62 63 def get_last_modified_date ( self ) -> datetime : \"\"\" Get the last modified date of the graph :return: the last modified date of the graph \"\"\" metadata_last_version = self . get_metadata ()[ self . last_modified_date_key ] return ModelUtil . convert_str_to_datetime ( metadata_last_version ) get_metadata () Get the metadata of the graph :return: the dict containing all graph metadata Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 22 23 24 25 26 27 def get_metadata ( self ) -> dict : \"\"\" Get the metadata of the graph :return: the dict containing all graph metadata \"\"\" return self . r . hgetall ( self . metadata_key ) set_all_metadata ( metadata ) Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def set_all_metadata ( self , metadata : dict ): \"\"\" Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) new_version = int ( metadata [ self . last_version_key ]) if new_version > current_version : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) else : raise Exception ( f \"The current version { current_version } is equal or greater than the version to set: { new_version } \" ) else : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) set_graph_rotation ( graph_rotation ) Set the graph rotation of the graph :param graph_rotation the graph rotation Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 124 125 126 127 128 129 130 131 def set_graph_rotation ( self , graph_rotation : int ): \"\"\" Set the graph rotation of the graph :param graph_rotation the graph rotation \"\"\" self . r . hset ( self . metadata_key , self . graph_rotation_key , str ( graph_rotation )) logger . debug ( f \"Graph graph_rotation to set : { str ( graph_rotation ) } \" ) self . update_last_modified_date () set_graph_source_url ( graph_source_url ) Set the datasource of the graph :param graph_source_url the source url Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 115 116 117 118 119 120 121 122 def set_graph_source_url ( self , graph_source_url : str ): \"\"\" Set the datasource of the graph :param graph_source_url the source url \"\"\" self . r . hset ( self . metadata_key , self . source_url_key , graph_source_url ) logger . debug ( f \"Graph source_url to set : { str ( graph_source_url ) } \" ) self . update_last_modified_date () set_last_graph_version ( last_graph_version ) Set the current last version of the graph :param last_graph_version the new version Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 106 107 108 109 110 111 112 113 def set_last_graph_version ( self , last_graph_version : int ): \"\"\" Set the current last version of the graph :param last_graph_version the new version \"\"\" self . r . hset ( self . metadata_key , self . last_version_key , str ( last_graph_version )) logger . debug ( f \"Graph last_graph_version to set : { str ( last_graph_version ) } \" ) self . update_last_modified_date () set_metadata ( last_graph_version , graph_source_url , graph_rotation ) Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_metadata ( self , last_graph_version : int , graph_source_url : str , graph_rotation : int ) -> dict : \"\"\" Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one \"\"\" metadata = { self . last_version_key : str ( last_graph_version ), self . graph_name_key : self . name , self . source_url_key : graph_source_url , self . graph_rotation_key : str ( graph_rotation ), self . last_modified_date_key : ModelUtil . convert_datetime_to_str ( datetime . utcnow ()) } logger . debug ( f \"Metatadata to set : { metadata } \" ) self . set_all_metadata ( metadata = metadata ) update_last_modified_date () Update the last modified date of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 133 134 135 136 137 def update_last_modified_date ( self ): \"\"\" Update the last modified date of the graph \"\"\" self . r . hset ( self . metadata_key , self . last_modified_date_key , ModelUtil . convert_datetime_to_str ( datetime . utcnow ())) update_last_version () Update the last version of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 139 140 141 142 143 144 145 146 147 148 149 150 151 def update_last_version ( self ): \"\"\" Update the last version of the graph \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) current_version += 1 self . set_last_graph_version ( str ( current_version )) self . update_last_modified_date () else : self . set_last_graph_version ( \"0\" ) self . update_last_modified_date ()","title":"model_metadata"},{"location":"references/Modelops/core/io/model_metadata/#cosmotech_acceleration_librarymodelopscoreiomodel_metadata","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata","text":"Bases: RedisHandler Model Metadata management class for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 class ModelMetadata ( RedisHandler ): \"\"\" Model Metadata management class for cached data \"\"\" last_modified_date_key = \"lastModifiedDate\" last_version_key = \"lastVersion\" source_url_key = \"adtUrl\" graph_name_key = \"graphName\" graph_rotation_key = \"graphRotation\" def get_metadata ( self ) -> dict : \"\"\" Get the metadata of the graph :return: the dict containing all graph metadata \"\"\" return self . r . hgetall ( self . metadata_key ) def get_last_graph_version ( self ) -> str : \"\"\" Get the current last version of the graph :return: the graph last version \"\"\" return self . get_metadata ()[ self . last_version_key ] def get_graph_name ( self ) -> str : \"\"\" Get the graph's name :return: the graph's name \"\"\" return self . name def get_graph_source_url ( self ) -> str : \"\"\" Get the datasource of the graph :return: the datasource of the graph \"\"\" return self . get_metadata ()[ self . source_url_key ] def get_graph_rotation ( self ) -> str : \"\"\" Get the graph rotation of the graph :return: the graph rotation of the graph \"\"\" return self . get_metadata ()[ self . graph_rotation_key ] def get_last_modified_date ( self ) -> datetime : \"\"\" Get the last modified date of the graph :return: the last modified date of the graph \"\"\" metadata_last_version = self . get_metadata ()[ self . last_modified_date_key ] return ModelUtil . convert_str_to_datetime ( metadata_last_version ) def set_all_metadata ( self , metadata : dict ): \"\"\" Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) new_version = int ( metadata [ self . last_version_key ]) if new_version > current_version : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) else : raise Exception ( f \"The current version { current_version } is equal or greater than the version to set: { new_version } \" ) else : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) def set_metadata ( self , last_graph_version : int , graph_source_url : str , graph_rotation : int ) -> dict : \"\"\" Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one \"\"\" metadata = { self . last_version_key : str ( last_graph_version ), self . graph_name_key : self . name , self . source_url_key : graph_source_url , self . graph_rotation_key : str ( graph_rotation ), self . last_modified_date_key : ModelUtil . convert_datetime_to_str ( datetime . utcnow ()) } logger . debug ( f \"Metatadata to set : { metadata } \" ) self . set_all_metadata ( metadata = metadata ) def set_last_graph_version ( self , last_graph_version : int ): \"\"\" Set the current last version of the graph :param last_graph_version the new version \"\"\" self . r . hset ( self . metadata_key , self . last_version_key , str ( last_graph_version )) logger . debug ( f \"Graph last_graph_version to set : { str ( last_graph_version ) } \" ) self . update_last_modified_date () def set_graph_source_url ( self , graph_source_url : str ): \"\"\" Set the datasource of the graph :param graph_source_url the source url \"\"\" self . r . hset ( self . metadata_key , self . source_url_key , graph_source_url ) logger . debug ( f \"Graph source_url to set : { str ( graph_source_url ) } \" ) self . update_last_modified_date () def set_graph_rotation ( self , graph_rotation : int ): \"\"\" Set the graph rotation of the graph :param graph_rotation the graph rotation \"\"\" self . r . hset ( self . metadata_key , self . graph_rotation_key , str ( graph_rotation )) logger . debug ( f \"Graph graph_rotation to set : { str ( graph_rotation ) } \" ) self . update_last_modified_date () def update_last_modified_date ( self ): \"\"\" Update the last modified date of the graph \"\"\" self . r . hset ( self . metadata_key , self . last_modified_date_key , ModelUtil . convert_datetime_to_str ( datetime . utcnow ())) def update_last_version ( self ): \"\"\" Update the last version of the graph \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) current_version += 1 self . set_last_graph_version ( str ( current_version )) self . update_last_modified_date () else : self . set_last_graph_version ( \"0\" ) self . update_last_modified_date ()","title":"ModelMetadata"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_graph_name","text":"Get the graph's name :return: the graph's name Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 36 37 38 39 40 41 def get_graph_name ( self ) -> str : \"\"\" Get the graph's name :return: the graph's name \"\"\" return self . name","title":"get_graph_name()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_graph_rotation","text":"Get the graph rotation of the graph :return: the graph rotation of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 50 51 52 53 54 55 def get_graph_rotation ( self ) -> str : \"\"\" Get the graph rotation of the graph :return: the graph rotation of the graph \"\"\" return self . get_metadata ()[ self . graph_rotation_key ]","title":"get_graph_rotation()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_graph_source_url","text":"Get the datasource of the graph :return: the datasource of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 43 44 45 46 47 48 def get_graph_source_url ( self ) -> str : \"\"\" Get the datasource of the graph :return: the datasource of the graph \"\"\" return self . get_metadata ()[ self . source_url_key ]","title":"get_graph_source_url()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_last_graph_version","text":"Get the current last version of the graph :return: the graph last version Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 29 30 31 32 33 34 def get_last_graph_version ( self ) -> str : \"\"\" Get the current last version of the graph :return: the graph last version \"\"\" return self . get_metadata ()[ self . last_version_key ]","title":"get_last_graph_version()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_last_modified_date","text":"Get the last modified date of the graph :return: the last modified date of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 57 58 59 60 61 62 63 def get_last_modified_date ( self ) -> datetime : \"\"\" Get the last modified date of the graph :return: the last modified date of the graph \"\"\" metadata_last_version = self . get_metadata ()[ self . last_modified_date_key ] return ModelUtil . convert_str_to_datetime ( metadata_last_version )","title":"get_last_modified_date()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.get_metadata","text":"Get the metadata of the graph :return: the dict containing all graph metadata Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 22 23 24 25 26 27 def get_metadata ( self ) -> dict : \"\"\" Get the metadata of the graph :return: the dict containing all graph metadata \"\"\" return self . r . hgetall ( self . metadata_key )","title":"get_metadata()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.set_all_metadata","text":"Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def set_all_metadata ( self , metadata : dict ): \"\"\" Set the metadata of the graph :param metadata the metadata to set :raise Exception if the current version is greater than the new one \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) new_version = int ( metadata [ self . last_version_key ]) if new_version > current_version : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata ) else : raise Exception ( f \"The current version { current_version } is equal or greater than the version to set: { new_version } \" ) else : logger . debug ( f \"Metatadata to set : { metadata } \" ) self . r . hmset ( self . metadata_key , metadata )","title":"set_all_metadata()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.set_graph_rotation","text":"Set the graph rotation of the graph :param graph_rotation the graph rotation Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 124 125 126 127 128 129 130 131 def set_graph_rotation ( self , graph_rotation : int ): \"\"\" Set the graph rotation of the graph :param graph_rotation the graph rotation \"\"\" self . r . hset ( self . metadata_key , self . graph_rotation_key , str ( graph_rotation )) logger . debug ( f \"Graph graph_rotation to set : { str ( graph_rotation ) } \" ) self . update_last_modified_date ()","title":"set_graph_rotation()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.set_graph_source_url","text":"Set the datasource of the graph :param graph_source_url the source url Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 115 116 117 118 119 120 121 122 def set_graph_source_url ( self , graph_source_url : str ): \"\"\" Set the datasource of the graph :param graph_source_url the source url \"\"\" self . r . hset ( self . metadata_key , self . source_url_key , graph_source_url ) logger . debug ( f \"Graph source_url to set : { str ( graph_source_url ) } \" ) self . update_last_modified_date ()","title":"set_graph_source_url()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.set_last_graph_version","text":"Set the current last version of the graph :param last_graph_version the new version Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 106 107 108 109 110 111 112 113 def set_last_graph_version ( self , last_graph_version : int ): \"\"\" Set the current last version of the graph :param last_graph_version the new version \"\"\" self . r . hset ( self . metadata_key , self . last_version_key , str ( last_graph_version )) logger . debug ( f \"Graph last_graph_version to set : { str ( last_graph_version ) } \" ) self . update_last_modified_date ()","title":"set_last_graph_version()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.set_metadata","text":"Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def set_metadata ( self , last_graph_version : int , graph_source_url : str , graph_rotation : int ) -> dict : \"\"\" Set the metadata of the graph :param last_graph_version the new version :param graph_source_url the source url :param graph_rotation the graph rotation :return the metadata set :raise Exception if the current version is greater than the new one \"\"\" metadata = { self . last_version_key : str ( last_graph_version ), self . graph_name_key : self . name , self . source_url_key : graph_source_url , self . graph_rotation_key : str ( graph_rotation ), self . last_modified_date_key : ModelUtil . convert_datetime_to_str ( datetime . utcnow ()) } logger . debug ( f \"Metatadata to set : { metadata } \" ) self . set_all_metadata ( metadata = metadata )","title":"set_metadata()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.update_last_modified_date","text":"Update the last modified date of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 133 134 135 136 137 def update_last_modified_date ( self ): \"\"\" Update the last modified date of the graph \"\"\" self . r . hset ( self . metadata_key , self . last_modified_date_key , ModelUtil . convert_datetime_to_str ( datetime . utcnow ()))","title":"update_last_modified_date()"},{"location":"references/Modelops/core/io/model_metadata/#CosmoTech_Acceleration_Library.Modelops.core.io.model_metadata.ModelMetadata.update_last_version","text":"Update the last version of the graph Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_metadata.py 139 140 141 142 143 144 145 146 147 148 149 150 151 def update_last_version ( self ): \"\"\" Update the last version of the graph \"\"\" current_metadata = self . get_metadata () if self . last_version_key in current_metadata : current_version = int ( self . get_last_graph_version ()) current_version += 1 self . set_last_graph_version ( str ( current_version )) self . update_last_modified_date () else : self . set_last_graph_version ( \"0\" ) self . update_last_modified_date ()","title":"update_last_version()"},{"location":"references/Modelops/core/io/model_reader/","text":"CosmoTech_Acceleration_Library.Modelops.core.io.model_reader ModelReader Bases: VersionedGraphHandler Model Reader for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ModelReader ( VersionedGraphHandler ): \"\"\" Model Reader for cached data \"\"\" def get_twin_types ( self ) -> list : \"\"\" Get twin types :return: twin types list \"\"\" return [ item for sublist in self . graph . labels () for item in sublist ] def get_twins_by_type ( self , twin_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter \"\"\" twin_query = f 'MATCH (node: { twin_type } ) RETURN node' if limit != 0 : twin_query = f ' { twin_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { twin_query } \" ) return self . graph . query ( twin_query , read_only = True ) def get_twin_properties_by_type ( self , twin_type : str ) -> list : \"\"\" Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list \"\"\" result = [] twin_result = self . get_twins_by_type ( twin_type , 1 ) result_set = twin_result . result_set if result_set and result_set [ 0 ]: for key , val in result_set [ 0 ][ 0 ] . properties . items (): if str ( key ) != ModelUtil . dt_id_key : result . append ( str ( key )) else : result . append ( ModelUtil . id_key ) return result def get_relationship_types ( self ) -> list : \"\"\" Get relationship types :return: relationship types list \"\"\" return [ item for sublist in self . graph . relationship_types () for item in sublist ] def get_relationships_by_type ( self , relationship_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter \"\"\" rel_query = f 'MATCH (n)-[relation: { relationship_type } ]->(m) RETURN n.dt_id as { ModelUtil . source_key } , ' \\ f 'm.dt_id as { ModelUtil . target_key } , relation' if limit != 0 : rel_query = f ' { rel_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { rel_query } \" ) return self . graph . query ( rel_query , read_only = True ) def get_relationship_properties_by_type ( self , relationship_type : str ) -> list : \"\"\" Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list \"\"\" result = [ ModelUtil . source_key , ModelUtil . target_key ] relationship_result = self . get_relationships_by_type ( relationship_type , 1 ) result_set = relationship_result . result_set if result_set and result_set [ 0 ]: # relationship for key , val in result_set [ 0 ][ 2 ] . properties . items (): if not str ( key ) in result : if str ( key ) == ModelUtil . dt_id_key : result . append ( ModelUtil . id_key ) elif str ( key ) != ModelUtil . src_key and str ( key ) != ModelUtil . dest_key : result . append ( str ( key )) return result def query ( self , query : str , params : dict = None , timeout : int = None , read_only : bool = False ) -> QueryResult : \"\"\" Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query \"\"\" logger . debug ( f \"Query : { query } \" ) return self . graph . query ( q = query , params = params , timeout = timeout , read_only = read_only ) def exists ( self , key ) -> bool : \"\"\" Check if a key exists in Redis :param key: the key :return: True if exists else False \"\"\" return False if self . r . exists ( key ) == 0 else True exists ( key ) Check if a key exists in Redis :param key: the key :return: True if exists else False Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 108 109 110 111 112 113 114 def exists ( self , key ) -> bool : \"\"\" Check if a key exists in Redis :param key: the key :return: True if exists else False \"\"\" return False if self . r . exists ( key ) == 0 else True get_relationship_properties_by_type ( relationship_type ) Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def get_relationship_properties_by_type ( self , relationship_type : str ) -> list : \"\"\" Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list \"\"\" result = [ ModelUtil . source_key , ModelUtil . target_key ] relationship_result = self . get_relationships_by_type ( relationship_type , 1 ) result_set = relationship_result . result_set if result_set and result_set [ 0 ]: # relationship for key , val in result_set [ 0 ][ 2 ] . properties . items (): if not str ( key ) in result : if str ( key ) == ModelUtil . dt_id_key : result . append ( ModelUtil . id_key ) elif str ( key ) != ModelUtil . src_key and str ( key ) != ModelUtil . dest_key : result . append ( str ( key )) return result get_relationship_types () Get relationship types :return: relationship types list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 55 56 57 58 59 60 def get_relationship_types ( self ) -> list : \"\"\" Get relationship types :return: relationship types list \"\"\" return [ item for sublist in self . graph . relationship_types () for item in sublist ] get_relationships_by_type ( relationship_type , limit = 0 ) Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 74 def get_relationships_by_type ( self , relationship_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter \"\"\" rel_query = f 'MATCH (n)-[relation: { relationship_type } ]->(m) RETURN n.dt_id as { ModelUtil . source_key } , ' \\ f 'm.dt_id as { ModelUtil . target_key } , relation' if limit != 0 : rel_query = f ' { rel_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { rel_query } \" ) return self . graph . query ( rel_query , read_only = True ) get_twin_properties_by_type ( twin_type ) Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def get_twin_properties_by_type ( self , twin_type : str ) -> list : \"\"\" Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list \"\"\" result = [] twin_result = self . get_twins_by_type ( twin_type , 1 ) result_set = twin_result . result_set if result_set and result_set [ 0 ]: for key , val in result_set [ 0 ][ 0 ] . properties . items (): if str ( key ) != ModelUtil . dt_id_key : result . append ( str ( key )) else : result . append ( ModelUtil . id_key ) return result get_twin_types () Get twin types :return: twin types list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 17 18 19 20 21 22 def get_twin_types ( self ) -> list : \"\"\" Get twin types :return: twin types list \"\"\" return [ item for sublist in self . graph . labels () for item in sublist ] get_twins_by_type ( twin_type , limit = 0 ) Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 24 25 26 27 28 29 30 31 32 33 34 35 def get_twins_by_type ( self , twin_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter \"\"\" twin_query = f 'MATCH (node: { twin_type } ) RETURN node' if limit != 0 : twin_query = f ' { twin_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { twin_query } \" ) return self . graph . query ( twin_query , read_only = True ) query ( query , params = None , timeout = None , read_only = False ) Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 96 97 98 99 100 101 102 103 104 105 106 def query ( self , query : str , params : dict = None , timeout : int = None , read_only : bool = False ) -> QueryResult : \"\"\" Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query \"\"\" logger . debug ( f \"Query : { query } \" ) return self . graph . query ( q = query , params = params , timeout = timeout , read_only = read_only )","title":"model_reader"},{"location":"references/Modelops/core/io/model_reader/#cosmotech_acceleration_librarymodelopscoreiomodel_reader","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_reader"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader","text":"Bases: VersionedGraphHandler Model Reader for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 class ModelReader ( VersionedGraphHandler ): \"\"\" Model Reader for cached data \"\"\" def get_twin_types ( self ) -> list : \"\"\" Get twin types :return: twin types list \"\"\" return [ item for sublist in self . graph . labels () for item in sublist ] def get_twins_by_type ( self , twin_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter \"\"\" twin_query = f 'MATCH (node: { twin_type } ) RETURN node' if limit != 0 : twin_query = f ' { twin_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { twin_query } \" ) return self . graph . query ( twin_query , read_only = True ) def get_twin_properties_by_type ( self , twin_type : str ) -> list : \"\"\" Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list \"\"\" result = [] twin_result = self . get_twins_by_type ( twin_type , 1 ) result_set = twin_result . result_set if result_set and result_set [ 0 ]: for key , val in result_set [ 0 ][ 0 ] . properties . items (): if str ( key ) != ModelUtil . dt_id_key : result . append ( str ( key )) else : result . append ( ModelUtil . id_key ) return result def get_relationship_types ( self ) -> list : \"\"\" Get relationship types :return: relationship types list \"\"\" return [ item for sublist in self . graph . relationship_types () for item in sublist ] def get_relationships_by_type ( self , relationship_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter \"\"\" rel_query = f 'MATCH (n)-[relation: { relationship_type } ]->(m) RETURN n.dt_id as { ModelUtil . source_key } , ' \\ f 'm.dt_id as { ModelUtil . target_key } , relation' if limit != 0 : rel_query = f ' { rel_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { rel_query } \" ) return self . graph . query ( rel_query , read_only = True ) def get_relationship_properties_by_type ( self , relationship_type : str ) -> list : \"\"\" Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list \"\"\" result = [ ModelUtil . source_key , ModelUtil . target_key ] relationship_result = self . get_relationships_by_type ( relationship_type , 1 ) result_set = relationship_result . result_set if result_set and result_set [ 0 ]: # relationship for key , val in result_set [ 0 ][ 2 ] . properties . items (): if not str ( key ) in result : if str ( key ) == ModelUtil . dt_id_key : result . append ( ModelUtil . id_key ) elif str ( key ) != ModelUtil . src_key and str ( key ) != ModelUtil . dest_key : result . append ( str ( key )) return result def query ( self , query : str , params : dict = None , timeout : int = None , read_only : bool = False ) -> QueryResult : \"\"\" Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query \"\"\" logger . debug ( f \"Query : { query } \" ) return self . graph . query ( q = query , params = params , timeout = timeout , read_only = read_only ) def exists ( self , key ) -> bool : \"\"\" Check if a key exists in Redis :param key: the key :return: True if exists else False \"\"\" return False if self . r . exists ( key ) == 0 else True","title":"ModelReader"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.exists","text":"Check if a key exists in Redis :param key: the key :return: True if exists else False Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 108 109 110 111 112 113 114 def exists ( self , key ) -> bool : \"\"\" Check if a key exists in Redis :param key: the key :return: True if exists else False \"\"\" return False if self . r . exists ( key ) == 0 else True","title":"exists()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_properties_by_type","text":"Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 def get_relationship_properties_by_type ( self , relationship_type : str ) -> list : \"\"\" Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list \"\"\" result = [ ModelUtil . source_key , ModelUtil . target_key ] relationship_result = self . get_relationships_by_type ( relationship_type , 1 ) result_set = relationship_result . result_set if result_set and result_set [ 0 ]: # relationship for key , val in result_set [ 0 ][ 2 ] . properties . items (): if not str ( key ) in result : if str ( key ) == ModelUtil . dt_id_key : result . append ( ModelUtil . id_key ) elif str ( key ) != ModelUtil . src_key and str ( key ) != ModelUtil . dest_key : result . append ( str ( key )) return result","title":"get_relationship_properties_by_type()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_types","text":"Get relationship types :return: relationship types list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 55 56 57 58 59 60 def get_relationship_types ( self ) -> list : \"\"\" Get relationship types :return: relationship types list \"\"\" return [ item for sublist in self . graph . relationship_types () for item in sublist ]","title":"get_relationship_types()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationships_by_type","text":"Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 62 63 64 65 66 67 68 69 70 71 72 73 74 def get_relationships_by_type ( self , relationship_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter \"\"\" rel_query = f 'MATCH (n)-[relation: { relationship_type } ]->(m) RETURN n.dt_id as { ModelUtil . source_key } , ' \\ f 'm.dt_id as { ModelUtil . target_key } , relation' if limit != 0 : rel_query = f ' { rel_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { rel_query } \" ) return self . graph . query ( rel_query , read_only = True )","title":"get_relationships_by_type()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_properties_by_type","text":"Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def get_twin_properties_by_type ( self , twin_type : str ) -> list : \"\"\" Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list \"\"\" result = [] twin_result = self . get_twins_by_type ( twin_type , 1 ) result_set = twin_result . result_set if result_set and result_set [ 0 ]: for key , val in result_set [ 0 ][ 0 ] . properties . items (): if str ( key ) != ModelUtil . dt_id_key : result . append ( str ( key )) else : result . append ( ModelUtil . id_key ) return result","title":"get_twin_properties_by_type()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_types","text":"Get twin types :return: twin types list Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 17 18 19 20 21 22 def get_twin_types ( self ) -> list : \"\"\" Get twin types :return: twin types list \"\"\" return [ item for sublist in self . graph . labels () for item in sublist ]","title":"get_twin_types()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twins_by_type","text":"Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 24 25 26 27 28 29 30 31 32 33 34 35 def get_twins_by_type ( self , twin_type : str , limit : int = 0 ) -> QueryResult : \"\"\" Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter \"\"\" twin_query = f 'MATCH (node: { twin_type } ) RETURN node' if limit != 0 : twin_query = f ' { twin_query } LIMIT { str ( limit ) } ' logger . debug ( f \"Query : { twin_query } \" ) return self . graph . query ( twin_query , read_only = True )","title":"get_twins_by_type()"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.query","text":"Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py 96 97 98 99 100 101 102 103 104 105 106 def query ( self , query : str , params : dict = None , timeout : int = None , read_only : bool = False ) -> QueryResult : \"\"\" Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query \"\"\" logger . debug ( f \"Query : { query } \" ) return self . graph . query ( q = query , params = params , timeout = timeout , read_only = read_only )","title":"query()"},{"location":"references/Modelops/core/io/model_writer/","text":"CosmoTech_Acceleration_Library.Modelops.core.io.model_writer ModelWriter Bases: RotatedGraphHandler Model Writer for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class ModelWriter ( RotatedGraphHandler ): \"\"\" Model Writer for cached data \"\"\" @update_last_modified_date def create_twin ( self , twin_type : str , properties : dict ): \"\"\" Create a twin :param twin_type: the twin type :param properties: the twin properties \"\"\" create_query = ModelUtil . create_twin_query ( twin_type , properties ) logger . debug ( f \"Query: { create_query } \" ) self . graph . query ( create_query ) @update_last_modified_date def create_relationship ( self , relationship_type : str , properties : dict ): \"\"\" Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties \"\"\" create_rel = ModelUtil . create_relationship_query ( relationship_type , properties ) logger . debug ( f \"Query: { create_rel } \" ) self . graph . query ( create_rel ) create_relationship ( relationship_type , properties ) Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 27 28 29 30 31 32 33 34 35 36 @update_last_modified_date def create_relationship ( self , relationship_type : str , properties : dict ): \"\"\" Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties \"\"\" create_rel = ModelUtil . create_relationship_query ( relationship_type , properties ) logger . debug ( f \"Query: { create_rel } \" ) self . graph . query ( create_rel ) create_twin ( twin_type , properties ) Create a twin :param twin_type: the twin type :param properties: the twin properties Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 16 17 18 19 20 21 22 23 24 25 @update_last_modified_date def create_twin ( self , twin_type : str , properties : dict ): \"\"\" Create a twin :param twin_type: the twin type :param properties: the twin properties \"\"\" create_query = ModelUtil . create_twin_query ( twin_type , properties ) logger . debug ( f \"Query: { create_query } \" ) self . graph . query ( create_query )","title":"model_writer"},{"location":"references/Modelops/core/io/model_writer/#cosmotech_acceleration_librarymodelopscoreiomodel_writer","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_writer"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter","text":"Bases: RotatedGraphHandler Model Writer for cached data Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class ModelWriter ( RotatedGraphHandler ): \"\"\" Model Writer for cached data \"\"\" @update_last_modified_date def create_twin ( self , twin_type : str , properties : dict ): \"\"\" Create a twin :param twin_type: the twin type :param properties: the twin properties \"\"\" create_query = ModelUtil . create_twin_query ( twin_type , properties ) logger . debug ( f \"Query: { create_query } \" ) self . graph . query ( create_query ) @update_last_modified_date def create_relationship ( self , relationship_type : str , properties : dict ): \"\"\" Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties \"\"\" create_rel = ModelUtil . create_relationship_query ( relationship_type , properties ) logger . debug ( f \"Query: { create_rel } \" ) self . graph . query ( create_rel )","title":"ModelWriter"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_relationship","text":"Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 27 28 29 30 31 32 33 34 35 36 @update_last_modified_date def create_relationship ( self , relationship_type : str , properties : dict ): \"\"\" Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties \"\"\" create_rel = ModelUtil . create_relationship_query ( relationship_type , properties ) logger . debug ( f \"Query: { create_rel } \" ) self . graph . query ( create_rel )","title":"create_relationship()"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_twin","text":"Create a twin :param twin_type: the twin type :param properties: the twin properties Source code in CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py 16 17 18 19 20 21 22 23 24 25 @update_last_modified_date def create_twin ( self , twin_type : str , properties : dict ): \"\"\" Create a twin :param twin_type: the twin type :param properties: the twin properties \"\"\" create_query = ModelUtil . create_twin_query ( twin_type , properties ) logger . debug ( f \"Query: { create_query } \" ) self . graph . query ( create_query )","title":"create_twin()"},{"location":"references/Modelops/core/utils/model_util/","text":"CosmoTech_Acceleration_Library.Modelops.core.utils.model_util ModelUtil Utility class for Redis management Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 class ModelUtil : \"\"\" Utility class for Redis management \"\"\" # ADT variables source_key = 'source' target_key = 'target' id_key = 'id' # Redis/Csm variables src_key = 'src' dest_key = 'dest' dt_id_key = 'dt_id' @staticmethod def dict_to_cypher_parameters ( parameters : dict ) -> str : \"\"\" Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters \"\"\" cypher_list = [] for key , value in parameters . items (): cypher_list . append ( f \" { key } : { stringify_param_value ( value ) } \" ) joined_list = ', ' . join ( cypher_list ) return '{' + joined_list + '}' @staticmethod def create_index_query ( entity_name : str , entity_property_name : str ) -> str : \"\"\" Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query \"\"\" return f \"CREATE INDEX ON : { entity_name } ( { entity_property_name } )\" @staticmethod def create_twin_query ( twin_type : str , properties : dict ) -> str : \"\"\" Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query \"\"\" if ModelUtil . dt_id_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"CREATE (: { twin_type } { cypher_params } )\" raise Exception ( f \"When you create a twin, you should define at least { ModelUtil . dt_id_key } properties \" ) @staticmethod def create_relationship_query ( relationship_type : str , properties : dict ) -> str : \"\"\" Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query \"\"\" if ModelUtil . src_key in properties and ModelUtil . dest_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"MATCH (n), (m) WHERE n.dt_id = ' { properties . get ( ModelUtil . src_key ) } ' \" \\ f \"AND m.dt_id = ' { properties . get ( ModelUtil . dest_key ) } ' \" \\ f \"CREATE (n)-[r: { relationship_type } { cypher_params } ]->(m) RETURN r\" raise Exception ( f \"When you create a relationship, you should define at least { ModelUtil . src_key } and { ModelUtil . dest_key } properties \" ) @staticmethod def dict_to_json ( obj : dict ) -> str : \"\"\" Transform a dict to a json string :param obj: the dict :return: the json string corresponding \"\"\" return json . dumps ( obj , indent = 2 ) @staticmethod def result_set_to_json ( query_result : QueryResult ) -> list : \"\"\" Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list \"\"\" flattened_headers = [ item for sublist in query_result . header for item in sublist ] headers_without_integers = [ x for x in flattened_headers if not isinstance ( x , int )] result_list = [] for result in query_result . result_set : result_dict = {} for i in range ( len ( headers_without_integers )): obj = result [ i ] if isinstance ( obj , Edge ) or isinstance ( obj , Node ): result_dict [ headers_without_integers [ i ]] = obj . properties else : result_dict [ headers_without_integers [ i ]] = obj result_list . append ( ModelUtil . dict_to_json ( result_dict )) return result_list @staticmethod def print_query_result ( query_result : QueryResult ) -> None : \"\"\" Pretty print a QueryResult :param query_result: the QueryResult to print \"\"\" list_to_print = ModelUtil . result_set_to_json ( query_result ) for result in list_to_print : print ( result ) @staticmethod def convert_datetime_to_str ( date : datetime ) -> str : \"\"\" Convert a datetime to a str :param date: the datetime :return: the string representing the datetime \"\"\" return date . strftime ( '%Y/%m/ %d - %H:%M:%S' ) @staticmethod def convert_str_to_datetime ( date_str : str ) -> datetime : \"\"\" Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str \"\"\" date_time_obj = datetime . strptime ( date_str , '%Y/%m/ %d - %H:%M:%S' ) return date_time_obj @staticmethod def build_graph_version_name ( graph_name : str , version : int ) -> str : \"\"\" Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name \"\"\" return graph_name + \":\" + str ( version ) @staticmethod def build_graph_key_pattern ( graph_name : str ) -> str : return graph_name + \":*\" build_graph_version_name ( graph_name , version ) staticmethod Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 141 142 143 144 145 146 147 148 149 @staticmethod def build_graph_version_name ( graph_name : str , version : int ) -> str : \"\"\" Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name \"\"\" return graph_name + \":\" + str ( version ) convert_datetime_to_str ( date ) staticmethod Convert a datetime to a str :param date: the datetime :return: the string representing the datetime Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 122 123 124 125 126 127 128 129 @staticmethod def convert_datetime_to_str ( date : datetime ) -> str : \"\"\" Convert a datetime to a str :param date: the datetime :return: the string representing the datetime \"\"\" return date . strftime ( '%Y/%m/ %d - %H:%M:%S' ) convert_str_to_datetime ( date_str ) staticmethod Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 131 132 133 134 135 136 137 138 139 @staticmethod def convert_str_to_datetime ( date_str : str ) -> datetime : \"\"\" Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str \"\"\" date_time_obj = datetime . strptime ( date_str , '%Y/%m/ %d - %H:%M:%S' ) return date_time_obj create_index_query ( entity_name , entity_property_name ) staticmethod Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 41 42 43 44 45 46 47 48 49 @staticmethod def create_index_query ( entity_name : str , entity_property_name : str ) -> str : \"\"\" Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query \"\"\" return f \"CREATE INDEX ON : { entity_name } ( { entity_property_name } )\" create_relationship_query ( relationship_type , properties ) staticmethod Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @staticmethod def create_relationship_query ( relationship_type : str , properties : dict ) -> str : \"\"\" Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query \"\"\" if ModelUtil . src_key in properties and ModelUtil . dest_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"MATCH (n), (m) WHERE n.dt_id = ' { properties . get ( ModelUtil . src_key ) } ' \" \\ f \"AND m.dt_id = ' { properties . get ( ModelUtil . dest_key ) } ' \" \\ f \"CREATE (n)-[r: { relationship_type } { cypher_params } ]->(m) RETURN r\" raise Exception ( f \"When you create a relationship, you should define at least { ModelUtil . src_key } and { ModelUtil . dest_key } properties \" ) create_twin_query ( twin_type , properties ) staticmethod Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def create_twin_query ( twin_type : str , properties : dict ) -> str : \"\"\" Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query \"\"\" if ModelUtil . dt_id_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"CREATE (: { twin_type } { cypher_params } )\" raise Exception ( f \"When you create a twin, you should define at least { ModelUtil . dt_id_key } properties \" ) dict_to_cypher_parameters ( parameters ) staticmethod Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 27 28 29 30 31 32 33 34 35 36 37 38 39 @staticmethod def dict_to_cypher_parameters ( parameters : dict ) -> str : \"\"\" Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters \"\"\" cypher_list = [] for key , value in parameters . items (): cypher_list . append ( f \" { key } : { stringify_param_value ( value ) } \" ) joined_list = ', ' . join ( cypher_list ) return '{' + joined_list + '}' dict_to_json ( obj ) staticmethod Transform a dict to a json string :param obj: the dict :return: the json string corresponding Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 82 83 84 85 86 87 88 89 @staticmethod def dict_to_json ( obj : dict ) -> str : \"\"\" Transform a dict to a json string :param obj: the dict :return: the json string corresponding \"\"\" return json . dumps ( obj , indent = 2 ) print_query_result ( query_result ) staticmethod Pretty print a QueryResult :param query_result: the QueryResult to print Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 112 113 114 115 116 117 118 119 120 @staticmethod def print_query_result ( query_result : QueryResult ) -> None : \"\"\" Pretty print a QueryResult :param query_result: the QueryResult to print \"\"\" list_to_print = ModelUtil . result_set_to_json ( query_result ) for result in list_to_print : print ( result ) result_set_to_json ( query_result ) staticmethod Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @staticmethod def result_set_to_json ( query_result : QueryResult ) -> list : \"\"\" Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list \"\"\" flattened_headers = [ item for sublist in query_result . header for item in sublist ] headers_without_integers = [ x for x in flattened_headers if not isinstance ( x , int )] result_list = [] for result in query_result . result_set : result_dict = {} for i in range ( len ( headers_without_integers )): obj = result [ i ] if isinstance ( obj , Edge ) or isinstance ( obj , Node ): result_dict [ headers_without_integers [ i ]] = obj . properties else : result_dict [ headers_without_integers [ i ]] = obj result_list . append ( ModelUtil . dict_to_json ( result_dict )) return result_list","title":"model_util"},{"location":"references/Modelops/core/utils/model_util/#cosmotech_acceleration_librarymodelopscoreutilsmodel_util","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.model_util"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil","text":"Utility class for Redis management Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 class ModelUtil : \"\"\" Utility class for Redis management \"\"\" # ADT variables source_key = 'source' target_key = 'target' id_key = 'id' # Redis/Csm variables src_key = 'src' dest_key = 'dest' dt_id_key = 'dt_id' @staticmethod def dict_to_cypher_parameters ( parameters : dict ) -> str : \"\"\" Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters \"\"\" cypher_list = [] for key , value in parameters . items (): cypher_list . append ( f \" { key } : { stringify_param_value ( value ) } \" ) joined_list = ', ' . join ( cypher_list ) return '{' + joined_list + '}' @staticmethod def create_index_query ( entity_name : str , entity_property_name : str ) -> str : \"\"\" Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query \"\"\" return f \"CREATE INDEX ON : { entity_name } ( { entity_property_name } )\" @staticmethod def create_twin_query ( twin_type : str , properties : dict ) -> str : \"\"\" Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query \"\"\" if ModelUtil . dt_id_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"CREATE (: { twin_type } { cypher_params } )\" raise Exception ( f \"When you create a twin, you should define at least { ModelUtil . dt_id_key } properties \" ) @staticmethod def create_relationship_query ( relationship_type : str , properties : dict ) -> str : \"\"\" Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query \"\"\" if ModelUtil . src_key in properties and ModelUtil . dest_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"MATCH (n), (m) WHERE n.dt_id = ' { properties . get ( ModelUtil . src_key ) } ' \" \\ f \"AND m.dt_id = ' { properties . get ( ModelUtil . dest_key ) } ' \" \\ f \"CREATE (n)-[r: { relationship_type } { cypher_params } ]->(m) RETURN r\" raise Exception ( f \"When you create a relationship, you should define at least { ModelUtil . src_key } and { ModelUtil . dest_key } properties \" ) @staticmethod def dict_to_json ( obj : dict ) -> str : \"\"\" Transform a dict to a json string :param obj: the dict :return: the json string corresponding \"\"\" return json . dumps ( obj , indent = 2 ) @staticmethod def result_set_to_json ( query_result : QueryResult ) -> list : \"\"\" Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list \"\"\" flattened_headers = [ item for sublist in query_result . header for item in sublist ] headers_without_integers = [ x for x in flattened_headers if not isinstance ( x , int )] result_list = [] for result in query_result . result_set : result_dict = {} for i in range ( len ( headers_without_integers )): obj = result [ i ] if isinstance ( obj , Edge ) or isinstance ( obj , Node ): result_dict [ headers_without_integers [ i ]] = obj . properties else : result_dict [ headers_without_integers [ i ]] = obj result_list . append ( ModelUtil . dict_to_json ( result_dict )) return result_list @staticmethod def print_query_result ( query_result : QueryResult ) -> None : \"\"\" Pretty print a QueryResult :param query_result: the QueryResult to print \"\"\" list_to_print = ModelUtil . result_set_to_json ( query_result ) for result in list_to_print : print ( result ) @staticmethod def convert_datetime_to_str ( date : datetime ) -> str : \"\"\" Convert a datetime to a str :param date: the datetime :return: the string representing the datetime \"\"\" return date . strftime ( '%Y/%m/ %d - %H:%M:%S' ) @staticmethod def convert_str_to_datetime ( date_str : str ) -> datetime : \"\"\" Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str \"\"\" date_time_obj = datetime . strptime ( date_str , '%Y/%m/ %d - %H:%M:%S' ) return date_time_obj @staticmethod def build_graph_version_name ( graph_name : str , version : int ) -> str : \"\"\" Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name \"\"\" return graph_name + \":\" + str ( version ) @staticmethod def build_graph_key_pattern ( graph_name : str ) -> str : return graph_name + \":*\"","title":"ModelUtil"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.build_graph_version_name","text":"Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 141 142 143 144 145 146 147 148 149 @staticmethod def build_graph_version_name ( graph_name : str , version : int ) -> str : \"\"\" Build versioned graph name :param graph_name: the graph name :param version: the version :return: the versioned graph name \"\"\" return graph_name + \":\" + str ( version )","title":"build_graph_version_name()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_datetime_to_str","text":"Convert a datetime to a str :param date: the datetime :return: the string representing the datetime Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 122 123 124 125 126 127 128 129 @staticmethod def convert_datetime_to_str ( date : datetime ) -> str : \"\"\" Convert a datetime to a str :param date: the datetime :return: the string representing the datetime \"\"\" return date . strftime ( '%Y/%m/ %d - %H:%M:%S' )","title":"convert_datetime_to_str()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_str_to_datetime","text":"Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 131 132 133 134 135 136 137 138 139 @staticmethod def convert_str_to_datetime ( date_str : str ) -> datetime : \"\"\" Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str \"\"\" date_time_obj = datetime . strptime ( date_str , '%Y/%m/ %d - %H:%M:%S' ) return date_time_obj","title":"convert_str_to_datetime()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_index_query","text":"Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 41 42 43 44 45 46 47 48 49 @staticmethod def create_index_query ( entity_name : str , entity_property_name : str ) -> str : \"\"\" Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name: the entity property name on which you want to define an index :return: the create index query \"\"\" return f \"CREATE INDEX ON : { entity_name } ( { entity_property_name } )\"","title":"create_index_query()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_relationship_query","text":"Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 @staticmethod def create_relationship_query ( relationship_type : str , properties : dict ) -> str : \"\"\" Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query \"\"\" if ModelUtil . src_key in properties and ModelUtil . dest_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"MATCH (n), (m) WHERE n.dt_id = ' { properties . get ( ModelUtil . src_key ) } ' \" \\ f \"AND m.dt_id = ' { properties . get ( ModelUtil . dest_key ) } ' \" \\ f \"CREATE (n)-[r: { relationship_type } { cypher_params } ]->(m) RETURN r\" raise Exception ( f \"When you create a relationship, you should define at least { ModelUtil . src_key } and { ModelUtil . dest_key } properties \" )","title":"create_relationship_query()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_twin_query","text":"Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 51 52 53 54 55 56 57 58 59 60 61 62 63 @staticmethod def create_twin_query ( twin_type : str , properties : dict ) -> str : \"\"\" Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query \"\"\" if ModelUtil . dt_id_key in properties : cypher_params = ModelUtil . dict_to_cypher_parameters ( properties ) return f \"CREATE (: { twin_type } { cypher_params } )\" raise Exception ( f \"When you create a twin, you should define at least { ModelUtil . dt_id_key } properties \" )","title":"create_twin_query()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_cypher_parameters","text":"Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 27 28 29 30 31 32 33 34 35 36 37 38 39 @staticmethod def dict_to_cypher_parameters ( parameters : dict ) -> str : \"\"\" Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters \"\"\" cypher_list = [] for key , value in parameters . items (): cypher_list . append ( f \" { key } : { stringify_param_value ( value ) } \" ) joined_list = ', ' . join ( cypher_list ) return '{' + joined_list + '}'","title":"dict_to_cypher_parameters()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_json","text":"Transform a dict to a json string :param obj: the dict :return: the json string corresponding Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 82 83 84 85 86 87 88 89 @staticmethod def dict_to_json ( obj : dict ) -> str : \"\"\" Transform a dict to a json string :param obj: the dict :return: the json string corresponding \"\"\" return json . dumps ( obj , indent = 2 )","title":"dict_to_json()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.print_query_result","text":"Pretty print a QueryResult :param query_result: the QueryResult to print Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 112 113 114 115 116 117 118 119 120 @staticmethod def print_query_result ( query_result : QueryResult ) -> None : \"\"\" Pretty print a QueryResult :param query_result: the QueryResult to print \"\"\" list_to_print = ModelUtil . result_set_to_json ( query_result ) for result in list_to_print : print ( result )","title":"print_query_result()"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.result_set_to_json","text":"Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 @staticmethod def result_set_to_json ( query_result : QueryResult ) -> list : \"\"\" Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list \"\"\" flattened_headers = [ item for sublist in query_result . header for item in sublist ] headers_without_integers = [ x for x in flattened_headers if not isinstance ( x , int )] result_list = [] for result in query_result . result_set : result_dict = {} for i in range ( len ( headers_without_integers )): obj = result [ i ] if isinstance ( obj , Edge ) or isinstance ( obj , Node ): result_dict [ headers_without_integers [ i ]] = obj . properties else : result_dict [ headers_without_integers [ i ]] = obj result_list . append ( ModelUtil . dict_to_json ( result_dict )) return result_list","title":"result_set_to_json()"},{"location":"references/Modelops/core/utils/tests/model_util_test/","text":"CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test TestModelUtil Bases: unittest . TestCase Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/tests/model_util_test.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class TestModelUtil ( unittest . TestCase ): # Global variables simple_parameters = { \"dt_id\" : \"Twin1\" , \"brand\" : \"Ford\" , \"electric\" : False , \"year\" : 1964 , \"dict_param\" : { \"property1\" : \"toto\" , \"property2\" : \"tata\" , }, \"with_quotes\" : \"'9999'\" , \"with_dbl_quotes\" : '\"1234\"' , \"colors\" : [ \"red\" , \"white\" , \"blue\" ] } relationship_simple_parameters = { \"src\" : \"Node1\" , \"dest\" : \"Node2\" , \"brand\" : \"Ford\" , \"electric\" : False , \"year\" : 1964 , \"dict_param\" : { \"property1\" : \"toto\" , \"property2\" : \"tata\" , }, \"with_quotes\" : \"'12345'\" , \"colors\" : [ \"red\" , \"white\" , \"blue\" ] } expected_simple_parameters = '{dt_id : \"Twin1\", ' \\ 'brand : \"Ford\", ' \\ 'electric : False, ' \\ 'year : 1964, ' \\ 'dict_param : {property1:\"toto\",property2:\"tata\"}, ' \\ 'with_quotes : \" \\' 9999 \\' \", ' \\ 'with_dbl_quotes : \" \\\\ \"1234 \\\\ \"\", ' \\ 'colors : [\"red\",\"white\",\"blue\"]}' expected_relationship_simple_parameters = '{src : \"Node1\", ' \\ 'dest : \"Node2\", ' \\ 'brand : \"Ford\", ' \\ 'electric : False, ' \\ 'year : 1964, ' \\ 'dict_param : {property1:\"toto\",property2:\"tata\"}, ' \\ 'with_quotes : \" \\' 12345 \\' \", ' \\ 'colors : [\"red\",\"white\",\"blue\"]}' def setUp ( self ): self . model_util = ModelUtil () def test_dict_to_cypher_parameters_with_simple_parameters ( self ): self . assertEqual ( self . expected_simple_parameters , self . model_util . dict_to_cypher_parameters ( self . simple_parameters )) def test_create_index_query ( self ): expected_result = \"CREATE INDEX ON :Entity_Test(property_name_test)\" self . assertEqual ( expected_result , self . model_util . create_index_query ( \"Entity_Test\" , \"property_name_test\" )) def test_create_twin_query ( self ): expected_result = f \"CREATE (:Entity_Test { self . expected_simple_parameters } )\" self . assertEqual ( expected_result , self . model_util . create_twin_query ( \"Entity_Test\" , self . simple_parameters )) def test_create_twin_query_Exception ( self ): twin_name = 'Twin_name' self . assertRaises ( Exception , self . model_util . create_twin_query , twin_name , self . expected_simple_parameters ) def test_create_relationship_query ( self ): source_id = 'Node1' destination_id = 'Node2' relation_name = 'Relation_Name' expected_result = f \"MATCH (n), (m) WHERE n.dt_id = ' { source_id } ' AND m.dt_id = ' { destination_id } ' CREATE (n)-[r: { relation_name } { self . expected_relationship_simple_parameters } ]->(m) RETURN r\" self . assertEqual ( expected_result , self . model_util . create_relationship_query ( relation_name , self . relationship_simple_parameters )) def test_create_relationship_query_Exception ( self ): relation_name = 'Relation_Name' self . assertRaises ( Exception , self . model_util . create_relationship_query , relation_name , self . expected_simple_parameters )","title":"model_util_test"},{"location":"references/Modelops/core/utils/tests/model_util_test/#cosmotech_acceleration_librarymodelopscoreutilstestsmodel_util_test","text":"","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test"},{"location":"references/Modelops/core/utils/tests/model_util_test/#CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test.TestModelUtil","text":"Bases: unittest . TestCase Source code in CosmoTech_Acceleration_Library/Modelops/core/utils/tests/model_util_test.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class TestModelUtil ( unittest . TestCase ): # Global variables simple_parameters = { \"dt_id\" : \"Twin1\" , \"brand\" : \"Ford\" , \"electric\" : False , \"year\" : 1964 , \"dict_param\" : { \"property1\" : \"toto\" , \"property2\" : \"tata\" , }, \"with_quotes\" : \"'9999'\" , \"with_dbl_quotes\" : '\"1234\"' , \"colors\" : [ \"red\" , \"white\" , \"blue\" ] } relationship_simple_parameters = { \"src\" : \"Node1\" , \"dest\" : \"Node2\" , \"brand\" : \"Ford\" , \"electric\" : False , \"year\" : 1964 , \"dict_param\" : { \"property1\" : \"toto\" , \"property2\" : \"tata\" , }, \"with_quotes\" : \"'12345'\" , \"colors\" : [ \"red\" , \"white\" , \"blue\" ] } expected_simple_parameters = '{dt_id : \"Twin1\", ' \\ 'brand : \"Ford\", ' \\ 'electric : False, ' \\ 'year : 1964, ' \\ 'dict_param : {property1:\"toto\",property2:\"tata\"}, ' \\ 'with_quotes : \" \\' 9999 \\' \", ' \\ 'with_dbl_quotes : \" \\\\ \"1234 \\\\ \"\", ' \\ 'colors : [\"red\",\"white\",\"blue\"]}' expected_relationship_simple_parameters = '{src : \"Node1\", ' \\ 'dest : \"Node2\", ' \\ 'brand : \"Ford\", ' \\ 'electric : False, ' \\ 'year : 1964, ' \\ 'dict_param : {property1:\"toto\",property2:\"tata\"}, ' \\ 'with_quotes : \" \\' 12345 \\' \", ' \\ 'colors : [\"red\",\"white\",\"blue\"]}' def setUp ( self ): self . model_util = ModelUtil () def test_dict_to_cypher_parameters_with_simple_parameters ( self ): self . assertEqual ( self . expected_simple_parameters , self . model_util . dict_to_cypher_parameters ( self . simple_parameters )) def test_create_index_query ( self ): expected_result = \"CREATE INDEX ON :Entity_Test(property_name_test)\" self . assertEqual ( expected_result , self . model_util . create_index_query ( \"Entity_Test\" , \"property_name_test\" )) def test_create_twin_query ( self ): expected_result = f \"CREATE (:Entity_Test { self . expected_simple_parameters } )\" self . assertEqual ( expected_result , self . model_util . create_twin_query ( \"Entity_Test\" , self . simple_parameters )) def test_create_twin_query_Exception ( self ): twin_name = 'Twin_name' self . assertRaises ( Exception , self . model_util . create_twin_query , twin_name , self . expected_simple_parameters ) def test_create_relationship_query ( self ): source_id = 'Node1' destination_id = 'Node2' relation_name = 'Relation_Name' expected_result = f \"MATCH (n), (m) WHERE n.dt_id = ' { source_id } ' AND m.dt_id = ' { destination_id } ' CREATE (n)-[r: { relation_name } { self . expected_relationship_simple_parameters } ]->(m) RETURN r\" self . assertEqual ( expected_result , self . model_util . create_relationship_query ( relation_name , self . relationship_simple_parameters )) def test_create_relationship_query_Exception ( self ): relation_name = 'Relation_Name' self . assertRaises ( Exception , self . model_util . create_relationship_query , relation_name , self . expected_simple_parameters )","title":"TestModelUtil"}]}