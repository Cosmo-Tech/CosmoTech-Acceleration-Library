{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cosmotech Acceleration library","text":"<p>Acceleration library for CosmoTech cloud based solution development</p>"},{"location":"#csm-data","title":"csm-data","text":"<p><code>csm-data</code> is a CLI made to give CosmoTech solution modelers and integrators accelerators to start interacting with multiple systems.</p> <p>It gives a first entrypoint to get ready to use commands to send and retrieve data from a number of systems in which a Cosmo Tech API could be integrated</p>"},{"location":"#data-store","title":"data-store","text":"<p>The data store gives a way to keep local data during simulations and comes with <code>csm-data</code> commands to easily send those data to a target system allowing to easily send results anywhere.</p>"},{"location":"#legacy-part","title":"Legacy part","text":"<p>The following description is tied to the legacy part of CoAL that is getting slowly moved to the new code organization before a 1.0.0 release</p>"},{"location":"#code-organisation","title":"Code organisation","text":"<p>In project root directory you'll find 4 main directories:</p> <ul> <li>CosmoTech_Acceleration_Library: containing all Cosmo Tech libraries to accelerate interaction with Cosmo Tech solutions</li> <li>data: a bunch of csv files on which samples are based</li> <li>samples: a bunch of python scripts to demonstrate how to use the library</li> <li>doc: for schema or specific documentation</li> </ul>"},{"location":"#accelerators","title":"Accelerators","text":"<p>TODO</p>"},{"location":"#modelops-library","title":"Modelops library","text":"<p>The aim of this library is to simplify the model accesses via python code.</p> <p>The library can be used by Data Scientists, Modelers, Developers, ...</p>"},{"location":"#utility-classes","title":"Utility classes","text":"<ul> <li><code>ModelImporter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to bulk import data from csv files with schema enforced (<code>samples/Modelops/Bulk_Import_from_CSV_with_schema.py</code>) or not (<code>samples/Modelops/Bulk_Import_from_CSV_without_schema.py</code>) (see documentation for further details)</li> <li><code>ModelExporter(host: str, port: int, name: str, version: int, export_dir: str = '/')</code> : will allow you to export data from a model cache instance</li> <li><code>ModelReader(host: str, port: int, name: str, version: int)</code> : will allow you to read data from a model cache instance (object returned)</li> <li><code>ModelWriter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to write data into a model instance</li> <li><code>ModelUtil</code> : a bunch of utilities to manipulate and facilitate interaction with model instance (result_set_to_json, print_query_result, ... )</li> <li><code>ModelMetadata</code>: will allow you to management graph metadata</li> </ul>"},{"location":"dependencies/","title":"List of dependencies","text":"<p>Azure connection requirements </p> <p>Keycloak connection </p> <p>Modelops requirements </p> <p>Cosmotech specific requirements </p> <p>Commands requirements </p> <p>Orchestrator templates requirements </p> <p>Data store requirements </p> <p>CLI requirements </p> <p>Other requirements </p> <p>fix distutils missing from 3.12   Documentation generation   Extra requirements   Test requirements </p>"},{"location":"csm-data/","title":"csm-data","text":"<p>Help command</p> <pre><code>&gt; csm-data --help\n\n Usage: csm-data [OPTIONS] COMMAND [ARGS]...                                                                          \n\n Cosmo Tech Data Interface                                                                                            \n Command toolkit providing quick implementation of data connections to use inside the Cosmo Tech Platform             \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --log-level    LVL  Either CRITICAL, ERROR, WARNING, INFO or DEBUG                                                 \u2502\n\u2502                     ENV: LOG_LEVEL                                                                                 \u2502\n\u2502 --version           Print version number and return.                                                               \u2502\n\u2502 --web-help          Open the web documentation                                                                     \u2502\n\u2502 --help              Show this message and exit.                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 adx-send-scenariodata  Uses environment variables to send content of CSV files to ADX Requires a valid Azure       \u2502\n\u2502                        connection either with:                                                                     \u2502\n\u2502                                                                                                                    \u2502\n\u2502                         \u2022 The AZ cli command: az login                                                             \u2502\n\u2502                         \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET               \u2502\n\u2502 api                    Cosmo Tech API helper command                                                               \u2502\n\u2502 az-storage-upload      Upload a folder to an Azure Storage Blob                                                    \u2502\n\u2502 legacy                 Cosmo Tech legacy API group                                                                 \u2502\n\u2502 s3-bucket-delete       Delete S3 bucket content to a given folder                                                  \u2502\n\u2502 s3-bucket-download     Download S3 bucket content to a given folder                                                \u2502\n\u2502 s3-bucket-upload       Upload a folder to a S3 Bucket                                                              \u2502\n\u2502 store                  CoAL Data Store command group                                                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/adx-send-scenariodata/","title":"adx-send-scenariodata","text":"<p>Help command</p> <pre><code>&gt; csm-data adx-send-scenariodata --help\n\n Usage: csm-data adx-send-scenariodata [OPTIONS]                                                                      \n\n Uses environment variables to send content of CSV files to ADX Requires a valid Azure connection either with:        \n\n  \u2022 The AZ cli command: az login                                                                                      \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET                                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --dataset-absolute-path                   PATH  A local folder to store the main dataset content                \u2502\n\u2502                                                    ENV: CSM_DATASET_ABSOLUTE_PATH                                  \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502 *  --parameters-absolute-path                PATH  A local folder to store the parameters content                  \u2502\n\u2502                                                    ENV: CSM_PARAMETERS_ABSOLUTE_PATH                               \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502 *  --simulation-id                           UUID  the Simulation Id to add to records                             \u2502\n\u2502                                                    ENV: CSM_SIMULATION_ID                                          \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502 *  --adx-uri                                 URI   the ADX cluster path (URI info can be found into ADX cluster    \u2502\n\u2502                                                    page)                                                           \u2502\n\u2502                                                    ENV: AZURE_DATA_EXPLORER_RESOURCE_URI                           \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502 *  --adx-ingest-uri                          URI   The ADX cluster ingest path (URI info can be found into ADX     \u2502\n\u2502                                                    cluster page)                                                   \u2502\n\u2502                                                    ENV: AZURE_DATA_EXPLORER_RESOURCE_INGEST_URI                    \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502 *  --database-name                           NAME  The targeted database name                                      \u2502\n\u2502                                                    ENV: AZURE_DATA_EXPLORER_DATABASE_NAME                          \u2502\n\u2502                                                    [required]                                                      \u2502\n\u2502    --send-parameters/--no-send-parameters          whether or not to send parameters (parameters path is mandatory \u2502\n\u2502                                                    then)                                                           \u2502\n\u2502                                                    ENV: CSM_SEND_DATAWAREHOUSE_PARAMETERS                          \u2502\n\u2502                                                    DEFAULT: no-send-parameters                                     \u2502\n\u2502    --send-datasets/--no-send-datasets              whether or not to send datasets (parameters path is mandatory   \u2502\n\u2502                                                    then)                                                           \u2502\n\u2502                                                    ENV: CSM_SEND_DATAWAREHOUSE_DATASETS                            \u2502\n\u2502                                                    DEFAULT: no-send-datasets                                       \u2502\n\u2502    --wait/--no-wait                                Toggle waiting for the ingestion results                        \u2502\n\u2502                                                    ENV: WAIT_FOR_INGESTION                                         \u2502\n\u2502                                                    DEFAULT: no-wait                                                \u2502\n\u2502    --help                                          Show this message and exit.                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/az-storage-upload/","title":"az-storage-upload","text":"<p>Help command</p> <pre><code>&gt; csm-data az-storage-upload --help\n\n Usage: csm-data az-storage-upload [OPTIONS]                                                                          \n\n Upload a folder to an Azure Storage Blob                                                                             \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --source-folder               PATH    The folder/file to upload to the target blob storage                      \u2502\n\u2502                                          ENV: CSM_DATASET_ABSOLUTE_PATH                                            \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502    --recursive/--no-recursive            Recursively send the content of every folder inside the starting folder   \u2502\n\u2502                                          to the blob storage                                                       \u2502\n\u2502 *  --blob-name                   BUCKET  The blob name in the Azure Storage service to upload to                   \u2502\n\u2502                                          ENV: AZURE_STORAGE_BLOB_NAME                                              \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502    --prefix                      PREFIX  A prefix by which all uploaded files should start with in the blob        \u2502\n\u2502                                          storage                                                                   \u2502\n\u2502                                          ENV: CSM_DATA_BLOB_PREFIX                                                 \u2502\n\u2502    --az-storage-sas-url          URL     SAS url allowing access to the AZ storage container                       \u2502\n\u2502                                          ENV: AZURE_STORAGE_SAS_URL                                                \u2502\n\u2502    --web-help                            Open the web documentation                                                \u2502\n\u2502    --help                                Show this message and exit.                                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/s3-bucket-delete/","title":"s3-bucket-delete","text":"<p>Help command</p> <pre><code>&gt; csm-data s3-bucket-delete --help\n\n Usage: csm-data s3-bucket-delete [OPTIONS]                                                                           \n\n Delete S3 bucket content to a given folder                                                                           \n Will delete everything in the bucket unless a prefix is set, then only file following the given prefix will be       \n deleted                                                                                                              \n\n Make use of the boto3 library to access the bucket                                                                   \n\n More information is available on this page:                                                                          \n [https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html]                                   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --bucket-name         BUCKET  The bucket on S3 to delete                                                        \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_NAME                                                         \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502    --prefix-filter       PREFIX  A prefix by which all deleted files should start in the bucket                    \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_PREFIX                                                       \u2502\n\u2502    --use-ssl/--no-ssl            Use SSL to secure connection to S3                                                \u2502\n\u2502 *  --s3-url              URL     URL to connect to the S3 system                                                   \u2502\n\u2502                                  ENV: AWS_ENDPOINT_URL                                                             \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502 *  --access-id           ID      Identity used to connect to the S3 system                                         \u2502\n\u2502                                  ENV: AWS_ACCESS_KEY_ID                                                            \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502 *  --secret-key          ID      Secret tied to the ID used to connect to the S3 system                            \u2502\n\u2502                                  ENV: AWS_SECRET_ACCESS_KEY                                                        \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502    --ssl-cert-bundle     PATH    Path to an alternate CA Bundle to validate SSL connections                        \u2502\n\u2502                                  ENV: CSM_S3_CA_BUNDLE                                                             \u2502\n\u2502    --web-help                    Open the web documentation                                                        \u2502\n\u2502    --help                        Show this message and exit.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/s3-bucket-download/","title":"s3-bucket-download","text":"<p>Help command</p> <pre><code>&gt; csm-data s3-bucket-download --help\n\n Usage: csm-data s3-bucket-download [OPTIONS]                                                                         \n\n Download S3 bucket content to a given folder                                                                         \n Will download everything in the bucket unless a prefix is set, then only file following the given prefix will be     \n downloaded                                                                                                           \n\n Make use of the boto3 library to access the bucket                                                                   \n\n More information is available on this page:                                                                          \n [https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html]                                   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --target-folder       PATH    The folder in which to download the bucket content                                \u2502\n\u2502                                  ENV: CSM_DATASET_ABSOLUTE_PATH                                                    \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502 *  --bucket-name         BUCKET  The bucket on S3 to download                                                      \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_NAME                                                         \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502    --prefix-filter       PREFIX  A prefix by which all downloaded files should start in the bucket                 \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_PREFIX                                                       \u2502\n\u2502    --use-ssl/--no-ssl            Use SSL to secure connection to S3                                                \u2502\n\u2502 *  --s3-url              URL     URL to connect to the S3 system                                                   \u2502\n\u2502                                  ENV: AWS_ENDPOINT_URL                                                             \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502 *  --access-id           ID      Identity used to connect to the S3 system                                         \u2502\n\u2502                                  ENV: AWS_ACCESS_KEY_ID                                                            \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502 *  --secret-key          ID      Secret tied to the ID used to connect to the S3 system                            \u2502\n\u2502                                  ENV: AWS_SECRET_ACCESS_KEY                                                        \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502    --ssl-cert-bundle     PATH    Path to an alternate CA Bundle to validate SSL connections                        \u2502\n\u2502                                  ENV: CSM_S3_CA_BUNDLE                                                             \u2502\n\u2502    --web-help                    Open the web documentation                                                        \u2502\n\u2502    --help                        Show this message and exit.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/s3-bucket-upload/","title":"s3-bucket-upload","text":"<p>Help command</p> <pre><code>&gt; csm-data s3-bucket-upload --help\n\n Usage: csm-data s3-bucket-upload [OPTIONS]                                                                           \n\n Upload a folder to a S3 Bucket                                                                                       \n Will upload everything from a given folder to a S3 bucket. If a single file is passed only it will be uploaded, and  \n recursive will be ignored                                                                                            \n\n Giving a prefix will add it to every upload (finishing the prefix with a \"/\" will allow to upload in a folder inside \n the bucket)                                                                                                          \n\n Make use of the boto3 library to access the bucket                                                                   \n\n More information is available on this page:                                                                          \n [https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html]                                   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --source-folder               PATH    The folder/file to upload to the target bucket                            \u2502\n\u2502                                          ENV: CSM_DATASET_ABSOLUTE_PATH                                            \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502    --recursive/--no-recursive            Recursively send the content of every folder inside the starting folder   \u2502\n\u2502                                          to the bucket                                                             \u2502\n\u2502 *  --bucket-name                 BUCKET  The bucket on S3 to upload to                                             \u2502\n\u2502                                          ENV: CSM_DATA_BUCKET_NAME                                                 \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502    --prefix                      PREFIX  A prefix by which all uploaded files should start with in the bucket      \u2502\n\u2502                                          ENV: CSM_DATA_BUCKET_PREFIX                                               \u2502\n\u2502    --use-ssl/--no-ssl                    Use SSL to secure connection to S3                                        \u2502\n\u2502 *  --s3-url                      URL     URL to connect to the S3 system                                           \u2502\n\u2502                                          ENV: AWS_ENDPOINT_URL                                                     \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502 *  --access-id                   ID      Identity used to connect to the S3 system                                 \u2502\n\u2502                                          ENV: AWS_ACCESS_KEY_ID                                                    \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502 *  --secret-key                  ID      Secret tied to the ID used to connect to the S3 system                    \u2502\n\u2502                                          ENV: AWS_SECRET_ACCESS_KEY                                                \u2502\n\u2502                                          [required]                                                                \u2502\n\u2502    --ssl-cert-bundle             PATH    Path to an alternate CA Bundle to validate SSL connections                \u2502\n\u2502                                          ENV: CSM_S3_CA_BUNDLE                                                     \u2502\n\u2502    --web-help                            Open the web documentation                                                \u2502\n\u2502    --help                                Show this message and exit.                                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/","title":"api","text":"<p>Help command</p> <pre><code>&gt; csm-data api --help\n\n Usage: csm-data api [OPTIONS] COMMAND [ARGS]...                                                                      \n\n Cosmo Tech API helper command                                                                                        \n This command will inform you of which connection is available to use for the Cosmo Tech API                          \n\n If no connection is available, will list all possible set of parameters and return an error code,                    \n\n You can use this command in a csm-orc template to make sure that API connection is available.                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                                                         \u2502\n\u2502 --help          Show this message and exit.                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 postgres-send-runner-metadata  Send runner metadata to a PostgreSQL database.                                      \u2502\n\u2502 rds-load-csv                   Load data from a runner's RDS database into a CSV file.                             \u2502\n\u2502 rds-send-csv                   Send CSV files to a runner's RDS database.                                          \u2502\n\u2502 rds-send-store                 Send data from a store to a runner's RDS database.                                  \u2502\n\u2502 run-load-data                  Download a runner data from the Cosmo Tech API Requires a valid Azure connection    \u2502\n\u2502                                either with:                                                                        \u2502\n\u2502                                                                                                                    \u2502\n\u2502                                 \u2022 The AZ cli command: az login                                                     \u2502\n\u2502                                 \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET       \u2502\n\u2502 runtemplate-load-handler       Uses environment variables to download cloud based Template steps                   \u2502\n\u2502 scenariorun-load-data          Uses environment variables to call the download_scenario_data function Requires a   \u2502\n\u2502                                valid Azure connection either with:                                                 \u2502\n\u2502                                                                                                                    \u2502\n\u2502                                 \u2022 The AZ cli command: az login                                                     \u2502\n\u2502                                 \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET       \u2502\n\u2502 tdl-load-files                 Query a twingraph and loads all the data from it                                    \u2502\n\u2502 tdl-send-files                 Reads a folder CSVs and send those to the Cosmo Tech API as a Dataset               \u2502\n\u2502 wsf-load-file                  Download files from a workspace.                                                    \u2502\n\u2502 wsf-send-file                  Upload a file to a workspace.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-load-csv/","title":"rds-load-csv","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-load-csv --help\n\n Usage: csm-data api rds-load-csv [OPTIONS]                                                                           \n\n Load data from a runner's RDS database into a CSV file.                                                              \n Executes a SQL query against the runner's RDS database and saves the results to a CSV file. By default, it will list \n all tables in the public schema if no specific query is provided.                                                    \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --target-folder      PATH        The folder where the csv will be written                                       \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH                                                 \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API                                             \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API                                                \u2502\n\u2502                                     ENV: CSM_RUN_ID                                                                \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --file-name          NAME        A file name to write the query results                                         \u2502\n\u2502                                     DEFAULT: results                                                               \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --query              SQL_QUERY   SQL query to execute (defaults to listing all tables in public schema)         \u2502\n\u2502                                     DEFAULT: SELECT table_name FROM information_schema.tables WHERE                \u2502\n\u2502                                     table_schema='public'                                                          \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-send-csv/","title":"rds-send-csv","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-send-csv --help\n\n Usage: csm-data api rds-send-csv [OPTIONS]                                                                           \n\n Send CSV files to a runner's RDS database.                                                                           \n Takes all CSV files from a source folder and sends their content to the runner's RDS database. Each CSV file will be \n sent to a table named after the file (without the .csv extension). The table name will be prefixed with \"CD_\" in the \n database.                                                                                                            \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --source-folder      PATH        The folder containing csvs to send                                             \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH                                                 \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API                                             \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API                                                \u2502\n\u2502                                     ENV: CSM_RUN_ID                                                                \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-send-store/","title":"rds-send-store","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-send-store --help\n\n Usage: csm-data api rds-send-store [OPTIONS]                                                                         \n\n Send data from a store to a runner's RDS database.                                                                   \n Takes all tables from a store and sends their content to the runner's RDS database. Each table will be sent to a     \n table with the same name, prefixed with \"CD_\" in the database. Null values in rows will be removed before sending.   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder       PATH        The folder containing the store files                                          \u2502\n\u2502                                     ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                              \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API                                             \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API                                                \u2502\n\u2502                                     ENV: CSM_RUN_ID                                                                \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/run-load-data/","title":"run-load-data","text":"<p>Help command</p> <pre><code>&gt; csm-data api run-load-data --help\n\n Usage: csm-data api run-load-data [OPTIONS]                                                                          \n\n Download a runner data from the Cosmo Tech API Requires a valid Azure connection either with:                        \n\n  \u2022 The AZ cli command: az login                                                                                      \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET                                        \n Requires env var CSM_API_URL     The URL to a Cosmotech API                                                          \n Requires env var CSM_API_SCOPE   The identification scope of a Cosmotech API                                         \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id             o-##########  The id of an organization in the cosmotech api                      \u2502\n\u2502                                                ENV: CSM_ORGANIZATION_ID                                            \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502 *  --workspace-id                w-##########  The id of a workspace in the cosmotech api                          \u2502\n\u2502                                                ENV: CSM_WORKSPACE_ID                                               \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502 *  --runner-id                   s-##########  The id of a runner in the cosmotech api                             \u2502\n\u2502                                                ENV: CSM_RUNNER_ID                                                  \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502 *  --parameters-absolute-path    PATH          A local folder to store the parameters content                      \u2502\n\u2502                                                ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                   \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502    --web-help                                  Open the web documentation                                          \u2502\n\u2502    --help                                      Show this message and exit.                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/runtemplate-load-handler/","title":"runtemplate-load-handler","text":"<p>Help command</p> <pre><code>&gt; csm-data api runtemplate-load-handler --help\n\n Usage: csm-data api runtemplate-load-handler [OPTIONS]                                                               \n\n Uses environment variables to download cloud based Template steps                                                    \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-##########         The id of an organization in the cosmotech api                        \u2502\n\u2502                                              ENV: CSM_ORGANIZATION_ID                                              \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --workspace-id       w-##########         The id of a solution in the cosmotech api                             \u2502\n\u2502                                              ENV: CSM_WORKSPACE_ID                                                 \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --run-template-id    NAME                 coal-help.commands.api.runtemplate_load_handler.parameters.run_templ\u2026 \u2502\n\u2502                                              ENV: CSM_RUN_TEMPLATE_ID                                              \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --handler-list       HANDLER,...,HANDLER  A list of handlers to download (comma separated)                      \u2502\n\u2502                                              ENV: CSM_CONTAINER_MODE                                               \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502    --help                                    Show this message and exit.                                           \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/scenariorun-load-data/","title":"scenariorun-load-data","text":"<p>Help command</p> <pre><code>&gt; csm-data api scenariorun-load-data --help\n\n Usage: csm-data api scenariorun-load-data [OPTIONS]                                                                  \n\n Uses environment variables to call the download_scenario_data function Requires a valid Azure connection either      \n with:                                                                                                                \n\n  \u2022 The AZ cli command: az login                                                                                      \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET                                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id                     o-##########  The id of an organization in the cosmotech api              \u2502\n\u2502                                                        ENV: CSM_ORGANIZATION_ID                                    \u2502\n\u2502                                                        [required]                                                  \u2502\n\u2502 *  --workspace-id                        w-##########  The id of a workspace in the cosmotech api                  \u2502\n\u2502                                                        ENV: CSM_WORKSPACE_ID                                       \u2502\n\u2502                                                        [required]                                                  \u2502\n\u2502 *  --scenario-id                         s-##########  The id of a scenario in the cosmotech api                   \u2502\n\u2502                                                        ENV: CSM_SCENARIO_ID                                        \u2502\n\u2502                                                        [required]                                                  \u2502\n\u2502 *  --dataset-absolute-path               PATH          A local folder to store the main dataset content            \u2502\n\u2502                                                        ENV: CSM_DATASET_ABSOLUTE_PATH                              \u2502\n\u2502                                                        [required]                                                  \u2502\n\u2502 *  --parameters-absolute-path            PATH          A local folder to store the parameters content              \u2502\n\u2502                                                        ENV: CSM_PARAMETERS_ABSOLUTE_PATH                           \u2502\n\u2502                                                        [required]                                                  \u2502\n\u2502    --write-json/--no-write-json                        Toggle writing of parameters in json format                 \u2502\n\u2502                                                        ENV: WRITE_JSON                                             \u2502\n\u2502                                                        DEFAULT: no-write-json                                      \u2502\n\u2502    --write-csv/--no-write-csv                          Toggle writing of parameters in csv format                  \u2502\n\u2502                                                        ENV: WRITE_CSV                                              \u2502\n\u2502                                                        DEFAULT: write-csv                                          \u2502\n\u2502    --fetch-dataset/--no-fetch-dataset                  Toggle fetching datasets                                    \u2502\n\u2502                                                        ENV: FETCH_DATASET                                          \u2502\n\u2502                                                        DEFAULT: fetch-dataset                                      \u2502\n\u2502    --parallel/--no-parallel                            Toggle parallelization while fetching datasets              \u2502\n\u2502                                                        ENV: FETCH_DATASETS_IN_PARALLEL                             \u2502\n\u2502                                                        DEFAULT: parallel                                           \u2502\n\u2502    --web-help                                          Open the web documentation                                  \u2502\n\u2502    --help                                              Show this message and exit.                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/tdl-load-files/","title":"tdl-load-files","text":"<p>Help command</p> <pre><code>&gt; csm-data api tdl-load-files --help\n\n Usage: csm-data api tdl-load-files [OPTIONS]                                                                         \n\n Query a twingraph and loads all the data from it                                                                     \n Will create 1 csv file per node type / relationship type                                                             \n\n The twingraph must have been populated using the \"tdl-send-files\" command for this to work correctly                 \n\n Requires a valid connection to the API to send the data                                                              \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --scenario-id        s-XXXXXXXX  A scenario id for the Cosmo Tech API (required if runner-id not provided)      \u2502\n\u2502                                     ENV: CSM_SCENARIO_ID                                                           \u2502\n\u2502    --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API (required if scenario-id not provided)      \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502 *  --dir                PATH        Path to the directory to write the results to                                  \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH                                                 \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/tdl-send-files/","title":"tdl-send-files","text":"<p>Help command</p> <pre><code>&gt; csm-data api tdl-send-files --help\n\n Usage: csm-data api tdl-send-files [OPTIONS]                                                                         \n\n Reads a folder CSVs and send those to the Cosmo Tech API as a Dataset                                                \n CSVs must follow a given format:                                                                                     \n\n  \u2022 Nodes files must have an id column                                                                                \n  \u2022 Relationship files must have id, src and dest columns                                                             \n\n Non-existing relationship (aka dest or src does not point to existing node) won't trigger an error, the relationship \n will not be created instead.                                                                                         \n\n Requires a valid connection to the API to send the data                                                              \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --api-url            URI         The URI to a Cosmo Tech API instance                                           \u2502\n\u2502                                     ENV: CSM_API_URL                                                               \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API                                             \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --dir                PATH        Path to the directory containing csvs to send                                  \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH                                                 \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --clear/--keep                   Flag to clear the target dataset first (if set to True will clear the dataset  \u2502\n\u2502                                     before sending anything, irreversibly)                                         \u2502\n\u2502                                     DEFAULT: clear                                                                 \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/wsf-load-file/","title":"wsf-load-file","text":"<p>Help command</p> <pre><code>&gt; csm-data api wsf-load-file --help\n\n Usage: csm-data api wsf-load-file [OPTIONS]                                                                          \n\n Download files from a workspace.                                                                                     \n Downloads files from a specified path in a workspace to a local target folder. If the workspace path ends with '/',  \n it will be treated as a folder and all files within will be downloaded.                                              \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --workspace-path     PATH        Path inside the workspace to load (end with '/' for a folder)                  \u2502\n\u2502 *  --target-folder      PATH        Folder in which to send the downloaded file                                    \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH                                                 \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/wsf-send-file/","title":"wsf-send-file","text":"<p>Help command</p> <pre><code>&gt; csm-data api wsf-send-file --help\n\n Usage: csm-data api wsf-send-file [OPTIONS]                                                                          \n\n Upload a file to a workspace.                                                                                        \n Uploads a local file to a specified path in a workspace. If the workspace path ends with '/', the file will be       \n uploaded to that folder with its original name. Otherwise, the file will be uploaded with the name specified in the  \n workspace path.                                                                                                      \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id     o-XXXXXXXX  An organization id for the Cosmo Tech API                                     \u2502\n\u2502                                      ENV: CSM_ORGANIZATION_ID                                                      \u2502\n\u2502                                      [required]                                                                    \u2502\n\u2502 *  --workspace-id        w-XXXXXXXX  A workspace id for the Cosmo Tech API                                         \u2502\n\u2502                                      ENV: CSM_WORKSPACE_ID                                                         \u2502\n\u2502                                      [required]                                                                    \u2502\n\u2502 *  --file-path           PATH        Path to the file to send as a workspace file                                  \u2502\n\u2502                                      [required]                                                                    \u2502\n\u2502 *  --workspace-path      PATH        Path inside the workspace to store the file (end with '/' for a folder)       \u2502\n\u2502                                      [required]                                                                    \u2502\n\u2502    --overwrite/--keep                Flag to overwrite the target file if it exists                                \u2502\n\u2502                                      DEFAULT: overwrite                                                            \u2502\n\u2502    --web-help                        Open the web documentation                                                    \u2502\n\u2502    --help                            Show this message and exit.                                                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/","title":"legacy","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy --help\n\n Usage: csm-data legacy [OPTIONS] COMMAND [ARGS]...                                                                   \n\n Cosmo Tech legacy API group                                                                                          \n This group will allow you to connect to the CosmoTech API and migrate solutions from pre-3.0 version to 3.X          \n compatible solutions                                                                                                 \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                                                         \u2502\n\u2502 --help          Show this message and exit.                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 generate-orchestrator        Generate an orchestrator configuration file from a solution's run template.           \u2502\n\u2502 init-local-parameter-folder  Initialize a local parameter folder structure from a solution's run template.         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/","title":"generate-orchestrator","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator --help\n\n Usage: csm-data legacy generate-orchestrator [OPTIONS] COMMAND [ARGS]...                                             \n\n Generate an orchestrator configuration file from a solution's run template.                                          \n This command group provides tools to generate orchestrator configuration files either from a local solution file or  \n directly from the Cosmo Tech API.                                                                                    \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                                                         \u2502\n\u2502 --help          Show this message and exit.                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 from-api   Generate an orchestrator configuration by fetching the solution from the API.                           \u2502\n\u2502 from-file  Generate an orchestrator configuration from a local solution file.                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/from-api/","title":"from-api","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator from-api --help\n\n Usage: csm-data legacy generate-orchestrator from-api [OPTIONS] OUTPUT                                               \n\n Generate an orchestrator configuration by fetching the solution from the API.                                        \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  OUTPUT    FILE  [required]                                                                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id           o-##########  The id of an organization in the cosmotech api                        \u2502\n\u2502                                              ENV: CSM_ORGANIZATION_ID                                              \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --workspace-id              w-##########  The id of a solution in the cosmotech api                             \u2502\n\u2502                                              ENV: CSM_WORKSPACE_ID                                                 \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --run-template-id           NAME          The name of the run template in the cosmotech api                     \u2502\n\u2502                                              ENV: CSM_RUN_TEMPLATE_ID                                              \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502    --describe/--no-describe                  Show a description of the generated template after generation         \u2502\n\u2502                                              DEFAULT: no-describe                                                  \u2502\n\u2502    --web-help                                Open the web documentation                                            \u2502\n\u2502    --help                                    Show this message and exit.                                           \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/from-file/","title":"from-file","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator from-file --help\n\n Usage: csm-data legacy generate-orchestrator from-file [OPTIONS] SOLUTION_FILE OUTPUT RUN_TEMPLATE_ID                \n\n Generate an orchestrator configuration from a local solution file.                                                   \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  SOLUTION_FILE      FILE  [required]                                                                             \u2502\n\u2502 *  OUTPUT             FILE  [required]                                                                             \u2502\n\u2502 *  RUN-TEMPLATE-ID    TEXT  [required]                                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --describe/--no-describe      Show a description of the generated template after generation                        \u2502\n\u2502                               DEFAULT: no-describe                                                                 \u2502\n\u2502 --web-help                    Open the web documentation                                                           \u2502\n\u2502 --help                        Show this message and exit.                                                          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/","title":"init-local-parameter-folder","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder --help\n\n Usage: csm-data legacy init-local-parameter-folder [OPTIONS] COMMAND [ARGS]...                                       \n\n Initialize a local parameter folder structure from a solution's run template.                                        \n This command group provides tools to create a local parameter folder structure either from a local solution file or  \n directly from the Cosmo Tech API. The folder will contain parameter files in CSV and/or JSON format.                 \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                                                         \u2502\n\u2502 --help          Show this message and exit.                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 cloud     Initialize parameter folder by fetching the solution from the API.                                       \u2502\n\u2502 solution  Initialize parameter folder from a local solution file.                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/cloud/","title":"cloud","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder cloud --help\n\n Usage: csm-data legacy init-local-parameter-folder cloud [OPTIONS] OUTPUT_FOLDER                                     \n\n Initialize parameter folder by fetching the solution from the API.                                                   \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  OUTPUT_FOLDER    PATH  [required]                                                                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id               o-##########  The id of an organization in the cosmotech api                    \u2502\n\u2502                                                  ENV: CSM_ORGANIZATION_ID                                          \u2502\n\u2502                                                  [required]                                                        \u2502\n\u2502 *  --workspace-id                  w-##########  The id of a solution in the cosmotech api                         \u2502\n\u2502                                                  ENV: CSM_WORKSPACE_ID                                             \u2502\n\u2502                                                  [required]                                                        \u2502\n\u2502 *  --run-template-id               NAME          The name of the run template in the cosmotech api                 \u2502\n\u2502                                                  ENV: CSM_RUN_TEMPLATE_ID                                          \u2502\n\u2502                                                  [required]                                                        \u2502\n\u2502    --write-json/--no-write-json                  Toggle writing of parameters in json format                       \u2502\n\u2502                                                  ENV: WRITE_JSON                                                   \u2502\n\u2502                                                  DEFAULT: no-write-json                                            \u2502\n\u2502    --write-csv/--no-write-csv                    Toggle writing of parameters in csv format                        \u2502\n\u2502                                                  ENV: WRITE_CSV                                                    \u2502\n\u2502                                                  DEFAULT: write-csv                                                \u2502\n\u2502    --web-help                                    Open the web documentation                                        \u2502\n\u2502    --help                                        Show this message and exit.                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/solution/","title":"solution","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder solution --help\n\n Usage: csm-data legacy init-local-parameter-folder solution [OPTIONS] SOLUTION_FILE OUTPUT_FOLDER RUN_TEMPLATE_ID    \n\n Initialize parameter folder from a local solution file.                                                              \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  SOLUTION_FILE      FILE  [required]                                                                             \u2502\n\u2502 *  OUTPUT_FOLDER      PATH  [required]                                                                             \u2502\n\u2502 *  RUN_TEMPLATE_ID    TEXT  [required]                                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --write-json/--no-write-json      Toggle writing of parameters in json format                                      \u2502\n\u2502                                   ENV: WRITE_JSON                                                                  \u2502\n\u2502                                   DEFAULT: no-write-json                                                           \u2502\n\u2502 --write-csv/--no-write-csv        Toggle writing of parameters in csv format                                       \u2502\n\u2502                                   ENV: WRITE_CSV                                                                   \u2502\n\u2502                                   DEFAULT: write-csv                                                               \u2502\n\u2502 --web-help                        Open the web documentation                                                       \u2502\n\u2502 --help                            Show this message and exit.                                                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/","title":"store","text":"<p>Help command</p> <pre><code>&gt; csm-data store --help\n\n Usage: csm-data store [OPTIONS] COMMAND [ARGS]...                                                                    \n\n CoAL Data Store command group                                                                                        \n This group of commands will give you helper commands to interact with the datastore                                  \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                                                         \u2502\n\u2502 --help          Show this message and exit.                                                                        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 dump-to-azure          Dump a datastore to a Azure storage account.                                                \u2502\n\u2502 dump-to-postgresql     Running this command will dump your store to a given postgresql database                    \u2502\n\u2502 dump-to-s3             Dump a datastore to a S3                                                                    \u2502\n\u2502 list-tables            Running this command will list the existing tables in your datastore                        \u2502\n\u2502 load-csv-folder        Running this command will find all csvs in the given folder and put them in the store       \u2502\n\u2502 load-from-singlestore  Load data from SingleStore tables into the store. Will download everything from a given     \u2502\n\u2502                        SingleStore database following some configuration into the store.                           \u2502\n\u2502 rds-send-store         Send data from a store to a runner's RDS database.                                          \u2502\n\u2502 reset                  Running this command will reset the state of your store                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/dump-to-azure/","title":"dump-to-azure","text":"<p>Help command</p> <pre><code>&gt; csm-data store dump-to-azure --help\n\n Usage: csm-data store dump-to-azure [OPTIONS]                                                                        \n\n Dump a datastore to a Azure storage account.                                                                         \n Will upload everything from a given data store to a Azure storage container.                                         \n\n 3 modes currently exists:                                                                                            \n\n  \u2022 sqlite: will dump the data store underlying database as is                                                        \n  \u2022 csv: will convert every table of the datastore to csv and send them as separate files                             \n  \u2022 parquet: will convert every table of the datastore to parquet and send them as separate files                     \n\n Make use of the azure.storage.blob library to access the container                                                   \n\n More information is available on this page:                                                                          \n [https://learn.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?tabs=managed-identity%2Croles \n -azure-portal%2Csign-in-azure-cli&amp;pivots=blob-storage-quickstart-scratch]                                            \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder      PATH                  The folder containing the store files                                 \u2502\n\u2502                                              ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                     \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502    --output-type       [sqlite|csv|parquet]  Choose the type of file output to use (sqlite, csv, parquet)          \u2502\n\u2502 *  --account-name      TEXT                  The account name on Azure to upload to                                \u2502\n\u2502                                              ENV: AZURE_ACCOUNT_NAME                                               \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502    --container-name    TEXT                  The container name on Azure to upload to                              \u2502\n\u2502                                              ENV: AZURE_CONTAINER_NAME                                             \u2502\n\u2502    --prefix            PREFIX                A prefix by which all uploaded files should start with in the         \u2502\n\u2502                                              container                                                             \u2502\n\u2502                                              ENV: CSM_DATA_PREFIX                                                  \u2502\n\u2502 *  --tenant-id         ID                    Tenant Identity used to connect to Azure storage system               \u2502\n\u2502                                              ENV: AZURE_TENANT_ID                                                  \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --client-id         ID                    Client Identity used to connect to Azure storage system               \u2502\n\u2502                                              ENV: AZURE_CLIENT_ID                                                  \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502 *  --client-secret     ID                    Client Secret tied to the ID used to connect to Azure storage system  \u2502\n\u2502                                              ENV: AZURE_CLIENT_SECRET                                              \u2502\n\u2502                                              [required]                                                            \u2502\n\u2502    --web-help                                Open the web documentation                                            \u2502\n\u2502    --help                                    Show this message and exit.                                           \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/dump-to-postgresql/","title":"dump-to-postgresql","text":"<p>Help command</p> <pre><code>&gt; csm-data store dump-to-postgresql --help\n\n Usage: csm-data store dump-to-postgresql [OPTIONS]                                                                   \n\n Running this command will dump your store to a given postgresql database                                             \n Tables names from the store will be prepended with table-prefix in target database                                   \n\n The postgresql user must have USAGE granted on the schema for this script to work due to the use of the command COPY \n FROM STDIN                                                                                                           \n\n\n\n You can simply give him that grant by running the command: GRANT USAGE ON SCHEMA  TO                                 \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder         PATH     The folder containing the store files                                           \u2502\n\u2502                                    ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                               \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502    --table-prefix         PREFIX   Prefix to add to the table name                                                 \u2502\n\u2502 *  --postgres-host        TEXT     PostgreSQL host URI                                                             \u2502\n\u2502                                    ENV: POSTGRES_HOST_URI                                                          \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502    --postgres-port        INTEGER  PostgreSQL database port                                                        \u2502\n\u2502                                    ENV: POSTGRES_HOST_PORT                                                         \u2502\n\u2502 *  --postgres-db          TEXT     PostgreSQL database name                                                        \u2502\n\u2502                                    ENV: POSTGRES_DB_NAME                                                           \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502 *  --postgres-schema      TEXT     PostgreSQL schema name                                                          \u2502\n\u2502                                    ENV: POSTGRES_DB_SCHEMA                                                         \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502 *  --postgres-user        TEXT     PostgreSQL connection user name                                                 \u2502\n\u2502                                    ENV: POSTGRES_USER_NAME                                                         \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502 *  --postgres-password    TEXT     PostgreSQL connection password                                                  \u2502\n\u2502                                    ENV: POSTGRES_USER_PASSWORD                                                     \u2502\n\u2502                                    [required]                                                                      \u2502\n\u2502    --replace/--append              Append data on existing tables                                                  \u2502\n\u2502                                    DEFAULT: replace                                                                \u2502\n\u2502    --help                          Show this message and exit.                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/dump-to-s3/","title":"dump-to-s3","text":"<p>Help command</p> <pre><code>&gt; csm-data store dump-to-s3 --help\n\n Usage: csm-data store dump-to-s3 [OPTIONS]                                                                           \n\n Dump a datastore to a S3                                                                                             \n Will upload everything from a given data store to a S3 bucket.                                                       \n\n 3 modes currently exists:                                                                                            \n\n  \u2022 sqlite: will dump the data store underlying database as is                                                        \n  \u2022 csv: will convert every table of the datastore to csv and send them as separate files                             \n  \u2022 parquet: will convert every table of the datastore to parquet and send them as separate files                     \n\n Giving a prefix will add it to every upload (finishing the prefix with a \"/\" will allow to upload in a folder inside \n the bucket)                                                                                                          \n\n Make use of the boto3 library to access the bucket                                                                   \n\n More information is available on this page:                                                                          \n [https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html]                                   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder        PATH                  The folder containing the store files                               \u2502\n\u2502                                                ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                   \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502    --output-type         [sqlite|csv|parquet]  Choose the type of file output to use (sqlite, csv, parquet)        \u2502\n\u2502 *  --bucket-name         BUCKET                The bucket on S3 to upload to                                       \u2502\n\u2502                                                ENV: CSM_DATA_BUCKET_NAME                                           \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502    --prefix              PREFIX                A prefix by which all uploaded files should start with in the       \u2502\n\u2502                                                bucket                                                              \u2502\n\u2502                                                ENV: CSM_DATA_BUCKET_PREFIX                                         \u2502\n\u2502    --use-ssl/--no-ssl                          Use SSL to secure connection to S3                                  \u2502\n\u2502 *  --s3-url              URL                   URL to connect to the S3 system                                     \u2502\n\u2502                                                ENV: AWS_ENDPOINT_URL                                               \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502 *  --access-id           ID                    Identity used to connect to the S3 system                           \u2502\n\u2502                                                ENV: AWS_ACCESS_KEY_ID                                              \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502 *  --secret-key          ID                    Secret tied to the ID used to connect to the S3 system              \u2502\n\u2502                                                ENV: AWS_SECRET_ACCESS_KEY                                          \u2502\n\u2502                                                [required]                                                          \u2502\n\u2502    --ssl-cert-bundle     PATH                  Path to an alternate CA Bundle to validate SSL connections          \u2502\n\u2502                                                ENV: CSM_S3_CA_BUNDLE                                               \u2502\n\u2502    --web-help                                  Open the web documentation                                          \u2502\n\u2502    --help                                      Show this message and exit.                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/list-tables/","title":"list-tables","text":"<p>Help command</p> <pre><code>&gt; csm-data store list-tables --help\n\n Usage: csm-data store list-tables [OPTIONS]                                                                          \n\n Running this command will list the existing tables in your datastore                                                 \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder          PATH  The folder containing the store files                                             \u2502\n\u2502                                  ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                                 \u2502\n\u2502                                  [required]                                                                        \u2502\n\u2502    --schema/--no-schema          Display the schema of the tables                                                  \u2502\n\u2502    --help                        Show this message and exit.                                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/load-csv-folder/","title":"load-csv-folder","text":"<p>Help command</p> <pre><code>&gt; csm-data store load-csv-folder --help\n\n Usage: csm-data store load-csv-folder [OPTIONS]                                                                      \n\n Running this command will find all csvs in the given folder and put them in the store                                \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder    PATH  The folder containing the store files                                                   \u2502\n\u2502                            ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                                       \u2502\n\u2502                            [required]                                                                              \u2502\n\u2502 *  --csv-folder      PATH  The folder containing the csv files to store                                            \u2502\n\u2502                            ENV: CSM_DATASET_ABSOLUTE_PATH                                                          \u2502\n\u2502                            [required]                                                                              \u2502\n\u2502    --help                  Show this message and exit.                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/load-from-singlestore/","title":"load-from-singlestore","text":"<p>Help command</p> <pre><code>&gt; csm-data store load-from-singlestore --help\n\n Usage: csm-data store load-from-singlestore [OPTIONS]                                                                \n\n Load data from SingleStore tables into the store. Will download everything from a given SingleStore database         \n following some configuration into the store.                                                                         \n Make use of the singlestoredb to access to SingleStore                                                               \n\n More information is available on this page:                                                                          \n [https://docs.singlestore.com/cloud/developer-resources/connect-with-application-development-tools/connect-with-pyth \n on/connect-using-the-singlestore-python-client/]                                                                     \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --singlestore-host        TEXT     SingleStore instance URI                                                     \u2502\n\u2502                                       ENV: SINGLE_STORE_HOST                                                       \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502    --singlestore-port        INTEGER  SingleStore port                                                             \u2502\n\u2502                                       ENV: SINGLE_STORE_PORT                                                       \u2502\n\u2502 *  --singlestore-db          TEXT     SingleStore database name                                                    \u2502\n\u2502                                       ENV: SINGLE_STORE_DB                                                         \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502 *  --singlestore-user        TEXT     SingleStore connection user name                                             \u2502\n\u2502                                       ENV: SINGLE_STORE_USERNAME                                                   \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502 *  --singlestore-password    TEXT     SingleStore connection password                                              \u2502\n\u2502                                       ENV: SINGLE_STORE_PASSWORD                                                   \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502 *  --singlestore-tables      TEXT     SingleStore table names to fetched (separated by comma)                      \u2502\n\u2502                                       ENV: SINGLE_STORE_TABLES                                                     \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502 *  --store-folder            PATH     The folder containing the store files                                        \u2502\n\u2502                                       ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                            \u2502\n\u2502                                       [required]                                                                   \u2502\n\u2502    --help                             Show this message and exit.                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/rds-send-store/","title":"rds-send-store","text":"<p>Help command</p> <pre><code>&gt; csm-data store rds-send-store --help\n\n Usage: csm-data store rds-send-store [OPTIONS]                                                                       \n\n Send data from a store to a runner's RDS database.                                                                   \n Takes all tables from a store and sends their content to the runner's RDS database. Each table will be sent to a     \n table with the same name, prefixed with \"CD_\" in the database. Null values in rows will be removed before sending.   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder       PATH        The folder containing the store files                                          \u2502\n\u2502                                     ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                              \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                                                       \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API                                          \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                                                          \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API                                             \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                                                             \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API                                                \u2502\n\u2502                                     ENV: CSM_RUN_ID                                                                \u2502\n\u2502                                     [required]                                                                     \u2502\n\u2502    --web-help                       Open the web documentation                                                     \u2502\n\u2502    --help                           Show this message and exit.                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/reset/","title":"reset","text":"<p>Help command</p> <pre><code>&gt; csm-data store reset --help\n\n Usage: csm-data store reset [OPTIONS]                                                                                \n\n Running this command will reset the state of your store                                                              \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder    PATH  The folder containing the store files                                                   \u2502\n\u2502                            ENV: CSM_PARAMETERS_ABSOLUTE_PATH                                                       \u2502\n\u2502                            [required]                                                                              \u2502\n\u2502    --help                  Show this message and exit.                                                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"references/SUMMARY/","title":"SUMMARY","text":"<ul> <li>References<ul> <li>coal<ul> <li>azure<ul> <li>adx<ul> <li>ingestion</li> <li>tables</li> <li>wrapper</li> <li>query</li> <li>auth</li> <li>utils</li> </ul> </li> </ul> </li> <li>csm<ul> <li>engine</li> </ul> </li> <li>cli<ul> <li>utils<ul> <li>decorators</li> </ul> </li> </ul> </li> <li>store<ul> <li>csv</li> <li>pyarrow</li> <li>store</li> <li>pandas</li> <li>native_python</li> </ul> </li> <li>utils<ul> <li>postgresql</li> </ul> </li> <li>dataset<ul> <li>utils</li> </ul> </li> <li>cosmotech_api<ul> <li>run</li> <li>runner<ul> <li>metadata</li> <li>parameters</li> </ul> </li> <li>connection</li> <li>workspace</li> <li>twin_data_layer</li> <li>dataset<ul> <li>utils</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"references/coal/utils/","title":"cosmotech.coal.utils","text":""},{"location":"references/coal/utils/#cosmotech.coal.utils","title":"<code>utils</code>","text":""},{"location":"references/coal/azure/adx/auth/","title":"cosmotech.coal.azure.adx.auth","text":""},{"location":"references/coal/azure/adx/auth/#cosmotech.coal.azure.adx.auth","title":"<code>auth</code>","text":""},{"location":"references/coal/azure/adx/auth/#cosmotech.coal.azure.adx.auth.create_ingest_client","title":"<code>create_ingest_client(ingest_url, client_id=None, client_secret=None, tenant_id=None)</code>","text":"<p>Create a QueuedIngestClient for ingesting data to ADX.</p> <p>Parameters:</p> Name Type Description Default <code>ingest_url</code> <code>str</code> <p>The ingestion URL of the ADX cluster</p> required <code>client_id</code> <code>Optional[str]</code> <p>Azure client ID (optional, will use environment variable if not provided)</p> <code>None</code> <code>client_secret</code> <code>Optional[str]</code> <p>Azure client secret (optional, will use environment variable if not provided)</p> <code>None</code> <code>tenant_id</code> <code>Optional[str]</code> <p>Azure tenant ID (optional, will use environment variable if not provided)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>QueuedIngestClient</code> <code>QueuedIngestClient</code> <p>A client for ingesting data to ADX</p> Source code in <code>cosmotech/coal/azure/adx/auth.py</code> <pre><code>def create_ingest_client(\n    ingest_url: str,\n    client_id: Optional[str] = None,\n    client_secret: Optional[str] = None,\n    tenant_id: Optional[str] = None\n) -&gt; QueuedIngestClient:\n    \"\"\"\n    Create a QueuedIngestClient for ingesting data to ADX.\n\n    Args:\n        ingest_url: The ingestion URL of the ADX cluster\n        client_id: Azure client ID (optional, will use environment variable if not provided)\n        client_secret: Azure client secret (optional, will use environment variable if not provided)\n        tenant_id: Azure tenant ID (optional, will use environment variable if not provided)\n\n    Returns:\n        QueuedIngestClient: A client for ingesting data to ADX\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.creating_ingest_client\").format(ingest_url=ingest_url))\n\n    try:\n        az_client_id = client_id or os.environ['AZURE_CLIENT_ID']\n        az_client_secret = client_secret or os.environ['AZURE_CLIENT_SECRET']\n        az_tenant_id = tenant_id or os.environ['AZURE_TENANT_ID']\n\n        kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(\n            ingest_url,\n            az_client_id,\n            az_client_secret,\n            az_tenant_id\n        )\n        LOGGER.debug(T(\"coal.logs.adx.using_app_auth\"))\n    except KeyError:\n        LOGGER.debug(T(\"coal.logs.adx.using_cli_auth\"))\n        kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(ingest_url)\n\n    return QueuedIngestClient(kcsb)\n</code></pre>"},{"location":"references/coal/azure/adx/auth/#cosmotech.coal.azure.adx.auth.create_kusto_client","title":"<code>create_kusto_client(cluster_url, client_id=None, client_secret=None, tenant_id=None)</code>","text":"<p>Create a KustoClient for querying ADX.</p> <p>Parameters:</p> Name Type Description Default <code>cluster_url</code> <code>str</code> <p>The URL of the ADX cluster</p> required <code>client_id</code> <code>Optional[str]</code> <p>Azure client ID (optional, will use environment variable if not provided)</p> <code>None</code> <code>client_secret</code> <code>Optional[str]</code> <p>Azure client secret (optional, will use environment variable if not provided)</p> <code>None</code> <code>tenant_id</code> <code>Optional[str]</code> <p>Azure tenant ID (optional, will use environment variable if not provided)</p> <code>None</code> <p>Returns:</p> Name Type Description <code>KustoClient</code> <code>KustoClient</code> <p>A client for querying ADX</p> Source code in <code>cosmotech/coal/azure/adx/auth.py</code> <pre><code>def create_kusto_client(\n    cluster_url: str,\n    client_id: Optional[str] = None,\n    client_secret: Optional[str] = None,\n    tenant_id: Optional[str] = None\n) -&gt; KustoClient:\n    \"\"\"\n    Create a KustoClient for querying ADX.\n\n    Args:\n        cluster_url: The URL of the ADX cluster\n        client_id: Azure client ID (optional, will use environment variable if not provided)\n        client_secret: Azure client secret (optional, will use environment variable if not provided)\n        tenant_id: Azure tenant ID (optional, will use environment variable if not provided)\n\n    Returns:\n        KustoClient: A client for querying ADX\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.creating_kusto_client\").format(cluster_url=cluster_url))\n\n    try:\n        az_client_id = client_id or os.environ['AZURE_CLIENT_ID']\n        az_client_secret = client_secret or os.environ['AZURE_CLIENT_SECRET']\n        az_tenant_id = tenant_id or os.environ['AZURE_TENANT_ID']\n\n        kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(\n            cluster_url,\n            az_client_id,\n            az_client_secret,\n            az_tenant_id\n        )\n        LOGGER.debug(T(\"coal.logs.adx.using_app_auth\"))\n    except KeyError:\n        LOGGER.debug(T(\"coal.logs.adx.using_cli_auth\"))\n        kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(cluster_url)\n\n    return KustoClient(kcsb)\n</code></pre>"},{"location":"references/coal/azure/adx/auth/#cosmotech.coal.azure.adx.auth.get_cluster_urls","title":"<code>get_cluster_urls(cluster_name, cluster_region)</code>","text":"<p>Generate cluster and ingest URLs from cluster name and region.</p> <p>Parameters:</p> Name Type Description Default <code>cluster_name</code> <code>str</code> <p>The name of the ADX cluster</p> required <code>cluster_region</code> <code>str</code> <p>The region of the ADX cluster</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[str, str]</code> <p>(cluster_url, ingest_url)</p> Source code in <code>cosmotech/coal/azure/adx/auth.py</code> <pre><code>def get_cluster_urls(\n    cluster_name: str,\n    cluster_region: str\n) -&gt; tuple[str, str]:\n    \"\"\"\n    Generate cluster and ingest URLs from cluster name and region.\n\n    Args:\n        cluster_name: The name of the ADX cluster\n        cluster_region: The region of the ADX cluster\n\n    Returns:\n        tuple: (cluster_url, ingest_url)\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.generating_urls\").format(\n        cluster_name=cluster_name, \n        cluster_region=cluster_region\n    ))\n\n    cluster_url = f\"https://{cluster_name}.{cluster_region}.kusto.windows.net\"\n    ingest_url = f\"https://ingest-{cluster_name}.{cluster_region}.kusto.windows.net\"\n\n    return cluster_url, ingest_url\n</code></pre>"},{"location":"references/coal/azure/adx/ingestion/","title":"cosmotech.coal.azure.adx.ingestion","text":""},{"location":"references/coal/azure/adx/ingestion/#cosmotech.coal.azure.adx.ingestion.IngestionStatus","title":"<code>IngestionStatus</code>","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>cosmotech/coal/azure/adx/ingestion.py</code> <pre><code>class IngestionStatus(Enum):\n    QUEUED = 'QUEUED'\n    SUCCESS = 'SUCCESS'\n    FAILURE = 'FAILURE'\n    UNKNOWN = 'UNKNOWN'\n    TIMEOUT = 'TIMED OUT'\n</code></pre>"},{"location":"references/coal/azure/adx/query/","title":"cosmotech.coal.azure.adx.query","text":""},{"location":"references/coal/azure/adx/query/#cosmotech.coal.azure.adx.query","title":"<code>query</code>","text":""},{"location":"references/coal/azure/adx/query/#cosmotech.coal.azure.adx.query.run_command_query","title":"<code>run_command_query(client, database, query)</code>","text":"<p>Execute a command query on the database.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>KustoClient</code> <p>The KustoClient to use</p> required <code>database</code> <code>str</code> <p>The name of the database</p> required <code>query</code> <code>str</code> <p>The query to execute</p> required <p>Returns:</p> Name Type Description <code>KustoResponseDataSet</code> <code>KustoResponseDataSet</code> <p>The results of the query</p> Source code in <code>cosmotech/coal/azure/adx/query.py</code> <pre><code>def run_command_query(\n    client: KustoClient,\n    database: str,\n    query: str\n) -&gt; KustoResponseDataSet:\n    \"\"\"\n    Execute a command query on the database.\n\n    Args:\n        client: The KustoClient to use\n        database: The name of the database\n        query: The query to execute\n\n    Returns:\n        KustoResponseDataSet: The results of the query\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.running_command\").format(\n        database=database,\n        query=query\n    ))\n\n    result = client.execute_mgmt(database, query)\n    LOGGER.debug(T(\"coal.logs.adx.command_complete\"))\n\n    return result\n</code></pre>"},{"location":"references/coal/azure/adx/query/#cosmotech.coal.azure.adx.query.run_query","title":"<code>run_query(client, database, query)</code>","text":"<p>Execute a simple query on the database.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>KustoClient</code> <p>The KustoClient to use</p> required <code>database</code> <code>str</code> <p>The name of the database</p> required <code>query</code> <code>str</code> <p>The query to execute</p> required <p>Returns:</p> Name Type Description <code>KustoResponseDataSet</code> <code>KustoResponseDataSet</code> <p>The results of the query</p> Source code in <code>cosmotech/coal/azure/adx/query.py</code> <pre><code>def run_query(\n    client: KustoClient,\n    database: str,\n    query: str\n) -&gt; KustoResponseDataSet:\n    \"\"\"\n    Execute a simple query on the database.\n\n    Args:\n        client: The KustoClient to use\n        database: The name of the database\n        query: The query to execute\n\n    Returns:\n        KustoResponseDataSet: The results of the query\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.running_query\").format(\n        database=database,\n        query=query\n    ))\n\n    result = client.execute(database, query)\n    LOGGER.debug(T(\"coal.logs.adx.query_complete\").format(\n        rows=len(result.primary_results[0]) if result.primary_results else 0\n    ))\n\n    return result\n</code></pre>"},{"location":"references/coal/azure/adx/tables/","title":"cosmotech.coal.azure.adx.tables","text":""},{"location":"references/coal/azure/adx/tables/#cosmotech.coal.azure.adx.tables","title":"<code>tables</code>","text":""},{"location":"references/coal/azure/adx/tables/#cosmotech.coal.azure.adx.tables.create_table","title":"<code>create_table(client, database, table_name, schema)</code>","text":"<p>Create a table in the database.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>KustoClient</code> <p>The KustoClient to use</p> required <code>database</code> <code>str</code> <p>The name of the database</p> required <code>table_name</code> <code>str</code> <p>The name of the table to create</p> required <code>schema</code> <code>Dict[str, str]</code> <p>Dictionary mapping column names to ADX types</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the table was created successfully, False otherwise</p> Source code in <code>cosmotech/coal/azure/adx/tables.py</code> <pre><code>def create_table(\n    client: KustoClient,\n    database: str,\n    table_name: str,\n    schema: Dict[str, str]\n) -&gt; bool:\n    \"\"\"\n    Create a table in the database.\n\n    Args:\n        client: The KustoClient to use\n        database: The name of the database\n        table_name: The name of the table to create\n        schema: Dictionary mapping column names to ADX types\n\n    Returns:\n        bool: True if the table was created successfully, False otherwise\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.creating_table\").format(\n        database=database,\n        table_name=table_name\n    ))\n\n    create_query = f\".create-merge table {table_name}(\"\n\n    for column_name, column_type in schema.items():\n        create_query += f\"{column_name}:{column_type},\"\n\n    create_query = create_query[:-1] + \")\"\n\n    LOGGER.debug(T(\"coal.logs.adx.create_query\").format(query=create_query))\n\n    try:\n        client.execute(database, create_query)\n        LOGGER.info(T(\"coal.logs.adx.table_created\").format(table_name=table_name))\n        return True\n    except Exception as e:\n        LOGGER.error(T(\"coal.logs.adx.table_creation_error\").format(\n            table_name=table_name,\n            error=str(e)\n        ))\n        return False\n</code></pre>"},{"location":"references/coal/azure/adx/tables/#cosmotech.coal.azure.adx.tables.table_exists","title":"<code>table_exists(client, database, table_name)</code>","text":"<p>Check if a table exists in the database.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>KustoClient</code> <p>The KustoClient to use</p> required <code>database</code> <code>str</code> <p>The name of the database</p> required <code>table_name</code> <code>str</code> <p>The name of the table to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the table exists, False otherwise</p> Source code in <code>cosmotech/coal/azure/adx/tables.py</code> <pre><code>def table_exists(\n    client: KustoClient,\n    database: str,\n    table_name: str\n) -&gt; bool:\n    \"\"\"\n    Check if a table exists in the database.\n\n    Args:\n        client: The KustoClient to use\n        database: The name of the database\n        table_name: The name of the table to check\n\n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.checking_table\").format(\n        database=database,\n        table_name=table_name\n    ))\n\n    get_tables_query = f\".show database ['{database}'] schema| distinct TableName\"\n    tables = client.execute(database, get_tables_query)\n\n    for r in tables.primary_results[0]:\n        if table_name == r[0]:\n            LOGGER.debug(T(\"coal.logs.adx.table_exists\").format(table_name=table_name))\n            return True\n\n    LOGGER.debug(T(\"coal.logs.adx.table_not_exists\").format(table_name=table_name))\n    return False\n</code></pre>"},{"location":"references/coal/azure/adx/utils/","title":"cosmotech.coal.azure.adx.utils","text":""},{"location":"references/coal/azure/adx/utils/#cosmotech.coal.azure.adx.utils","title":"<code>utils</code>","text":""},{"location":"references/coal/azure/adx/utils/#cosmotech.coal.azure.adx.utils.type_mapping","title":"<code>type_mapping(key, key_example_value)</code>","text":"<p>Map Python types to ADX types.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the key</p> required <code>key_example_value</code> <code>Any</code> <p>A possible value of the key</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the type used in ADX</p> Source code in <code>cosmotech/coal/azure/adx/utils.py</code> <pre><code>def type_mapping(key: str, key_example_value: Any) -&gt; str:\n    \"\"\"\n    Map Python types to ADX types.\n\n    Args:\n        key: The name of the key\n        key_example_value: A possible value of the key\n\n    Returns:\n        str: The name of the type used in ADX\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.adx.mapping_type\").format(\n        key=key,\n        value_type=type(key_example_value).__name__\n    ))\n\n    if key == \"SimulationRun\":\n        return \"guid\"\n\n    try:\n        # Use dateutil parser to test if the value could be a date, in case of error it is not\n        dateutil.parser.parse(key_example_value, fuzzy=False)\n        return \"datetime\"\n    except (ValueError, TypeError):\n        pass\n\n    if isinstance(key_example_value, float):\n        return \"real\"\n\n    if isinstance(key_example_value, int):\n        return \"long\"\n\n    # Default case to string\n    return \"string\"\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/","title":"cosmotech.coal.azure.adx.wrapper","text":""},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper","title":"<code>ADXQueriesWrapper</code>","text":"<p>Wrapping class to ADX that uses modular functions from the adx package. This class maintains backward compatibility with the original implementation.</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>class ADXQueriesWrapper:\n    \"\"\"\n    Wrapping class to ADX that uses modular functions from the adx package.\n    This class maintains backward compatibility with the original implementation.\n    \"\"\"\n\n    def __init__(self,\n                 database: str,\n                 cluster_url: Union[str, None] = None,\n                 ingest_url: Union[str, None] = None,\n                 cluster_name: Union[str, None] = None,\n                 cluster_region: Union[str, None] = None):\n        \"\"\"\n        Initialize the ADXQueriesWrapper.\n\n        Args:\n            database: The name of the database\n            cluster_url: The URL of the ADX cluster\n            ingest_url: The ingestion URL of the ADX cluster\n            cluster_name: The name of the ADX cluster\n            cluster_region: The region of the ADX cluster\n        \"\"\"\n        if cluster_name and cluster_region:\n            cluster_url, ingest_url = get_cluster_urls(cluster_name, cluster_region)\n\n        self.kusto_client = create_kusto_client(cluster_url)\n        self.ingest_client = create_ingest_client(ingest_url)\n        self.database = database\n        self.timeout = 900\n\n    def type_mapping(self, key: str, key_example_value) -&gt; str:\n        \"\"\"\n        Map Python types to ADX types.\n\n        Args:\n            key: The name of the key\n            key_example_value: A possible value of the key\n\n        Returns:\n            str: The name of the type used in ADX\n        \"\"\"\n        return type_mapping(key, key_example_value)\n\n    def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                    drop_by_tag: str = None):\n        \"\"\"\n        Send a list of dictionaries to an ADX table.\n\n        Args:\n            dict_list: The list of dictionaries to send\n            table_name: The name of the table\n            ignore_table_creation: If False, will create the table if it doesn't exist\n            drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n\n        Returns:\n            The ingestion result with source_id for status tracking\n        \"\"\"\n        return send_to_adx(\n            self.kusto_client,\n            self.ingest_client,\n            self.database,\n            dict_list,\n            table_name,\n            ignore_table_creation,\n            drop_by_tag\n        )\n\n    def ingest_dataframe(self, table_name: str, dataframe, drop_by_tag: str = None):\n        \"\"\"\n        Ingest a pandas DataFrame into an ADX table.\n\n        Args:\n            table_name: The name of the table\n            dataframe: The DataFrame to ingest\n            drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n\n        Returns:\n            The ingestion result with source_id for status tracking\n        \"\"\"\n        return ingest_dataframe(\n            self.ingest_client,\n            self.database,\n            table_name,\n            dataframe,\n            drop_by_tag\n        )\n\n    def check_ingestion_status(self, source_ids: List[str],\n                               timeout: int = None,\n                               logs: bool = False) -&gt; Iterator[Tuple[str, IngestionStatus]]:\n        \"\"\"\n        Check the status of ingestion operations.\n\n        Args:\n            source_ids: List of source IDs to check\n            timeout: Timeout in seconds (default: self.timeout)\n            logs: Whether to log detailed information\n\n        Returns:\n            Iterator of (source_id, status) tuples\n        \"\"\"\n        return check_ingestion_status(\n            self.ingest_client,\n            source_ids,\n            timeout or self.timeout,\n            logs\n        )\n\n    def _clear_ingestion_status_queues(self, confirmation: bool = False):\n        \"\"\"\n        Clear all data in the ingestion status queues.\n        DANGEROUS: This will clear all queues for the entire ADX cluster.\n\n        Args:\n            confirmation: Must be True to proceed with clearing\n        \"\"\"\n        from cosmotech.coal.azure.adx.ingestion import clear_ingestion_status_queues\n        clear_ingestion_status_queues(self.ingest_client, confirmation)\n\n    def run_command_query(self, query: str):\n        \"\"\"\n        Execute a command query on the database.\n\n        Args:\n            query: The query to execute\n\n        Returns:\n            KustoResponseDataSet: The results of the query\n        \"\"\"\n        return run_command_query(self.kusto_client, self.database, query)\n\n    def run_query(self, query: str):\n        \"\"\"\n        Execute a simple query on the database.\n\n        Args:\n            query: The query to execute\n\n        Returns:\n            KustoResponseDataSet: The results of the query\n        \"\"\"\n        return run_query(self.kusto_client, self.database, query)\n\n    def table_exists(self, table_name: str) -&gt; bool:\n        \"\"\"\n        Check if a table exists in the database.\n\n        Args:\n            table_name: The name of the table to check\n\n        Returns:\n            bool: True if the table exists, False otherwise\n        \"\"\"\n        return table_exists(self.kusto_client, self.database, table_name)\n\n    def create_table(self, table_name: str, schema: dict) -&gt; bool:\n        \"\"\"\n        Create a table in the database.\n\n        Args:\n            table_name: The name of the table to create\n            schema: Dictionary mapping column names to ADX types\n\n        Returns:\n            bool: True if the table was created successfully, False otherwise\n        \"\"\"\n        return create_table(self.kusto_client, self.database, table_name, schema)\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.__init__","title":"<code>__init__(database, cluster_url=None, ingest_url=None, cluster_name=None, cluster_region=None)</code>","text":"<p>Initialize the ADXQueriesWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>database</code> <code>str</code> <p>The name of the database</p> required <code>cluster_url</code> <code>Union[str, None]</code> <p>The URL of the ADX cluster</p> <code>None</code> <code>ingest_url</code> <code>Union[str, None]</code> <p>The ingestion URL of the ADX cluster</p> <code>None</code> <code>cluster_name</code> <code>Union[str, None]</code> <p>The name of the ADX cluster</p> <code>None</code> <code>cluster_region</code> <code>Union[str, None]</code> <p>The region of the ADX cluster</p> <code>None</code> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def __init__(self,\n             database: str,\n             cluster_url: Union[str, None] = None,\n             ingest_url: Union[str, None] = None,\n             cluster_name: Union[str, None] = None,\n             cluster_region: Union[str, None] = None):\n    \"\"\"\n    Initialize the ADXQueriesWrapper.\n\n    Args:\n        database: The name of the database\n        cluster_url: The URL of the ADX cluster\n        ingest_url: The ingestion URL of the ADX cluster\n        cluster_name: The name of the ADX cluster\n        cluster_region: The region of the ADX cluster\n    \"\"\"\n    if cluster_name and cluster_region:\n        cluster_url, ingest_url = get_cluster_urls(cluster_name, cluster_region)\n\n    self.kusto_client = create_kusto_client(cluster_url)\n    self.ingest_client = create_ingest_client(ingest_url)\n    self.database = database\n    self.timeout = 900\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.check_ingestion_status","title":"<code>check_ingestion_status(source_ids, timeout=None, logs=False)</code>","text":"<p>Check the status of ingestion operations.</p> <p>Parameters:</p> Name Type Description Default <code>source_ids</code> <code>List[str]</code> <p>List of source IDs to check</p> required <code>timeout</code> <code>int</code> <p>Timeout in seconds (default: self.timeout)</p> <code>None</code> <code>logs</code> <code>bool</code> <p>Whether to log detailed information</p> <code>False</code> <p>Returns:</p> Type Description <code>Iterator[Tuple[str, IngestionStatus]]</code> <p>Iterator of (source_id, status) tuples</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def check_ingestion_status(self, source_ids: List[str],\n                           timeout: int = None,\n                           logs: bool = False) -&gt; Iterator[Tuple[str, IngestionStatus]]:\n    \"\"\"\n    Check the status of ingestion operations.\n\n    Args:\n        source_ids: List of source IDs to check\n        timeout: Timeout in seconds (default: self.timeout)\n        logs: Whether to log detailed information\n\n    Returns:\n        Iterator of (source_id, status) tuples\n    \"\"\"\n    return check_ingestion_status(\n        self.ingest_client,\n        source_ids,\n        timeout or self.timeout,\n        logs\n    )\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.create_table","title":"<code>create_table(table_name, schema)</code>","text":"<p>Create a table in the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to create</p> required <code>schema</code> <code>dict</code> <p>Dictionary mapping column names to ADX types</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the table was created successfully, False otherwise</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def create_table(self, table_name: str, schema: dict) -&gt; bool:\n    \"\"\"\n    Create a table in the database.\n\n    Args:\n        table_name: The name of the table to create\n        schema: Dictionary mapping column names to ADX types\n\n    Returns:\n        bool: True if the table was created successfully, False otherwise\n    \"\"\"\n    return create_table(self.kusto_client, self.database, table_name, schema)\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.ingest_dataframe","title":"<code>ingest_dataframe(table_name, dataframe, drop_by_tag=None)</code>","text":"<p>Ingest a pandas DataFrame into an ADX table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table</p> required <code>dataframe</code> <p>The DataFrame to ingest</p> required <code>drop_by_tag</code> <code>str</code> <p>Tag used for the drop by capacity of the Cosmotech API</p> <code>None</code> <p>Returns:</p> Type Description <p>The ingestion result with source_id for status tracking</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def ingest_dataframe(self, table_name: str, dataframe, drop_by_tag: str = None):\n    \"\"\"\n    Ingest a pandas DataFrame into an ADX table.\n\n    Args:\n        table_name: The name of the table\n        dataframe: The DataFrame to ingest\n        drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n\n    Returns:\n        The ingestion result with source_id for status tracking\n    \"\"\"\n    return ingest_dataframe(\n        self.ingest_client,\n        self.database,\n        table_name,\n        dataframe,\n        drop_by_tag\n    )\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.run_command_query","title":"<code>run_command_query(query)</code>","text":"<p>Execute a command query on the database.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to execute</p> required <p>Returns:</p> Name Type Description <code>KustoResponseDataSet</code> <p>The results of the query</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def run_command_query(self, query: str):\n    \"\"\"\n    Execute a command query on the database.\n\n    Args:\n        query: The query to execute\n\n    Returns:\n        KustoResponseDataSet: The results of the query\n    \"\"\"\n    return run_command_query(self.kusto_client, self.database, query)\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.run_query","title":"<code>run_query(query)</code>","text":"<p>Execute a simple query on the database.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to execute</p> required <p>Returns:</p> Name Type Description <code>KustoResponseDataSet</code> <p>The results of the query</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def run_query(self, query: str):\n    \"\"\"\n    Execute a simple query on the database.\n\n    Args:\n        query: The query to execute\n\n    Returns:\n        KustoResponseDataSet: The results of the query\n    \"\"\"\n    return run_query(self.kusto_client, self.database, query)\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.send_to_adx","title":"<code>send_to_adx(dict_list, table_name, ignore_table_creation=True, drop_by_tag=None)</code>","text":"<p>Send a list of dictionaries to an ADX table.</p> <p>Parameters:</p> Name Type Description Default <code>dict_list</code> <code>list</code> <p>The list of dictionaries to send</p> required <code>table_name</code> <code>str</code> <p>The name of the table</p> required <code>ignore_table_creation</code> <code>bool</code> <p>If False, will create the table if it doesn't exist</p> <code>True</code> <code>drop_by_tag</code> <code>str</code> <p>Tag used for the drop by capacity of the Cosmotech API</p> <code>None</code> <p>Returns:</p> Type Description <p>The ingestion result with source_id for status tracking</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                drop_by_tag: str = None):\n    \"\"\"\n    Send a list of dictionaries to an ADX table.\n\n    Args:\n        dict_list: The list of dictionaries to send\n        table_name: The name of the table\n        ignore_table_creation: If False, will create the table if it doesn't exist\n        drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n\n    Returns:\n        The ingestion result with source_id for status tracking\n    \"\"\"\n    return send_to_adx(\n        self.kusto_client,\n        self.ingest_client,\n        self.database,\n        dict_list,\n        table_name,\n        ignore_table_creation,\n        drop_by_tag\n    )\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.table_exists","title":"<code>table_exists(table_name)</code>","text":"<p>Check if a table exists in the database.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the table exists, False otherwise</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def table_exists(self, table_name: str) -&gt; bool:\n    \"\"\"\n    Check if a table exists in the database.\n\n    Args:\n        table_name: The name of the table to check\n\n    Returns:\n        bool: True if the table exists, False otherwise\n    \"\"\"\n    return table_exists(self.kusto_client, self.database, table_name)\n</code></pre>"},{"location":"references/coal/azure/adx/wrapper/#cosmotech.coal.azure.adx.wrapper.ADXQueriesWrapper.type_mapping","title":"<code>type_mapping(key, key_example_value)</code>","text":"<p>Map Python types to ADX types.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The name of the key</p> required <code>key_example_value</code> <p>A possible value of the key</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the type used in ADX</p> Source code in <code>cosmotech/coal/azure/adx/wrapper.py</code> <pre><code>def type_mapping(self, key: str, key_example_value) -&gt; str:\n    \"\"\"\n    Map Python types to ADX types.\n\n    Args:\n        key: The name of the key\n        key_example_value: A possible value of the key\n\n    Returns:\n        str: The name of the type used in ADX\n    \"\"\"\n    return type_mapping(key, key_example_value)\n</code></pre>"},{"location":"references/coal/cli/utils/decorators/","title":"cosmotech.coal.cli.utils.decorators","text":""},{"location":"references/coal/cli/utils/decorators/#cosmotech.coal.cli.utils.decorators","title":"<code>decorators</code>","text":""},{"location":"references/coal/cli/utils/decorators/#cosmotech.coal.cli.utils.decorators.translate_help","title":"<code>translate_help(translation_key)</code>","text":"<p>Decorator that sets the function's doc to the translated help text.</p> Source code in <code>cosmotech/coal/cli/utils/decorators.py</code> <pre><code>def translate_help(translation_key):\n    \"\"\"Decorator that sets the function's __doc__ to the translated help text.\"\"\"\n    def wrap_function(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.__doc__ = T(translation_key)\n        return wrapper\n    return wrap_function\n</code></pre>"},{"location":"references/coal/cosmotech_api/connection/","title":"cosmotech.coal.cosmotech_api.connection","text":""},{"location":"references/coal/cosmotech_api/connection/#cosmotech.coal.cosmotech_api.connection","title":"<code>connection</code>","text":""},{"location":"references/coal/cosmotech_api/run/","title":"cosmotech.coal.cosmotech_api.run","text":""},{"location":"references/coal/cosmotech_api/run/#cosmotech.coal.cosmotech_api.run","title":"<code>run</code>","text":""},{"location":"references/coal/cosmotech_api/twin_data_layer/","title":"cosmotech.coal.cosmotech_api.twin_data_layer","text":""},{"location":"references/coal/cosmotech_api/twin_data_layer/#cosmotech.coal.cosmotech_api.twin_data_layer.CSVSourceFile","title":"<code>CSVSourceFile</code>","text":"Source code in <code>cosmotech/coal/cosmotech_api/twin_data_layer.py</code> <pre><code>class CSVSourceFile:\n\n    def __init__(self, file_path: pathlib.Path):\n        self.file_path = file_path\n        if not file_path.name.endswith(\".csv\"):\n            raise ValueError(T(\"coal.errors.validation.not_csv_file\").format(file_path=file_path))\n        with open(file_path) as _file:\n            dr = DictReader(_file)\n            self.fields = list(dr.fieldnames)\n        self.object_type = file_path.name[:-4]\n\n        self.id_column = None\n        self.source_column = None\n        self.target_column = None\n\n        for _c in self.fields:\n            if _c.lower() == ID_COLUMN:\n                self.id_column = _c\n            if _c.lower() == SOURCE_COLUMN:\n                self.source_column = _c\n            if _c.lower() == TARGET_COLUMN:\n                self.target_column = _c\n\n        has_id = self.id_column is not None\n        has_source = self.source_column is not None\n        has_target = self.target_column is not None\n\n        is_relation = all([has_source, has_target])\n\n        if not has_id and not is_relation:\n            LOGGER.error(T(\"coal.errors.validation.invalid_nodes_relations\").format(file_path=file_path))\n            LOGGER.error(T(\"coal.errors.validation.node_requirements\").format(id_column=ID_COLUMN))\n            LOGGER.error(T(\"coal.errors.validation.relationship_requirements\").format(\n                id_column=ID_COLUMN,\n                source_column=SOURCE_COLUMN,\n                target_column=TARGET_COLUMN\n            ))\n            raise ValueError(T(\"coal.errors.validation.invalid_nodes_relations\").format(file_path=file_path))\n\n        self.is_node = has_id and not is_relation\n\n        self.content_fields = {_f: _f for _f in self.fields if\n                               _f not in [self.id_column, self.source_column, self.target_column]}\n        if has_id:\n            self.content_fields[ID_COLUMN] = self.id_column\n        if is_relation:\n            self.content_fields[SOURCE_COLUMN] = self.source_column\n            self.content_fields[TARGET_COLUMN] = self.target_column\n\n    def reload(self, inplace: bool = False) -&gt; 'CSVSourceFile':\n        if inplace:\n            self.__init__(self.file_path)\n            return self\n        return CSVSourceFile(self.file_path)\n\n    def generate_query_insert(self) -&gt; str:\n        \"\"\"\n        Read a CSV file headers and generate a CREATE cypher query\n        :return: the Cypher query for CREATE\n        \"\"\"\n\n        field_names = sorted(self.content_fields.keys(), key=len, reverse=True)\n\n        if self.is_node:\n            query = (\"CREATE (:\" + self.object_type + \" {\" + \", \".join(\n                f\"{property_name}: ${self.content_fields[property_name]}\" for property_name in field_names) + \"})\")\n            # query = (\"UNWIND $params AS params \" +\n            #          f\"MERGE (n:{self.object_type}) \" +\n            #          \"SET n += params\")\n        else:\n            query = (\"MATCH \" +\n                     \"(source {\" + ID_COLUMN + \":$\" + self.source_column + \"}),\\n\" +\n                     \"(target {\" + ID_COLUMN + \":$\" + self.target_column + \"})\\n\" +\n                     \"CREATE (source)-[rel:\" + self.object_type +\n                     \" {\" + \", \".join(\n                        f\"{property_name}: ${self.content_fields[property_name]}\" for property_name in\n                        field_names) + \"}\" +\n                     \"]-&gt;(target)\\n\")\n            # query = (\"UNWIND $params AS params \" +\n            #          \"MATCH (source {\" + ID_COLUMN + \":params.\" + self.source_column + \"})\\n\" +\n            #          \"MATCH (target {\" + ID_COLUMN + \":params.\" + self.target_column + \"})\\n\" +\n            #          f\"CREATE (from) - [rel:{self.object_type}]-&gt;(to)\" +\n            #          \"SET rel += params\")\n        return query\n</code></pre>"},{"location":"references/coal/cosmotech_api/twin_data_layer/#cosmotech.coal.cosmotech_api.twin_data_layer.CSVSourceFile.generate_query_insert","title":"<code>generate_query_insert()</code>","text":"<p>Read a CSV file headers and generate a CREATE cypher query :return: the Cypher query for CREATE</p> Source code in <code>cosmotech/coal/cosmotech_api/twin_data_layer.py</code> <pre><code>def generate_query_insert(self) -&gt; str:\n    \"\"\"\n    Read a CSV file headers and generate a CREATE cypher query\n    :return: the Cypher query for CREATE\n    \"\"\"\n\n    field_names = sorted(self.content_fields.keys(), key=len, reverse=True)\n\n    if self.is_node:\n        query = (\"CREATE (:\" + self.object_type + \" {\" + \", \".join(\n            f\"{property_name}: ${self.content_fields[property_name]}\" for property_name in field_names) + \"})\")\n        # query = (\"UNWIND $params AS params \" +\n        #          f\"MERGE (n:{self.object_type}) \" +\n        #          \"SET n += params\")\n    else:\n        query = (\"MATCH \" +\n                 \"(source {\" + ID_COLUMN + \":$\" + self.source_column + \"}),\\n\" +\n                 \"(target {\" + ID_COLUMN + \":$\" + self.target_column + \"})\\n\" +\n                 \"CREATE (source)-[rel:\" + self.object_type +\n                 \" {\" + \", \".join(\n                    f\"{property_name}: ${self.content_fields[property_name]}\" for property_name in\n                    field_names) + \"}\" +\n                 \"]-&gt;(target)\\n\")\n        # query = (\"UNWIND $params AS params \" +\n        #          \"MATCH (source {\" + ID_COLUMN + \":params.\" + self.source_column + \"})\\n\" +\n        #          \"MATCH (target {\" + ID_COLUMN + \":params.\" + self.target_column + \"})\\n\" +\n        #          f\"CREATE (from) - [rel:{self.object_type}]-&gt;(to)\" +\n        #          \"SET rel += params\")\n    return query\n</code></pre>"},{"location":"references/coal/cosmotech_api/workspace/","title":"cosmotech.coal.cosmotech_api.workspace","text":""},{"location":"references/coal/cosmotech_api/workspace/#cosmotech.coal.cosmotech_api.workspace","title":"<code>workspace</code>","text":""},{"location":"references/coal/cosmotech_api/workspace/#cosmotech.coal.cosmotech_api.workspace.download_workspace_file","title":"<code>download_workspace_file(api_client, organization_id, workspace_id, file_name, target_dir)</code>","text":"<p>Downloads a given file from a workspace to a given directory If the file is inside a directory in the workspace, sub-directories will be created. :param api_client: An api client used to connect to the Cosmo Tech API :param organization_id: An ID of an Organization in the Cosmo Tech API :param workspace_id: An ID of a Workspace in the Cosmo Tech API :param file_name: The file to download to the workspace :param target_dir: The directory in which to write the file :return: The path to the created file</p> Source code in <code>cosmotech/coal/cosmotech_api/workspace.py</code> <pre><code>def download_workspace_file(\n    api_client: cosmotech_api.api_client.ApiClient,\n    organization_id: str,\n    workspace_id: str,\n    file_name: str,\n    target_dir: pathlib.Path\n) -&gt; pathlib.Path:\n    \"\"\"\n    Downloads a given file from a workspace to a given directory\n    If the file is inside a directory in the workspace, sub-directories will be created.\n    :param api_client: An api client used to connect to the Cosmo Tech API\n    :param organization_id: An ID of an Organization in the Cosmo Tech API\n    :param workspace_id: An ID of a Workspace in the Cosmo Tech API\n    :param file_name: The file to download to the workspace\n    :param target_dir: The directory in which to write the file\n    :return: The path to the created file\n    \"\"\"\n    if target_dir.is_file():\n        raise ValueError(T(\"coal.errors.file_system.not_directory\").format(target_dir=target_dir))\n    api_ws = cosmotech_api.api.workspace_api.WorkspaceApi(api_client)\n\n    LOGGER.info(T(\"coal.logs.workspace.loading_file\").format(file_name=file_name))\n\n    _file_content = api_ws.download_workspace_file(organization_id,\n                                                   workspace_id,\n                                                   file_name)\n\n    local_target_file = target_dir / file_name\n    local_target_file.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(local_target_file, \"wb\") as _file:\n        _file.write(_file_content)\n\n    LOGGER.info(T(\"coal.logs.workspace.file_loaded\").format(file=local_target_file))\n\n    return local_target_file\n</code></pre>"},{"location":"references/coal/cosmotech_api/workspace/#cosmotech.coal.cosmotech_api.workspace.list_workspace_files","title":"<code>list_workspace_files(api_client, organization_id, workspace_id, file_prefix)</code>","text":"<p>Helper function to list all workspace files using a pre-given file prefix :param api_client: An api client used to connect to the Cosmo Tech API :param organization_id: An ID of an Organization in the Cosmo Tech API :param workspace_id: An ID of a Workspace in the Cosmo Tech API :param file_prefix: The prefix of the files to find in the Workspace :return: A list of existing files inside the workspace</p> Source code in <code>cosmotech/coal/cosmotech_api/workspace.py</code> <pre><code>def list_workspace_files(\n    api_client: cosmotech_api.api_client.ApiClient,\n    organization_id: str,\n    workspace_id: str,\n    file_prefix: str\n) -&gt; list[str]:\n    \"\"\"\n    Helper function to list all workspace files using a pre-given file prefix\n    :param api_client: An api client used to connect to the Cosmo Tech API\n    :param organization_id: An ID of an Organization in the Cosmo Tech API\n    :param workspace_id: An ID of a Workspace in the Cosmo Tech API\n    :param file_prefix: The prefix of the files to find in the Workspace\n    :return: A list of existing files inside the workspace\n    \"\"\"\n    target_list = []\n    api_ws = cosmotech_api.api.workspace_api.WorkspaceApi(api_client)\n    LOGGER.info(T(\"coal.logs.workspace.target_is_folder\"))\n    wsf = api_ws.find_all_workspace_files(organization_id,\n                                          workspace_id)\n    for workspace_file in wsf:\n        if workspace_file.file_name.startswith(file_prefix):\n            target_list.append(workspace_file.file_name)\n\n    if not target_list:\n        LOGGER.error(T(\"coal.errors.data.no_workspace_files\").format(file_prefix=file_prefix))\n        raise ValueError(T(\"coal.errors.data.no_workspace_files\").format(\n            file_prefix=file_prefix,\n            workspace_id=workspace_id\n        ))\n\n    return target_list\n</code></pre>"},{"location":"references/coal/cosmotech_api/workspace/#cosmotech.coal.cosmotech_api.workspace.upload_workspace_file","title":"<code>upload_workspace_file(api_client, organization_id, workspace_id, file_path, workspace_path, overwrite=True)</code>","text":"<p>Upload a local file to a given workspace</p> <p>If workspace_path ends with a \"/\" it will be considered as a folder inside the workspace  and the file will keep its current name</p> <p>:param api_client: An api client used to connect to the Cosmo Tech API :param organization_id: An ID of an Organization in the Cosmo Tech API :param workspace_id: An ID of a Workspace in the Cosmo Tech API :param file_path: Path to the file to upload in the workspace :param workspace_path: The path inside the workspace to upload the file to :param overwrite: Overwrite existing file in the workspace :return: The final name of the file uploaded to the workspace</p> Source code in <code>cosmotech/coal/cosmotech_api/workspace.py</code> <pre><code>def upload_workspace_file(\n    api_client: cosmotech_api.api_client.ApiClient,\n    organization_id: str,\n    workspace_id: str,\n    file_path: str,\n    workspace_path: str,\n    overwrite: bool = True\n) -&gt; str:\n    \"\"\"\n    Upload a local file to a given workspace\n\n    If workspace_path ends with a \"/\" it will be considered as a folder inside the workspace \n    and the file will keep its current name\n\n    :param api_client: An api client used to connect to the Cosmo Tech API\n    :param organization_id: An ID of an Organization in the Cosmo Tech API\n    :param workspace_id: An ID of a Workspace in the Cosmo Tech API\n    :param file_path: Path to the file to upload in the workspace\n    :param workspace_path: The path inside the workspace to upload the file to\n    :param overwrite: Overwrite existing file in the workspace\n    :return: The final name of the file uploaded to the workspace\n    \"\"\"\n    target_file = pathlib.Path(file_path)\n    if not target_file.exists():\n        LOGGER.error(T(\"coal.errors.file_system.file_not_exists\").format(file_path=file_path))\n        raise ValueError(T(\"coal.errors.file_system.file_not_exists\").format(file_path=file_path))\n    if not target_file.is_file():\n        LOGGER.error(T(\"coal.errors.file_system.not_single_file\").format(file_path=file_path))\n        raise ValueError(T(\"coal.errors.file_system.not_single_file\").format(file_path=file_path))\n\n    api_ws = cosmotech_api.api.workspace_api.WorkspaceApi(api_client)\n    destination = workspace_path + target_file.name if workspace_path.endswith(\"/\") else workspace_path\n\n    LOGGER.info(T(\"coal.logs.workspace.sending_to_api\").format(destination=destination))\n    try:\n        _file = api_ws.upload_workspace_file(organization_id,\n                                             workspace_id,\n                                             file_path,\n                                             overwrite,\n                                             destination=destination)\n    except cosmotech_api.exceptions.ApiException as e:\n        LOGGER.error(T(\"coal.errors.file_system.file_exists\").format(csv_path=destination))\n        raise e\n\n    LOGGER.info(T(\"coal.logs.workspace.file_sent\").format(file=_file.file_name))\n    return _file.file_name\n</code></pre>"},{"location":"references/coal/cosmotech_api/dataset/utils/","title":"cosmotech.coal.cosmotech_api.dataset.utils","text":""},{"location":"references/coal/cosmotech_api/dataset/utils/#cosmotech.coal.cosmotech_api.dataset.utils","title":"<code>utils</code>","text":""},{"location":"references/coal/cosmotech_api/dataset/utils/#cosmotech.coal.cosmotech_api.dataset.utils.get_content_from_twin_graph_data","title":"<code>get_content_from_twin_graph_data(nodes, relationships, restore_names=False)</code>","text":"<p>Extract content from twin graph data.</p> <p>When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)</p> <p>Example with a sample of cypher response: [{   n: {     id: \"50\"  &lt;-- this id is used if restore_names is False     label: \"Customer\"     properties: {       Satisfaction: 0       SurroundingSatisfaction: 0       Thirsty: false       id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True     }     type: \"NODE\"   } }]</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>List[Dict]</code> <p>List of node data from cypher query</p> required <code>relationships</code> <code>List[Dict]</code> <p>List of relationship data from cypher query</p> required <code>restore_names</code> <code>bool</code> <p>Whether to use property ID instead of node ID</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, List[Dict]]</code> <p>Dict mapping entity types to lists of entities</p> Source code in <code>cosmotech/coal/cosmotech_api/dataset/utils.py</code> <pre><code>def get_content_from_twin_graph_data(nodes: List[Dict], relationships: List[Dict], restore_names: bool = False) -&gt; Dict[str, List[Dict]]:\n    \"\"\"\n    Extract content from twin graph data.\n\n    When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used\n    instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function\n    keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)\n\n    Example with a sample of cypher response:\n    [{\n      n: {\n        id: \"50\"  &lt;-- this id is used if restore_names is False\n        label: \"Customer\"\n        properties: {\n          Satisfaction: 0\n          SurroundingSatisfaction: 0\n          Thirsty: false\n          id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True\n        }\n        type: \"NODE\"\n      }\n    }]\n\n    Args:\n        nodes: List of node data from cypher query\n        relationships: List of relationship data from cypher query\n        restore_names: Whether to use property ID instead of node ID\n\n    Returns:\n        Dict mapping entity types to lists of entities\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.dataset.processing_graph_data\").format(\n        nodes_count=len(nodes),\n        relationships_count=len(relationships),\n        restore_names=restore_names\n    ))\n\n    content = dict()\n    # build keys\n    for item in relationships:\n        content[item['src']['label']] = list()\n        content[item['dest']['label']] = list()\n        content[item['rel']['label']] = list()\n\n    # Process nodes\n    for item in nodes:\n        label = item['n']['label']\n        props = item['n']['properties'].copy()  # Create a copy to avoid modifying the original\n        if not restore_names:\n            props.update({'id': item['n']['id']})\n        content.setdefault(label, list())\n        content[label].append(props)\n\n    # Process relationships\n    for item in relationships:\n        src = item['src']\n        dest = item['dest']\n        rel = item['rel']\n        props = rel['properties'].copy()  # Create a copy to avoid modifying the original\n        content[rel['label']].append({\n            'id': rel['id'],\n            'source': src['properties']['id'] if restore_names else src['id'],\n            'target': dest['properties']['id'] if restore_names else dest['id'],\n            **props\n        })\n\n    # Log the number of entities by type\n    for entity_type, entities in content.items():\n        LOGGER.debug(T(\"coal.logs.dataset.entity_count\").format(\n            entity_type=entity_type,\n            count=len(entities)\n        ))\n\n    return content\n</code></pre>"},{"location":"references/coal/cosmotech_api/dataset/utils/#cosmotech.coal.cosmotech_api.dataset.utils.sheet_to_header","title":"<code>sheet_to_header(sheet_content)</code>","text":"<p>Extract header fields from sheet content.</p> <p>Parameters:</p> Name Type Description Default <code>sheet_content</code> <code>List[Dict]</code> <p>List of dictionaries representing sheet rows</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of field names with id, source, and target fields first if present</p> Source code in <code>cosmotech/coal/cosmotech_api/dataset/utils.py</code> <pre><code>def sheet_to_header(sheet_content: List[Dict]) -&gt; List[str]:\n    \"\"\"\n    Extract header fields from sheet content.\n\n    Args:\n        sheet_content: List of dictionaries representing sheet rows\n\n    Returns:\n        List of field names with id, source, and target fields first if present\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.dataset.extracting_headers\").format(rows=len(sheet_content)))\n\n    fieldnames = []\n    has_src = False\n    has_id = False\n\n    for r in sheet_content:\n        for k in r.keys():\n            if k not in fieldnames:\n                if k in ['source', 'target']:\n                    has_src = True\n                elif k == \"id\":\n                    has_id = True\n                else:\n                    fieldnames.append(k)\n\n    # Ensure source/target and id fields come first\n    if has_src:\n        fieldnames = ['source', 'target'] + fieldnames\n    if has_id:\n        fieldnames = ['id'] + fieldnames\n\n    LOGGER.debug(T(\"coal.logs.dataset.headers_extracted\").format(\n        count=len(fieldnames),\n        fields=\", \".join(fieldnames[:5]) + (\"...\" if len(fieldnames) &gt; 5 else \"\")\n    ))\n\n    return fieldnames\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/metadata/","title":"cosmotech.coal.cosmotech_api.runner.metadata","text":""},{"location":"references/coal/cosmotech_api/runner/metadata/#cosmotech.coal.cosmotech_api.runner.metadata","title":"<code>metadata</code>","text":"<p>Runner metadata retrieval functions.</p>"},{"location":"references/coal/cosmotech_api/runner/metadata/#cosmotech.coal.cosmotech_api.runner.metadata.get_runner_metadata","title":"<code>get_runner_metadata(api_client, organization_id, workspace_id, runner_id, include=None, exclude=None)</code>","text":"<p>Get runner metadata from the API.</p> <p>Parameters:</p> Name Type Description Default <code>api_client</code> <code>ApiClient</code> <p>The API client to use</p> required <code>organization_id</code> <code>str</code> <p>The ID of the organization</p> required <code>workspace_id</code> <code>str</code> <p>The ID of the workspace</p> required <code>runner_id</code> <code>str</code> <p>The ID of the runner</p> required <code>include</code> <code>Optional[list[str]]</code> <p>Optional list of fields to include</p> <code>None</code> <code>exclude</code> <code>Optional[list[str]]</code> <p>Optional list of fields to exclude</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with runner metadata</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/metadata.py</code> <pre><code>def get_runner_metadata(\n    api_client: cosmotech_api.api_client.ApiClient,\n    organization_id: str,\n    workspace_id: str,\n    runner_id: str,\n    include: Optional[list[str]] = None,\n    exclude: Optional[list[str]] = None,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Get runner metadata from the API.\n\n    Args:\n        api_client: The API client to use\n        organization_id: The ID of the organization\n        workspace_id: The ID of the workspace\n        runner_id: The ID of the runner\n        include: Optional list of fields to include\n        exclude: Optional list of fields to exclude\n\n    Returns:\n        Dictionary with runner metadata\n    \"\"\"\n    runner_api = cosmotech_api.RunnerApi(api_client)\n    runner: cosmotech_api.Runner = runner_api.get_runner(organization_id,\n                                                         workspace_id,\n                                                         runner_id)\n\n    return runner.model_dump(by_alias=True, exclude_none=True, include=include, exclude=exclude, mode='json')\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/parameters/","title":"cosmotech.coal.cosmotech_api.runner.parameters","text":""},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters","title":"<code>parameters</code>","text":"<p>Parameter handling functions.</p>"},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters.format_parameters_list","title":"<code>format_parameters_list(runner_data)</code>","text":"<p>Format parameters from runner data as a list of dictionaries.</p> <p>Parameters:</p> Name Type Description Default <code>runner_data</code> <p>Runner data object</p> required <p>Returns:</p> Type Description <code>List[Dict[str, Any]]</code> <p>List of parameter dictionaries</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/parameters.py</code> <pre><code>def format_parameters_list(runner_data) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Format parameters from runner data as a list of dictionaries.\n\n    Args:\n        runner_data: Runner data object\n\n    Returns:\n        List of parameter dictionaries\n    \"\"\"\n    parameters = []\n\n    if not runner_data.parameters_values:\n        return parameters\n\n    max_name_size = max(map(lambda r: len(r.parameter_id), runner_data.parameters_values))\n    max_type_size = max(map(lambda r: len(r.var_type), runner_data.parameters_values))\n\n    for parameter_data in runner_data.parameters_values:\n        parameter_name = parameter_data.parameter_id\n        value = parameter_data.value\n        var_type = parameter_data.var_type\n        is_inherited = parameter_data.is_inherited\n\n        parameters.append({\n            \"parameterId\": parameter_name,\n            \"value\": value,\n            \"varType\": var_type,\n            \"isInherited\": is_inherited\n        })\n\n        LOGGER.debug(T(\"coal.logs.runner.parameter_debug\").format(\n            param_id=parameter_name,\n            max_name_size=max_name_size,\n            var_type=var_type,\n            max_type_size=max_type_size,\n            value=value,\n            inherited=' inherited' if is_inherited else ''\n        ))\n\n    return parameters\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters.get_runner_parameters","title":"<code>get_runner_parameters(runner_data)</code>","text":"<p>Extract parameters from runner data.</p> <p>Parameters:</p> Name Type Description Default <code>runner_data</code> <p>Runner data object</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary mapping parameter IDs to values</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/parameters.py</code> <pre><code>def get_runner_parameters(runner_data) -&gt; Dict[str, Any]:\n    \"\"\"\n    Extract parameters from runner data.\n\n    Args:\n        runner_data: Runner data object\n\n    Returns:\n        Dictionary mapping parameter IDs to values\n    \"\"\"\n    content = dict()\n    for parameter in runner_data.parameters_values:\n        content[parameter.parameter_id] = parameter.value\n    return content\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters.write_parameters","title":"<code>write_parameters(parameter_folder, parameters, write_csv=True, write_json=False)</code>","text":"<p>Write parameters to files based on specified formats.</p> <p>Parameters:</p> Name Type Description Default <code>parameter_folder</code> <code>str</code> <p>Folder to write the files to</p> required <code>parameters</code> <code>List[Dict[str, Any]]</code> <p>List of parameter dictionaries</p> required <code>write_csv</code> <code>bool</code> <p>Whether to write a CSV file</p> <code>True</code> <code>write_json</code> <code>bool</code> <p>Whether to write a JSON file</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary mapping file types to file paths</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/parameters.py</code> <pre><code>def write_parameters(parameter_folder: str, parameters: List[Dict[str, Any]], \n                    write_csv: bool = True, write_json: bool = False) -&gt; Dict[str, str]:\n    \"\"\"\n    Write parameters to files based on specified formats.\n\n    Args:\n        parameter_folder: Folder to write the files to\n        parameters: List of parameter dictionaries\n        write_csv: Whether to write a CSV file\n        write_json: Whether to write a JSON file\n\n    Returns:\n        Dictionary mapping file types to file paths\n    \"\"\"\n    result = {}\n\n    if write_csv:\n        result['csv'] = write_parameters_to_csv(parameter_folder, parameters)\n\n    if write_json:\n        result['json'] = write_parameters_to_json(parameter_folder, parameters)\n\n    return result\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters.write_parameters_to_csv","title":"<code>write_parameters_to_csv(parameter_folder, parameters)</code>","text":"<p>Write parameters to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>parameter_folder</code> <code>str</code> <p>Folder to write the file to</p> required <code>parameters</code> <code>List[Dict[str, Any]]</code> <p>List of parameter dictionaries</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the created file</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/parameters.py</code> <pre><code>def write_parameters_to_csv(parameter_folder: str, parameters: List[Dict[str, Any]]) -&gt; str:\n    \"\"\"\n    Write parameters to a CSV file.\n\n    Args:\n        parameter_folder: Folder to write the file to\n        parameters: List of parameter dictionaries\n\n    Returns:\n        Path to the created file\n    \"\"\"\n    pathlib.Path(parameter_folder).mkdir(exist_ok=True, parents=True)\n    tmp_parameter_file = os.path.join(parameter_folder, \"parameters.csv\")\n\n    LOGGER.info(T(\"coal.logs.runner.generating_file\").format(file=tmp_parameter_file))\n\n    with open(tmp_parameter_file, \"w\") as _file:\n        _w = DictWriter(_file, fieldnames=[\"parameterId\", \"value\", \"varType\", \"isInherited\"])\n        _w.writeheader()\n        _w.writerows(parameters)\n\n    return tmp_parameter_file\n</code></pre>"},{"location":"references/coal/cosmotech_api/runner/parameters/#cosmotech.coal.cosmotech_api.runner.parameters.write_parameters_to_json","title":"<code>write_parameters_to_json(parameter_folder, parameters)</code>","text":"<p>Write parameters to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>parameter_folder</code> <code>str</code> <p>Folder to write the file to</p> required <code>parameters</code> <code>List[Dict[str, Any]]</code> <p>List of parameter dictionaries</p> required <p>Returns:</p> Type Description <code>str</code> <p>Path to the created file</p> Source code in <code>cosmotech/coal/cosmotech_api/runner/parameters.py</code> <pre><code>def write_parameters_to_json(parameter_folder: str, parameters: List[Dict[str, Any]]) -&gt; str:\n    \"\"\"\n    Write parameters to a JSON file.\n\n    Args:\n        parameter_folder: Folder to write the file to\n        parameters: List of parameter dictionaries\n\n    Returns:\n        Path to the created file\n    \"\"\"\n    pathlib.Path(parameter_folder).mkdir(exist_ok=True, parents=True)\n    tmp_parameter_file = os.path.join(parameter_folder, \"parameters.json\")\n\n    LOGGER.info(T(\"coal.logs.runner.generating_file\").format(file=tmp_parameter_file))\n\n    with open(tmp_parameter_file, \"w\") as _file:\n        json.dump(parameters, _file, indent=2)\n\n    return tmp_parameter_file\n</code></pre>"},{"location":"references/coal/csm/engine/","title":"cosmotech.coal.csm.engine","text":""},{"location":"references/coal/csm/engine/#cosmotech.coal.csm.engine","title":"<code>engine</code>","text":""},{"location":"references/coal/csm/engine/#cosmotech.coal.csm.engine.apply_simple_csv_parameter_to_simulator","title":"<code>apply_simple_csv_parameter_to_simulator(simulator, parameter_name, target_attribute_name, csv_id_column='id', csv_value_column='value')</code>","text":"<p>Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None</p> Source code in <code>cosmotech/coal/csm/engine/__init__.py</code> <pre><code>def apply_simple_csv_parameter_to_simulator(\n    simulator,\n    parameter_name: str,\n    target_attribute_name: str,\n    csv_id_column: str = \"id\",\n    csv_value_column: str = \"value\"\n    ):\n    \"\"\"\n    Accelerator used to apply CSV parameters directly to a simulator\n    Will raise a ValueError if the parameter does not exist\n    If an entity is not found, will skip the row in the CSV\n    :param simulator: The simulator object to which the parameter will be applied\n    :param parameter_name: The name of the parameter fetched from the API\n    :param target_attribute_name: Target attribute of the entities listed in the CSV\n    :param csv_id_column: Column in the CSV file used for the entity ID\n    :param csv_value_column: Column in the CSV file used for the attribute value to change\n    :return: None\n    \"\"\"\n    parameter_path = os.path.join(os.environ.get(\"CSM_PARAMETERS_ABSOLUTE_PATH\"), parameter_name)\n    if os.path.exists(parameter_path):\n        csv_files = glob.glob(os.path.join(parameter_path, \"*.csv\"))\n        for csv_filename in csv_files:\n            model = simulator.GetModel()\n            with open(csv_filename, \"r\") as csv_file:\n                for row in csv.DictReader(csv_file):\n                    entity_name = row.get(csv_id_column)\n                    value = json.loads(row.get(csv_value_column))\n                    entity = model.FindEntityByName(entity_name)\n                    if entity:\n                        entity.SetAttributeAsString(target_attribute_name, json.dumps(value))\n    else:\n        raise ValueError(f\"Parameter {parameter_name} does not exists.\")\n</code></pre>"},{"location":"references/coal/dataset/utils/","title":"cosmotech.coal.dataset.utils","text":""},{"location":"references/coal/dataset/utils/#cosmotech.coal.dataset.utils","title":"<code>utils</code>","text":""},{"location":"references/coal/dataset/utils/#cosmotech.coal.dataset.utils.get_content_from_twin_graph_data","title":"<code>get_content_from_twin_graph_data(nodes, relationships, restore_names=False)</code>","text":"<p>Extract content from twin graph data.</p> <p>When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)</p> <p>Example with a sample of cypher response: [{   n: {     id: \"50\"  &lt;-- this id is used if restore_names is False     label: \"Customer\"     properties: {       Satisfaction: 0       SurroundingSatisfaction: 0       Thirsty: false       id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True     }     type: \"NODE\"   } }]</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>List[Dict]</code> <p>List of node data from cypher query</p> required <code>relationships</code> <code>List[Dict]</code> <p>List of relationship data from cypher query</p> required <code>restore_names</code> <code>bool</code> <p>Whether to use property ID instead of node ID</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, List[Dict]]</code> <p>Dict mapping entity types to lists of entities</p> Source code in <code>cosmotech/coal/dataset/utils.py</code> <pre><code>def get_content_from_twin_graph_data(nodes: List[Dict], relationships: List[Dict], restore_names: bool = False) -&gt; Dict[str, List[Dict]]:\n    \"\"\"\n    Extract content from twin graph data.\n\n    When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used\n    instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function\n    keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)\n\n    Example with a sample of cypher response:\n    [{\n      n: {\n        id: \"50\"  &lt;-- this id is used if restore_names is False\n        label: \"Customer\"\n        properties: {\n          Satisfaction: 0\n          SurroundingSatisfaction: 0\n          Thirsty: false\n          id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True\n        }\n        type: \"NODE\"\n      }\n    }]\n\n    Args:\n        nodes: List of node data from cypher query\n        relationships: List of relationship data from cypher query\n        restore_names: Whether to use property ID instead of node ID\n\n    Returns:\n        Dict mapping entity types to lists of entities\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.dataset.processing_graph_data\").format(\n        nodes_count=len(nodes),\n        relationships_count=len(relationships),\n        restore_names=restore_names\n    ))\n\n    content = dict()\n    # build keys\n    for item in relationships:\n        content[item['src']['label']] = list()\n        content[item['dest']['label']] = list()\n        content[item['rel']['label']] = list()\n\n    # Process nodes\n    for item in nodes:\n        label = item['n']['label']\n        props = item['n']['properties'].copy()  # Create a copy to avoid modifying the original\n        if not restore_names:\n            props.update({'id': item['n']['id']})\n        content.setdefault(label, list())\n        content[label].append(props)\n\n    # Process relationships\n    for item in relationships:\n        src = item['src']\n        dest = item['dest']\n        rel = item['rel']\n        props = rel['properties'].copy()  # Create a copy to avoid modifying the original\n        content[rel['label']].append({\n            'id': rel['id'],\n            'source': src['properties']['id'] if restore_names else src['id'],\n            'target': dest['properties']['id'] if restore_names else dest['id'],\n            **props\n        })\n\n    # Log the number of entities by type\n    for entity_type, entities in content.items():\n        LOGGER.debug(T(\"coal.logs.dataset.entity_count\").format(\n            entity_type=entity_type,\n            count=len(entities)\n        ))\n\n    return content\n</code></pre>"},{"location":"references/coal/dataset/utils/#cosmotech.coal.dataset.utils.sheet_to_header","title":"<code>sheet_to_header(sheet_content)</code>","text":"<p>Extract header fields from sheet content.</p> <p>Parameters:</p> Name Type Description Default <code>sheet_content</code> <code>List[Dict]</code> <p>List of dictionaries representing sheet rows</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List of field names with id, source, and target fields first if present</p> Source code in <code>cosmotech/coal/dataset/utils.py</code> <pre><code>def sheet_to_header(sheet_content: List[Dict]) -&gt; List[str]:\n    \"\"\"\n    Extract header fields from sheet content.\n\n    Args:\n        sheet_content: List of dictionaries representing sheet rows\n\n    Returns:\n        List of field names with id, source, and target fields first if present\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.dataset.extracting_headers\").format(rows=len(sheet_content)))\n\n    fieldnames = []\n    has_src = False\n    has_id = False\n\n    for r in sheet_content:\n        for k in r.keys():\n            if k not in fieldnames:\n                if k in ['source', 'target']:\n                    has_src = True\n                elif k == \"id\":\n                    has_id = True\n                else:\n                    fieldnames.append(k)\n\n    # Ensure source/target and id fields come first\n    if has_src:\n        fieldnames = ['source', 'target'] + fieldnames\n    if has_id:\n        fieldnames = ['id'] + fieldnames\n\n    LOGGER.debug(T(\"coal.logs.dataset.headers_extracted\").format(\n        count=len(fieldnames),\n        fields=\", \".join(fieldnames[:5]) + (\"...\" if len(fieldnames) &gt; 5 else \"\")\n    ))\n\n    return fieldnames\n</code></pre>"},{"location":"references/coal/store/csv/","title":"cosmotech.coal.store.csv","text":""},{"location":"references/coal/store/csv/#cosmotech.coal.store.csv","title":"<code>csv</code>","text":""},{"location":"references/coal/store/native_python/","title":"cosmotech.coal.store.native_python","text":""},{"location":"references/coal/store/native_python/#cosmotech.coal.store.native_python","title":"<code>native_python</code>","text":""},{"location":"references/coal/store/pandas/","title":"cosmotech.coal.store.pandas","text":""},{"location":"references/coal/store/pandas/#cosmotech.coal.store.pandas","title":"<code>pandas</code>","text":""},{"location":"references/coal/store/pyarrow/","title":"cosmotech.coal.store.pyarrow","text":""},{"location":"references/coal/store/pyarrow/#cosmotech.coal.store.pyarrow","title":"<code>pyarrow</code>","text":""},{"location":"references/coal/store/store/","title":"cosmotech.coal.store.store","text":""},{"location":"references/coal/store/store/#cosmotech.coal.store.store.Store","title":"<code>Store</code>","text":"Source code in <code>cosmotech/coal/store/store.py</code> <pre><code>class Store:\n\n    @staticmethod\n    def sanitize_column(column_name: str) -&gt; str:\n        return column_name.replace(\" \", \"_\")\n\n    def __init__(\n        self,\n        reset=False,\n        store_location: pathlib.Path = pathlib.Path(os.environ.get(\"CSM_PARAMETERS_ABSOLUTE_PATH\",\n                                                                   \".\"))\n    ):\n        self.store_location = pathlib.Path(store_location) / \".coal/store\"\n        self.store_location.mkdir(parents=True, exist_ok=True)\n        self._tables = dict()\n        self._database_path = self.store_location / \"db.sqlite\"\n        if reset:\n            self.reset()\n        self._database = str(self._database_path)\n\n    def reset(self):\n        if self._database_path.exists():\n            self._database_path.unlink()\n\n    def get_table(self, table_name: str) -&gt; pyarrow.Table:\n        if not self.table_exists(table_name):\n            raise ValueError(T(\"coal.errors.data.no_table\").format(table_name=table_name))\n        return self.execute_query(f\"select * from {table_name}\")\n\n    def table_exists(self, table_name) -&gt; bool:\n        return table_name in self.list_tables()\n\n    def get_table_schema(self, table_name: str) -&gt; pyarrow.Schema:\n        if not self.table_exists(table_name):\n            raise ValueError(T(\"coal.errors.data.no_table\").format(table_name=table_name))\n        with dbapi.connect(self._database) as conn:\n            return conn.adbc_get_table_schema(table_name)\n\n    def add_table(self, table_name: str, data=pyarrow.Table, replace: bool = False):\n        with dbapi.connect(self._database, autocommit=True) as conn:\n            with conn.cursor() as curs:\n                rows = curs.adbc_ingest(table_name, data, \"replace\" if replace else \"create_append\")\n                LOGGER.debug(T(\"coal.logs.data_transfer.rows_inserted\").format(rows=rows, table_name=table_name))\n\n    def execute_query(self, sql_query: str) -&gt; pyarrow.Table:\n        batch_size = 1024\n        batch_size_increment = 1024\n        while True:\n            try:\n                with dbapi.connect(self._database, autocommit=True) as conn:\n                    with conn.cursor() as curs:\n                        curs.adbc_statement.set_options(**{\"adbc.sqlite.query.batch_rows\":str(batch_size)})\n                        curs.execute(sql_query)\n                        return curs.fetch_arrow_table()\n            except OSError:\n                batch_size += batch_size_increment\n\n    def list_tables(self) -&gt; list[str]:\n        with dbapi.connect(self._database) as conn:\n            objects = conn.adbc_get_objects(depth=\"all\").read_all()\n            tables = objects[\"catalog_db_schemas\"][0][0][\"db_schema_tables\"]\n        for table in tables:\n            table_name: pyarrow.StringScalar = table[\"table_name\"]\n            yield table_name.as_py()\n</code></pre>"},{"location":"references/coal/utils/postgresql/","title":"cosmotech.coal.utils.postgresql","text":""},{"location":"references/coal/utils/postgresql/#cosmotech.coal.utils.postgresql","title":"<code>postgresql</code>","text":""},{"location":"references/coal/utils/postgresql/#cosmotech.coal.utils.postgresql.adapt_table_to_schema","title":"<code>adapt_table_to_schema(data, target_schema)</code>","text":"<p>Adapt a PyArrow table to match a target schema with detailed logging.</p> Source code in <code>cosmotech/coal/utils/postgresql.py</code> <pre><code>def adapt_table_to_schema(\n    data: pa.Table,\n    target_schema: pa.Schema\n) -&gt; pa.Table:\n    \"\"\"\n    Adapt a PyArrow table to match a target schema with detailed logging.\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.postgresql.schema_adaptation_start\").format(rows=len(data)))\n    LOGGER.debug(T(\"coal.logs.postgresql.original_schema\").format(schema=data.schema))\n    LOGGER.debug(T(\"coal.logs.postgresql.target_schema\").format(schema=target_schema))\n\n    target_fields = {field.name: field.type for field in target_schema}\n    new_columns = []\n\n    # Track adaptations for summary\n    added_columns = []\n    dropped_columns = []\n    type_conversions = []\n    failed_conversions = []\n\n    # Process each field in target schema\n    for field_name, target_type in target_fields.items():\n        if field_name in data.column_names:\n            # Column exists - try to cast to target type\n            col = data[field_name]\n            original_type = col.type\n\n            if original_type != target_type:\n                LOGGER.debug(\n                    T(\"coal.logs.postgresql.casting_column\").format(\n                        field_name=field_name,\n                        original_type=original_type,\n                        target_type=target_type\n                    )\n                )\n                try:\n                    new_col = pa.compute.cast(col, target_type)\n                    new_columns.append(new_col)\n                    type_conversions.append(\n                        f\"{field_name}: {original_type} -&gt; {target_type}\"\n                    )\n                except pa.ArrowInvalid as e:\n                    LOGGER.warning(\n                        T(\"coal.logs.postgresql.cast_failed\").format(\n                            field_name=field_name,\n                            original_type=original_type,\n                            target_type=target_type,\n                            error=str(e)\n                        )\n                    )\n                    new_columns.append(pa.nulls(len(data), type=target_type))\n                    failed_conversions.append(\n                        f\"{field_name}: {original_type} -&gt; {target_type}\"\n                    )\n            else:\n                new_columns.append(col)\n        else:\n            # Column doesn't exist - add nulls\n            LOGGER.debug(T(\"coal.logs.postgresql.adding_missing_column\").format(field_name=field_name))\n            new_columns.append(pa.nulls(len(data), type=target_type))\n            added_columns.append(field_name)\n\n    # Log columns that will be dropped\n    dropped_columns = [\n        name for name in data.column_names\n        if name not in target_fields\n    ]\n    if dropped_columns:\n        LOGGER.debug(\n            T(\"coal.logs.postgresql.dropping_columns\").format(columns=dropped_columns)\n        )\n\n    # Create new table\n    adapted_table = pa.Table.from_arrays(\n        new_columns,\n        schema=target_schema\n    )\n\n    # Log summary of adaptations\n    LOGGER.debug(T(\"coal.logs.postgresql.adaptation_summary\"))\n    if added_columns:\n        LOGGER.debug(T(\"coal.logs.postgresql.added_columns\").format(columns=added_columns))\n    if dropped_columns:\n        LOGGER.debug(T(\"coal.logs.postgresql.dropped_columns\").format(columns=dropped_columns))\n    if type_conversions:\n        LOGGER.debug(T(\"coal.logs.postgresql.successful_conversions\").format(conversions=type_conversions))\n    if failed_conversions:\n        LOGGER.debug(\n            T(\"coal.logs.postgresql.failed_conversions\").format(conversions=failed_conversions)\n        )\n\n    LOGGER.debug(T(\"coal.logs.postgresql.final_schema\").format(schema=adapted_table.schema))\n    return adapted_table\n</code></pre>"},{"location":"references/coal/utils/postgresql/#cosmotech.coal.utils.postgresql.get_postgresql_table_schema","title":"<code>get_postgresql_table_schema(target_table_name, postgres_host, postgres_port, postgres_db, postgres_schema, postgres_user, postgres_password)</code>","text":"<p>Get the schema of an existing PostgreSQL table using SQL queries.</p> <p>Parameters:</p> Name Type Description Default <code>target_table_name</code> <code>str</code> <p>Name of the table</p> required <code>postgres_host</code> <code>str</code> <p>PostgreSQL host</p> required <code>postgres_port</code> <code>str</code> <p>PostgreSQL port</p> required <code>postgres_db</code> <code>str</code> <p>PostgreSQL database name</p> required <code>postgres_schema</code> <code>str</code> <p>PostgreSQL schema name</p> required <code>postgres_user</code> <code>str</code> <p>PostgreSQL username</p> required <code>postgres_password</code> <code>str</code> <p>PostgreSQL password</p> required <p>Returns:</p> Type Description <code>Optional[Schema]</code> <p>PyArrow Schema if table exists, None otherwise</p> Source code in <code>cosmotech/coal/utils/postgresql.py</code> <pre><code>def get_postgresql_table_schema(\n    target_table_name: str,\n    postgres_host: str,\n    postgres_port: str,\n    postgres_db: str,\n    postgres_schema: str,\n    postgres_user: str,\n    postgres_password: str,\n) -&gt; Optional[pa.Schema]:\n    \"\"\"\n    Get the schema of an existing PostgreSQL table using SQL queries.\n\n    Args:\n        target_table_name: Name of the table\n        postgres_host: PostgreSQL host\n        postgres_port: PostgreSQL port\n        postgres_db: PostgreSQL database name\n        postgres_schema: PostgreSQL schema name\n        postgres_user: PostgreSQL username\n        postgres_password: PostgreSQL password\n\n    Returns:\n        PyArrow Schema if table exists, None otherwise\n    \"\"\"\n    LOGGER.debug(T(\"coal.logs.postgresql.getting_schema\").format(\n        postgres_schema=postgres_schema,\n        target_table_name=target_table_name\n    ))\n\n    postgresql_full_uri = generate_postgresql_full_uri(postgres_host,\n                                                       postgres_port,\n                                                       postgres_db,\n                                                       postgres_user,\n                                                       postgres_password)\n\n    with (dbapi.connect(postgresql_full_uri) as conn):\n        try:\n            catalog = conn.adbc_get_objects(depth=\"tables\",\n                                            catalog_filter=postgres_db,\n                                            db_schema_filter=postgres_schema,\n                                            table_name_filter=target_table_name).read_all().to_pylist()[0]\n            schema = catalog[\"catalog_db_schemas\"][0]\n            table = schema[\"db_schema_tables\"][0]\n            if table[\"table_name\"] == target_table_name:\n                return conn.adbc_get_table_schema(\n                    target_table_name,\n                    db_schema_filter=postgres_schema,\n                )\n        except IndexError:\n            LOGGER.warning(T(\"coal.logs.postgresql.table_not_found\").format(\n                postgres_schema=postgres_schema,\n                target_table_name=target_table_name\n            ))\n        return None\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>A list of tutorials for concepts added to CoAL</p> <p> csm-data</p> <p>Make full use of <code>csm-data</code> commands to connect to services during your orchestration runs</p> <p> csm-data</p> <p> Data store</p> <p>The datastore is your friend to keep data between orchestration steps. It comes with multiple ways to interact with it.</p> <p> Datastore</p>"},{"location":"tutorials/csm-data/","title":"CSM-DATA","text":"<p>Objective</p> <ul> <li>Understand what the csm-data CLI is and its capabilities</li> <li>Learn how to use the various command groups for different data management tasks</li> <li>Explore common use cases and workflows</li> <li>Master integration with CosmoTech platform services</li> </ul>"},{"location":"tutorials/csm-data/#what-is-csm-data","title":"What is csm-data?","text":"<p><code>csm-data</code> is a powerful Command Line Interface (CLI) bundled inside the CosmoTech Acceleration Library (CoAL). It provides a comprehensive set of commands designed to streamline interactions with various services used within a CosmoTech platform.</p> <p>The CLI is organized into several command groups, each focused on specific types of data operations:</p> <ul> <li>api: Commands for interacting with the CosmoTech API</li> <li>store: Commands for working with the CoAL datastore</li> <li>s3-bucket-*: Commands for S3 bucket operations (download, upload, delete)</li> <li>adx-send-scenariodata: Command for sending scenario data to Azure Data Explorer</li> <li>az-storage-upload: Command for uploading to Azure Storage</li> </ul> <p>Getting Help</p> <p>You can get detailed help for any command using the <code>--help</code> flag: <pre><code>csm-data --help\ncsm-data api --help\ncsm-data api scenariorun-load-data --help\n</code></pre></p>"},{"location":"tutorials/csm-data/#why-use-csm-data","title":"Why use csm-data?","text":""},{"location":"tutorials/csm-data/#standardized-interactions","title":"Standardized Interactions","text":"<p>The <code>csm-data</code> CLI provides tested, standardized interactions with multiple services used in CosmoTech simulations. This eliminates the need to:</p> <ul> <li>Write custom code for common data operations</li> <li>Handle authentication and connection details for each service</li> <li>Manage error handling and retries</li> <li>Deal with format conversions between services</li> </ul>"},{"location":"tutorials/csm-data/#environment-variable-support","title":"Environment Variable Support","text":"<p>Most commands support environment variables, making them ideal for:</p> <ul> <li>Integration with orchestration tools like <code>csm-orc</code></li> <li>Use in Docker containers and cloud environments</li> <li>Secure handling of credentials and connection strings</li> <li>Consistent configuration across development and production</li> </ul>"},{"location":"tutorials/csm-data/#workflow-automation","title":"Workflow Automation","text":"<p>The commands are designed to work together in data processing pipelines, enabling you to:</p> <ul> <li>Download data from various sources</li> <li>Transform and process the data</li> <li>Store results in different storage systems</li> <li>Send data to visualization and analysis services</li> </ul>"},{"location":"tutorials/csm-data/#command-groups-and-use-cases","title":"Command Groups and Use Cases","text":""},{"location":"tutorials/csm-data/#api-commands","title":"API Commands","text":"<p>The <code>api</code> command group facilitates interaction with the CosmoTech API, allowing you to work with scenarios, datasets, and other API resources.</p>"},{"location":"tutorials/csm-data/#scenario-data-management","title":"Scenario Data Management","text":"Download scenario data<pre><code>csm-data api scenariorun-load-data \\\n  --organization-id \"o-organization\" \\\n  --workspace-id \"w-workspace\" \\\n  --scenario-id \"s-scenario\" \\\n  --dataset-absolute-path \"/path/to/dataset/folder\" \\\n  --parameters-absolute-path \"/path/to/parameters/folder\" \\\n  --write-json \\\n  --write-csv \\\n  --fetch-dataset\n</code></pre> <p>This command: - Downloads scenario parameters and datasets from the CosmoTech API - Writes parameters as JSON and/or CSV files - Fetches associated datasets</p> <p>Common Use Case</p> <p>This command is particularly useful in container environments where you need to initialize your simulation with data from the platform. The environment variables are typically set by the platform when launching the container.</p>"},{"location":"tutorials/csm-data/#twin-data-layer-operations","title":"Twin Data Layer Operations","text":"Load files to Twin Data Layer<pre><code>csm-data api tdl-load-files \\\n  --organization-id \"o-organization\" \\\n  --workspace-id \"w-workspace\" \\\n  --dataset-id \"d-dataset\" \\\n  --source-folder \"/path/to/source/files\"\n</code></pre> Send files to Twin Data Layer<pre><code>csm-data api tdl-send-files \\\n  --organization-id \"o-organization\" \\\n  --workspace-id \"w-workspace\" \\\n  --dataset-id \"d-dataset\" \\\n  --source-folder \"/path/to/source/files\"\n</code></pre> <p>These commands facilitate working with the Twin Data Layer, allowing you to: - Load data from the Twin Data Layer to local files - Send local files to the Twin Data Layer</p>"},{"location":"tutorials/csm-data/#storage-commands","title":"Storage Commands","text":"<p>The <code>s3-bucket-*</code> commands provide a simple interface for working with S3-compatible storage:</p> DownloadUploadDelete Download from S3 bucket<pre><code>csm-data s3-bucket-download \\\n  --target-folder \"/path/to/download/to\" \\\n  --bucket-name \"my-bucket\" \\\n  --prefix-filter \"folder/prefix/\" \\\n  --s3-url \"https://s3.example.com\" \\\n  --access-id \"access-key-id\" \\\n  --secret-key \"secret-access-key\"\n</code></pre> Upload to S3 bucket<pre><code>csm-data s3-bucket-upload \\\n  --source-folder \"/path/to/upload/from\" \\\n  --bucket-name \"my-bucket\" \\\n  --target-prefix \"folder/prefix/\" \\\n  --s3-url \"https://s3.example.com\" \\\n  --access-id \"access-key-id\" \\\n  --secret-key \"secret-access-key\"\n</code></pre> Delete from S3 bucket<pre><code>csm-data s3-bucket-delete \\\n  --bucket-name \"my-bucket\" \\\n  --prefix-filter \"folder/prefix/\" \\\n  --s3-url \"https://s3.example.com\" \\\n  --access-id \"access-key-id\" \\\n  --secret-key \"secret-access-key\"\n</code></pre> <p>Environment Variables</p> <p>All these commands support environment variables for credentials and connection details, making them secure and easy to use in automated workflows: <pre><code>export AWS_ENDPOINT_URL=\"https://s3.example.com\"\nexport AWS_ACCESS_KEY_ID=\"access-key-id\"\nexport AWS_SECRET_ACCESS_KEY=\"secret-access-key\"\nexport CSM_DATA_BUCKET_NAME=\"my-bucket\"\n</code></pre></p>"},{"location":"tutorials/csm-data/#azure-data-explorer-integration","title":"Azure Data Explorer Integration","text":"<p>The <code>adx-send-scenariodata</code> command enables sending scenario data to Azure Data Explorer for analysis and visualization:</p> Send scenario data to ADX<pre><code>csm-data adx-send-scenariodata \\\n  --dataset-absolute-path \"/path/to/dataset/folder\" \\\n  --parameters-absolute-path \"/path/to/parameters/folder\" \\\n  --simulation-id \"simulation-id\" \\\n  --adx-uri \"https://adx.example.com\" \\\n  --adx-ingest-uri \"https://ingest-adx.example.com\" \\\n  --database-name \"my-database\" \\\n  --send-datasets \\\n  --wait\n</code></pre> <p>This command: - Creates tables in ADX based on CSV files in the dataset and/or parameters folders - Ingests the data into those tables - Adds a <code>simulationrun</code> column with the simulation ID for tracking - Optionally waits for ingestion to complete</p> <p>Table Creation</p> <p>This command will create tables in ADX based on the CSV file names and headers. Ensure your CSV files have appropriate headers and follow naming conventions suitable for ADX tables.</p>"},{"location":"tutorials/csm-data/#datastore-commands","title":"Datastore Commands","text":"<p>The <code>store</code> command group provides tools for working with the CoAL datastore:</p> Load CSV folder into datastore<pre><code>csm-data store load-csv-folder \\\n  --folder-path \"/path/to/csv/folder\" \\\n  --reset\n</code></pre> Dump datastore to S3<pre><code>csm-data store dump-to-s3 \\\n  --bucket-name \"my-bucket\" \\\n  --target-prefix \"store-dump/\" \\\n  --s3-url \"https://s3.example.com\" \\\n  --access-id \"access-key-id\" \\\n  --secret-key \"secret-access-key\"\n</code></pre> <p>These commands allow you to: - Load data from CSV files into the datastore - Dump datastore contents to various destinations (S3, Azure, PostgreSQL) - List tables in the datastore - Reset the datastore</p>"},{"location":"tutorials/csm-data/#common-workflows-and-integration-patterns","title":"Common Workflows and Integration Patterns","text":""},{"location":"tutorials/csm-data/#scenario-data-processing-pipeline","title":"Scenario Data Processing Pipeline","text":"<p>A common workflow combines multiple commands to create a complete data processing pipeline:</p> Complete data processing pipeline<pre><code># 1. Download scenario data from the API\ncsm-data api scenariorun-load-data \\\n  --organization-id \"$CSM_ORGANIZATION_ID\" \\\n  --workspace-id \"$CSM_WORKSPACE_ID\" \\\n  --scenario-id \"$CSM_SCENARIO_ID\" \\\n  --dataset-absolute-path \"$CSM_DATASET_ABSOLUTE_PATH\" \\\n  --parameters-absolute-path \"$CSM_PARAMETERS_ABSOLUTE_PATH\" \\\n  --write-json \\\n  --fetch-dataset\n\n# 2. Load data into the datastore for processing\ncsm-data store load-csv-folder \\\n  --folder-path \"$CSM_DATASET_ABSOLUTE_PATH\" \\\n  --reset\n\n# 3. Run your simulation (using your own code)\n# ...\n\n# 4. Send results to Azure Data Explorer for analysis\ncsm-data adx-send-scenariodata \\\n  --dataset-absolute-path \"$CSM_DATASET_ABSOLUTE_PATH\" \\\n  --parameters-absolute-path \"$CSM_PARAMETERS_ABSOLUTE_PATH\" \\\n  --simulation-id \"$CSM_SIMULATION_ID\" \\\n  --adx-uri \"$AZURE_DATA_EXPLORER_RESOURCE_URI\" \\\n  --adx-ingest-uri \"$AZURE_DATA_EXPLORER_RESOURCE_INGEST_URI\" \\\n  --database-name \"$AZURE_DATA_EXPLORER_DATABASE_NAME\" \\\n  --send-datasets \\\n  --wait\n</code></pre>"},{"location":"tutorials/csm-data/#integration-with-csm-orc","title":"Integration with csm-orc","text":"<p>The <code>csm-data</code> commands integrate seamlessly with <code>csm-orc</code> for orchestration:</p> run.json for csm-orc<pre><code>{\n  \"steps\": [\n    {\n      \"id\": \"download-scenario-data\",\n      \"command\": \"csm-data\",\n      \"arguments\": [\n        \"api\", \"scenariorun-load-data\",\n        \"--write-json\",\n        \"--fetch-dataset\"\n      ],\n      \"useSystemEnvironment\": true\n    },\n    {\n      \"id\": \"run-simulation\",\n      \"command\": \"python\",\n      \"arguments\": [\"run_simulation.py\"],\n      \"precedents\": [\"download-scenario-data\"]\n    },\n    {\n      \"id\": \"send-results-to-adx\",\n      \"command\": \"csm-data\",\n      \"arguments\": [\n        \"adx-send-scenariodata\",\n        \"--send-datasets\",\n        \"--wait\"\n      ],\n      \"useSystemEnvironment\": true,\n      \"precedents\": [\"run-simulation\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"tutorials/csm-data/#best-practices-and-tips","title":"Best Practices and Tips","text":"<p>Environment Variables</p> <p>Use environment variables for sensitive information and configuration that might change between environments: <pre><code># API connection\nexport CSM_ORGANIZATION_ID=\"o-organization\"\nexport CSM_WORKSPACE_ID=\"w-workspace\"\nexport CSM_SCENARIO_ID=\"s-scenario\"\n\n# Paths\nexport CSM_DATASET_ABSOLUTE_PATH=\"/path/to/dataset\"\nexport CSM_PARAMETERS_ABSOLUTE_PATH=\"/path/to/parameters\"\n\n# ADX connection\nexport AZURE_DATA_EXPLORER_RESOURCE_URI=\"https://adx.example.com\"\nexport AZURE_DATA_EXPLORER_RESOURCE_INGEST_URI=\"https://ingest-adx.example.com\"\nexport AZURE_DATA_EXPLORER_DATABASE_NAME=\"my-database\"\n</code></pre></p> <p>Error Handling</p> <p>Most commands will exit with a non-zero status code on failure, making them suitable for use in scripts and orchestration tools that check exit codes.</p> <p>Logging</p> <p>Control the verbosity of logging with the <code>--log-level</code> option: <pre><code>csm-data --log-level debug api scenariorun-load-data ...\n</code></pre></p>"},{"location":"tutorials/csm-data/#extending-csm-data","title":"Extending csm-data","text":"<p>If the existing commands don't exactly match your needs, you have several options:</p> <ol> <li>Use as a basis: Examine the code of similar commands and use it as a starting point for your own scripts</li> <li>Combine commands: Use shell scripting to combine multiple commands into a custom workflow</li> <li>Environment variables: Customize behavior through environment variables without modifying the code</li> <li>Contribute: Consider contributing enhancements back to the CoAL project</li> </ol>"},{"location":"tutorials/csm-data/#conclusion","title":"Conclusion","text":"<p>The <code>csm-data</code> CLI provides a powerful set of tools for managing data in CosmoTech platform environments. By leveraging these commands, you can:</p> <ul> <li>Streamline interactions with platform services</li> <li>Automate data processing workflows</li> <li>Integrate with orchestration tools</li> <li>Focus on your simulation logic rather than data handling</li> </ul> <p>Whether you're developing locally or deploying to production, <code>csm-data</code> offers a consistent interface for your data management needs.</p>"},{"location":"tutorials/datastore/","title":"Datastore","text":"<p>Objective</p> <ul> <li>Understand what the CoAL datastore is and its capabilities</li> <li>Learn how to store and retrieve data in various formats</li> <li>Master SQL querying capabilities for data analysis</li> <li>Build efficient data processing pipelines</li> </ul>"},{"location":"tutorials/datastore/#what-is-the-datastore","title":"What is the datastore?","text":"<p>The datastore is a powerful data management abstraction that provides a unified interface to a SQLite database. It allows you to store, retrieve, transform, and query tabular data in various formats through a consistent API.</p> <p>The core idea behind the datastore is to provide a robust, flexible system for data management that simplifies working with different data formats while offering persistence and advanced query capabilities.</p> <p>Key Features</p> <ul> <li>Format flexibility (Python dictionaries, CSV files, Pandas DataFrames, PyArrow Tables)</li> <li>Persistent storage in SQLite</li> <li>SQL query capabilities</li> <li>Simplified data pipeline management</li> </ul>"},{"location":"tutorials/datastore/#why-use-the-datastore","title":"Why use the datastore?","text":""},{"location":"tutorials/datastore/#format-flexibility","title":"Format Flexibility","text":"<p>The datastore works seamlessly with multiple data formats:</p> <ul> <li>Python dictionaries and lists</li> <li>CSV files</li> <li>Pandas DataFrames</li> <li>PyArrow Tables</li> </ul> <p>This flexibility eliminates the need for manual format conversions and allows you to work with data in your preferred format.</p>"},{"location":"tutorials/datastore/#persistence-and-performance","title":"Persistence and Performance","text":"<p>Instead of keeping all your data in memory or writing/reading from files repeatedly, the datastore:</p> <ul> <li>Persists data in a SQLite database</li> <li>Provides efficient storage and retrieval</li> <li>Handles large datasets that might not fit in memory</li> <li>Maintains data between application runs</li> </ul>"},{"location":"tutorials/datastore/#sql-query-capabilities","title":"SQL Query Capabilities","text":"<p>The datastore leverages the power of SQL:</p> <ul> <li>Filter, aggregate, join, and transform data using familiar SQL syntax</li> <li>Execute complex queries without writing custom data manipulation code</li> <li>Perform operations that would be cumbersome with file-based approaches</li> </ul>"},{"location":"tutorials/datastore/#simplified-data-pipeline","title":"Simplified Data Pipeline","text":"<p>The datastore serves as a central hub in your data processing pipeline:</p> <ul> <li>Import data from various sources</li> <li>Transform and clean data</li> <li>Query and analyze data</li> <li>Export results in different formats</li> </ul>"},{"location":"tutorials/datastore/#basic-example","title":"Basic example","text":"Basic use of the datastore<pre><code>from cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.native_python import store_pylist\n\n# We initialize and reset the data store\nmy_datastore = Store(reset=True)\n\n# We create a simple list of dict data\nmy_data = [{\n    \"foo\": \"bar\"\n},{\n    \"foo\": \"barbar\"\n},{\n    \"foo\": \"world\"\n},{\n    \"foo\": \"bar\"\n}]\n\n# We use a bundled method to send the py_list to the store\nstore_pylist(\"my_data\", my_data)\n\n# We can make a sql query over our data\n# Store.execute_query returns a pyarrow.Table object so we can make use of Table.to_pylist to get an equivalent format\nresults = my_datastore.execute_query(\"SELECT foo, count(*) as line_count FROM my_data GROUP BY foo\").to_pylist()\n\n# We can print our results now\nprint(results)\n# &gt; [{'foo': 'bar', 'line_count': 2}, {'foo': 'barbar', 'line_count': 1}, {'foo': 'world', 'line_count': 1}]\n</code></pre>"},{"location":"tutorials/datastore/#working-with-different-data-formats","title":"Working with different data formats","text":"<p>The datastore provides specialized adapters for working with various data formats:</p>"},{"location":"tutorials/datastore/#csv-files","title":"CSV Files","text":"Working with CSV files<pre><code>import pathlib\nfrom cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.csv import store_csv_file, convert_store_table_to_csv\n\n# Initialize the store\nstore = Store(reset=True)\n\n# Load data from a CSV file\ncsv_path = pathlib.Path(\"path/to/your/data.csv\")\nstore_csv_file(\"customers\", csv_path)\n\n# Query the data\nhigh_value_customers = store.execute_query(\"\"\"\n    SELECT * FROM customers \n    WHERE annual_spend &gt; 10000\n    ORDER BY annual_spend DESC\n\"\"\")\n\n# Export results to a new CSV file\noutput_path = pathlib.Path(\"path/to/output/high_value_customers.csv\")\nconvert_store_table_to_csv(\"high_value_customers\", output_path)\n</code></pre>"},{"location":"tutorials/datastore/#pandas-dataframes","title":"Pandas DataFrames","text":"Working with pandas DataFrames<pre><code>import pandas as pd\nfrom cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.pandas import store_dataframe, convert_store_table_to_dataframe\n\n# Initialize the store\nstore = Store(reset=True)\n\n# Create a pandas DataFrame\ndf = pd.DataFrame({\n    'product_id': [1, 2, 3, 4, 5],\n    'product_name': ['Widget A', 'Widget B', 'Gadget X', 'Tool Y', 'Device Z'],\n    'price': [19.99, 29.99, 99.99, 49.99, 199.99],\n    'category': ['Widgets', 'Widgets', 'Gadgets', 'Tools', 'Devices']\n})\n\n# Store the DataFrame\nstore_dataframe(\"products\", df)\n\n# Query the data\nexpensive_products = store.execute_query(\"\"\"\n    SELECT * FROM products\n    WHERE price &gt; 50\n    ORDER BY price DESC\n\"\"\")\n\n# Convert results back to a pandas DataFrame for further analysis\nexpensive_df = convert_store_table_to_dataframe(\"expensive_products\", store)\n\n# Use pandas methods on the result\nprint(expensive_df.describe())\n</code></pre>"},{"location":"tutorials/datastore/#pyarrow-tables","title":"PyArrow Tables","text":"Working with PyArrow Tables directly<pre><code>import pyarrow as pa\nfrom cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.pyarrow import store_table\n\n# Initialize the store\nstore = Store(reset=True)\n\n# Create a PyArrow Table\ndata = {\n    'date': pa.array(['2023-01-01', '2023-01-02', '2023-01-03']),\n    'value': pa.array([100, 150, 200]),\n    'category': pa.array(['A', 'B', 'A'])\n}\ntable = pa.Table.from_pydict(data)\n\n# Store the table\nstore_table(\"time_series\", table)\n\n# Query and retrieve data\nresult = store.execute_query(\"\"\"\n    SELECT date, SUM(value) as total_value\n    FROM time_series\n    GROUP BY date\n\"\"\")\n\nprint(result)\n</code></pre>"},{"location":"tutorials/datastore/#advanced-use-cases","title":"Advanced use cases","text":""},{"location":"tutorials/datastore/#joining-multiple-tables","title":"Joining multiple tables","text":"Joining tables in the datastore<pre><code>from cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.native_python import store_pylist\n\nstore = Store(reset=True)\n\n# Store customer data\ncustomers = [\n    {\"customer_id\": 1, \"name\": \"Acme Corp\", \"segment\": \"Enterprise\"},\n    {\"customer_id\": 2, \"name\": \"Small Shop\", \"segment\": \"SMB\"},\n    {\"customer_id\": 3, \"name\": \"Tech Giant\", \"segment\": \"Enterprise\"}\n]\nstore_pylist(\"customers\", customers, store=store)\n\n# Store order data\norders = [\n    {\"order_id\": 101, \"customer_id\": 1, \"amount\": 5000},\n    {\"order_id\": 102, \"customer_id\": 2, \"amount\": 500},\n    {\"order_id\": 103, \"customer_id\": 1, \"amount\": 7500},\n    {\"order_id\": 104, \"customer_id\": 3, \"amount\": 10000}\n]\nstore_pylist(\"orders\", orders, store=store)\n\n# Join tables to analyze orders by customer segment\nresults = store.execute_query(\"\"\"\n    SELECT c.segment, COUNT(o.order_id) as order_count, SUM(o.amount) as total_revenue\n    FROM customers c\n    JOIN orders o ON c.customer_id = o.customer_id\n    GROUP BY c.segment\n\"\"\").to_pylist()\n\nprint(results)\n# &gt; [{'segment': 'Enterprise', 'order_count': 3, 'total_revenue': 22500}, {'segment': 'SMB', 'order_count': 1, 'total_revenue': 500}]\n</code></pre>"},{"location":"tutorials/datastore/#data-transformation-pipeline","title":"Data transformation pipeline","text":"Complete pipelineStep-by-step Building a data transformation pipeline<pre><code>from cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.native_python import store_pylist, convert_table_as_pylist\nimport pathlib\nfrom cosmotech.coal.store.csv import store_csv_file, convert_store_table_to_csv\n\n# Initialize the store\nstore = Store(reset=True)\n\n# 1. Load raw data from CSV\nraw_data_path = pathlib.Path(\"path/to/raw_data.csv\")\nstore_csv_file(\"raw_data\", raw_data_path, store=store)\n\n# 2. Clean and transform the data\nstore.execute_query(\"\"\"\n    CREATE TABLE cleaned_data AS\n    SELECT \n        id,\n        TRIM(name) as name,\n        UPPER(category) as category,\n        CASE WHEN value &lt; 0 THEN 0 ELSE value END as value\n    FROM raw_data\n    WHERE id IS NOT NULL\n\"\"\")\n\n# 3. Aggregate the data\nstore.execute_query(\"\"\"\n    CREATE TABLE summary_data AS\n    SELECT\n        category,\n        COUNT(*) as count,\n        AVG(value) as avg_value,\n        SUM(value) as total_value\n    FROM cleaned_data\n    GROUP BY category\n\"\"\")\n\n# 4. Export the results\nsummary_data = convert_table_as_pylist(\"summary_data\", store=store)\nprint(summary_data)\n\n# 5. Save to CSV for reporting\noutput_path = pathlib.Path(\"path/to/output/summary.csv\")\nconvert_store_table_to_csv(\"summary_data\", output_path, store=store)\n</code></pre> Step 1: Load data<pre><code>from cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.csv import store_csv_file\nimport pathlib\n\n# Initialize the store\nstore = Store(reset=True)\n\n# Load raw data from CSV\nraw_data_path = pathlib.Path(\"path/to/raw_data.csv\")\nstore_csv_file(\"raw_data\", raw_data_path, store=store)\n</code></pre> Step 2: Clean data<pre><code># Clean and transform the data\nstore.execute_query(\"\"\"\n    CREATE TABLE cleaned_data AS\n    SELECT \n        id,\n        TRIM(name) as name,\n        UPPER(category) as category,\n        CASE WHEN value &lt; 0 THEN 0 ELSE value END as value\n    FROM raw_data\n    WHERE id IS NOT NULL\n\"\"\")\n</code></pre> Step 3: Aggregate data<pre><code># Aggregate the data\nstore.execute_query(\"\"\"\n    CREATE TABLE summary_data AS\n    SELECT\n        category,\n        COUNT(*) as count,\n        AVG(value) as avg_value,\n        SUM(value) as total_value\n    FROM cleaned_data\n    GROUP BY category\n\"\"\")\n</code></pre> Step 4: Export results<pre><code>from cosmotech.coal.store.native_python import convert_table_as_pylist\nfrom cosmotech.coal.store.csv import convert_store_table_to_csv\nimport pathlib\n\n# Export to Python list\nsummary_data = convert_table_as_pylist(\"summary_data\", store=store)\nprint(summary_data)\n\n# Save to CSV for reporting\noutput_path = pathlib.Path(\"path/to/output/summary.csv\")\nconvert_store_table_to_csv(\"summary_data\", output_path, store=store)\n</code></pre>"},{"location":"tutorials/datastore/#best-practices-and-tips","title":"Best practices and tips","text":"<p>Store initialization</p> <ul> <li>Use <code>reset=True</code> when you want to start with a fresh database</li> <li>Omit the reset parameter or set it to <code>False</code> when you want to maintain data between runs</li> <li>Specify a custom location with the <code>store_location</code> parameter if needed</li> </ul> Store initialization options<pre><code># Fresh store each time\nstore = Store(reset=True)\n\n# Persistent store at default location\nstore = Store()\n\n# Persistent store at custom location\nimport pathlib\ncustom_path = pathlib.Path(\"/path/to/custom/location\")\nstore = Store(store_location=custom_path)\n</code></pre> <p>Table management</p> <ul> <li>Use descriptive table names that reflect the data content</li> <li>Check if tables exist before attempting operations</li> <li>List available tables to explore the database</li> </ul> Table management<pre><code># Check if a table exists\nif store.table_exists(\"customers\"):\n    # Do something with the table\n    pass\n\n# List all tables\nfor table_name in store.list_tables():\n    print(f\"Table: {table_name}\")\n    # Get schema information\n    schema = store.get_table_schema(table_name)\n    print(f\"Schema: {schema}\")\n</code></pre> <p>Performance considerations</p> <ul> <li>For large datasets, consider chunking data when loading</li> <li>Use SQL to filter data early rather than loading everything into memory</li> <li>Index frequently queried columns for better performance</li> </ul> Handling large datasets<pre><code># Example of chunking data load\nchunk_size = 10000\nfor i in range(0, len(large_dataset), chunk_size):\n    chunk = large_dataset[i:i+chunk_size]\n    store_pylist(f\"data_chunk_{i//chunk_size}\", chunk, store=store)\n\n# Combine chunks with SQL\nstore.execute_query(\"\"\"\n    CREATE TABLE combined_data AS\n    SELECT * FROM data_chunk_0\n    UNION ALL\n    SELECT * FROM data_chunk_1\n    -- Add more chunks as needed\n\"\"\")\n</code></pre>"},{"location":"tutorials/datastore/#integration-with-cosmotech-ecosystem","title":"Integration with CosmoTech ecosystem","text":"<p>The datastore is designed to work seamlessly with other components of the CosmoTech Acceleration Library:</p> <ul> <li>Data loading: Load data from various sources into the datastore</li> <li>Scenario management: Store scenario parameters and results</li> <li>API integration: Exchange data with CosmoTech APIs</li> <li>Reporting: Generate reports and visualizations from stored data</li> </ul> <p>This integration makes the datastore a central component in CosmoTech-based data processing workflows.</p>"},{"location":"tutorials/datastore/#conclusion","title":"Conclusion","text":"<p>The datastore provides a powerful, flexible foundation for data management in your CosmoTech applications. By leveraging its capabilities, you can:</p> <ul> <li>Simplify data handling across different formats</li> <li>Build robust data processing pipelines</li> <li>Perform complex data transformations and analyses</li> <li>Maintain data persistence between application runs</li> <li>Integrate seamlessly with other CosmoTech components</li> </ul> <p>Whether you're working with small datasets or large-scale data processing tasks, the datastore offers the tools you need to manage your data effectively.</p>"}]}