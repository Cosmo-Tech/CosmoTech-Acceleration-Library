{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cosmotech Acceleration library","text":"<p>Acceleration library for CosmoTech cloud based solution development</p>"},{"location":"#code-organisation","title":"Code organisation","text":"<p>In project root directory you'll find 4 main directories:</p> <ul> <li>CosmoTech_Acceleration_Library: containing all Cosmo Tech libraries to accelerate interaction with Cosmo Tech solutions</li> <li>data: a bunch of csv files on which samples are based</li> <li>samples: a bunch of python scripts to demonstrate how to use the library</li> <li>doc: for schema or specific documentation</li> </ul>"},{"location":"#accelerators","title":"Accelerators","text":"<p>TODO</p>"},{"location":"#modelops-library","title":"Modelops library","text":"<p>The aim of this library is to simplify the model accesses via python code.</p> <p>The library can be used by Data Scientists, Modelers, Developers, ...</p>"},{"location":"#utility-classes","title":"Utility classes","text":"<ul> <li><code>ModelImporter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to bulk import data from csv files with schema enforced (<code>samples/Modelops/Bulk_Import_from_CSV_with_schema.py</code>) or not (<code>samples/Modelops/Bulk_Import_from_CSV_without_schema.py</code>) (see documentation for further details)</li> <li><code>ModelExporter(host: str, port: int, name: str, version: int, export_dir: str = '/')</code> : will allow you to export data from a model cache instance</li> <li><code>ModelReader(host: str, port: int, name: str, version: int)</code> : will allow you to read data from a model cache instance (object returned)</li> <li><code>ModelWriter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to write data into a model instance</li> <li><code>ModelUtil</code> : a bunch of utilities to manipulate and facilitate interaction with model instance (result_set_to_json, print_query_result, ... )</li> <li><code>ModelMetadata</code>: will allow you to management graph metadata</li> </ul>"},{"location":"#how-to","title":"How-to","text":"<p><code>python setup.py install --user</code></p>"},{"location":"dependencies/","title":"List of dependencies","text":"<p>Azure connection requirements </p> <p>Modelops requirements </p> <p>Cosmotech specific requirements </p> <p>Other requirements </p> <p>Documentation generation </p>"},{"location":"references/SUMMARY/","title":"SUMMARY","text":"<ul> <li>References<ul> <li>Modelops<ul> <li>core<ul> <li>common<ul> <li>redis_handler</li> <li>graph_handler</li> <li>writer<ul> <li>CsvWriter</li> </ul> </li> </ul> </li> <li>io<ul> <li>model_reader</li> <li>model_importer</li> <li>model_writer</li> <li>model_exporter</li> </ul> </li> <li>utils<ul> <li>model_util</li> <li>tests<ul> <li>model_util_test</li> </ul> </li> </ul> </li> <li>tests<ul> <li>redis_test</li> </ul> </li> </ul> </li> </ul> </li> <li>Accelerators<ul> <li>csm_engine</li> <li>adx_wrapper</li> <li>cosmo_api</li> <li>scenario_download<ul> <li>azure_function_main</li> <li>scenario_downloader</li> <li>download_command</li> </ul> </li> <li>utils<ul> <li>multi_environment</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"references/Accelerators/adx_wrapper/","title":"CosmoTech_Acceleration_Library.Accelerators.adx_wrapper","text":""},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper","title":"<code>ADXQueriesWrapper</code>","text":"<p>Wrapping class to ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>class ADXQueriesWrapper:\n    \"\"\"\n    Wrapping class to ADX\n    \"\"\"\n\n    def __init__(self,\n                 database: str,\n                 cluster_url: Union[str, None] = None,\n                 ingest_url: Union[str, None] = None,\n                 cluster_name: Union[str, None] = None,\n                 cluster_region: Union[str, None] = None):\n\n        if cluster_name and cluster_region:\n            cluster_url = f\"https://{cluster_name}.{cluster_region}.kusto.windows.net\"\n            ingest_url = f\"https://ingest-{cluster_name}.{cluster_region}.kusto.windows.net\"\n\n        try:\n            az_client_id = os.environ['AZURE_CLIENT_ID']\n            az_client_secret = os.environ['AZURE_CLIENT_SECRET']\n            az_tenant_id = os.environ['AZURE_TENANT_ID']\n\n            self.cluster_kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(cluster_url,\n                                                                                                     az_client_id,\n                                                                                                     az_client_secret,\n                                                                                                     az_tenant_id)\n            self.ingest_kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(ingest_url,\n                                                                                                    az_client_id,\n                                                                                                    az_client_secret,\n                                                                                                    az_tenant_id)\n        except KeyError:\n            self.cluster_kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(cluster_url)\n            self.ingest_kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(ingest_url)\n        self.kusto_client = KustoClient(self.cluster_kcsb)\n        self.ingest_client = QueuedIngestClient(self.ingest_kcsb)\n        self.database = database\n\n        self.timeout = 900\n\n        self.ingest_status = dict()\n        self.ingest_times = dict()\n\n    @staticmethod\n    def type_mapping(key: str, key_example_value) -&gt; str:\n        \"\"\"\n        This method is used to replace the type name from python to the one used in ADX\n        :param key: the name of the key\n        :param key_example_value: a possible value of the key\n        :return: the name of the type used in ADX\n        \"\"\"\n\n        if key == \"SimulationRun\":\n            return \"guid\"\n\n        try:\n            # Use dateutil parser to test if the value could be a date, in case of error it is not\n            dateutil.parser.parse(key_example_value, fuzzy=False)\n            return \"datetime\"\n        except (ValueError, TypeError):\n            pass\n\n        if type(key_example_value) is float:\n            return \"real\"\n\n        if type(key_example_value) is int:\n            return \"long\"\n\n        # Default case to string\n        return \"string\"\n\n    def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                    drop_by_tag: str = None):\n        \"\"\"\n        Will take a list of dict items and send them to a given table in ADX\n        :param dict_list: list of dict objects requiring to have the same keys\n        :param table_name: The name of the table in which the data should be sent\n        :param ignore_table_creation: If set to True won't try to create a table to send the data\n        :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n        :return: A boolean check if the data have been sent to ADX\n        \"\"\"\n\n        if not ignore_table_creation:\n            # If the target table does not exist create it\n            # First create the columns types needed for the table\n            types = {k: self.type_mapping(k, dict_list[0][k]) for k in dict_list[0].keys()}\n            # Then try to create the table\n            if not self.create_table(table_name, types):\n                print(f\"Error creating table {table_name}.\")\n                return False\n\n        # Create a dataframe with the data to write and send them to ADX\n        df = pd.DataFrame(dict_list)\n        ingestion_result = self.ingest_dataframe(table_name, df, drop_by_tag)\n        return ingestion_result\n\n    def ingest_dataframe(self, table_name: str, dataframe: pd.DataFrame, drop_by_tag: str = None):\n        \"\"\"\n        Write the content of dataframe to a table\n        :param table_name: name of the target table\n        :param dataframe: dataframe containing the data to be written\n        :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n        :return: None\n        \"\"\"\n        drop_by_tags = [drop_by_tag] if (drop_by_tag is not None) else None\n        properties = IngestionProperties(database=self.database, table=table_name, data_format=DataFormat.CSV,\n                                         drop_by_tags=drop_by_tags, report_level=ReportLevel.FailuresAndSuccesses)\n        client = self.ingest_client\n        ingestion_result = client.ingest_from_dataframe(dataframe, ingestion_properties=properties)\n        self.ingest_status[str(ingestion_result.source_id)] = IngestionStatus.QUEUED\n        self.ingest_times[str(ingestion_result.source_id)] = time.time()\n        return ingestion_result\n\n    def check_ingestion_status(self, source_ids: list[str],\n                               timeout: int = None,\n                               logs: bool = False) -&gt; Iterator[tuple[str, IngestionStatus]]:\n        remaining_ids = []\n        for source_id in source_ids:\n            if source_id not in self.ingest_status:\n                self.ingest_status[source_id] = IngestionStatus.UNKNOWN\n                self.ingest_times[source_id] = time.time()\n            if self.ingest_status[source_id] not in [IngestionStatus.QUEUED, IngestionStatus.UNKNOWN]:\n                yield source_id, self.ingest_status[source_id]\n            else:\n                remaining_ids.append(source_id)\n\n        qs = KustoIngestStatusQueues(self.ingest_client)\n\n        def get_messages(queues):\n            _r = []\n            for q in queues:\n                _r.extend(((q, m) for m in q.receive_messages(messages_per_page=32, visibility_timeout=1)))\n            return _r\n\n        successes = get_messages(qs.success._get_queues())\n        failures = get_messages(qs.failure._get_queues())\n\n        if logs:\n            print(f\"Success messages: {len(successes)}\")\n            print(f\"Failure messages: {len(failures)}\")\n        non_sent_ids = remaining_ids[:]\n        for messages, cast_func, status in [(successes, SuccessMessage, IngestionStatus.SUCCESS),\n                                            (failures, FailureMessage, IngestionStatus.FAILURE)]:\n            for _q, _m in messages:\n                dm = cast_func(_m.content)\n                to_check_ids = remaining_ids[:]\n                for source_id in to_check_ids:\n                    if dm.IngestionSourceId == str(source_id):\n                        self.ingest_status[source_id] = status\n                        if logs:\n                            print(f\"Found status for {source_id}: {status.value}\")\n                        _q.delete_message(_m)\n                        remaining_ids.remove(source_id)\n                        break\n                else:\n                    # The message did not correspond to a known ID\n                    continue\n                break\n            else:\n                # No message was found on the current list of messages for the given IDs\n                continue\n            break\n        else:\n            for source_id in remaining_ids:\n                if time.time() - self.ingest_times[source_id] &gt; ([timeout, self.timeout][timeout is None]):\n                    self.ingest_status[source_id] = IngestionStatus.TIMEOUT\n        for source_id in non_sent_ids:\n            yield source_id, self.ingest_status[source_id]\n\n    def _clear_ingestion_status_queues(self, confirmation: bool = False):\n        \"\"\"\n        Dangerous operation that will fully clear all data in the ingestion status queues\n        Those queues are common to all databases in the ADX Cluster so don't ut this unless you know what you are doing\n        :param confirmation: Unless confirmation is set to True, won't do anything\n        :return:\n        \"\"\"\n        if confirmation:\n            qs = KustoIngestStatusQueues(self.ingest_client)\n            while not qs.success.is_empty():\n                qs.success.pop(32)\n            while not qs.failure.is_empty():\n                qs.failure.pop(32)\n\n    def run_command_query(self, query: str):\n        \"\"\"\n        Execute a command query on the database\n        :param query: the query to execute\n        :return: the results of the query\n        \"\"\"\n        client = self.kusto_client\n        return client.execute_mgmt(self.database, query)\n\n    def run_query(self, query: str):\n        \"\"\"\n        Execute a simple query on the database\n        :param query: the query to execute\n        :return: the results of the query\n        \"\"\"\n        client = self.kusto_client\n        return client.execute(self.database, query)\n\n    def table_exists(self, table_name: str) -&gt; bool:\n        \"\"\"\n        Check if a table exists on the database\n        :param table_name: The table to look for\n        :return: does the table exits ?\n        \"\"\"\n        get_tables_query = f\".show database ['{self.database}'] schema| distinct TableName\"\n        tables = self.run_query(get_tables_query)\n        for r in tables.primary_results[0]:\n            if table_name == r[0]:\n                return True\n        return False\n\n    def create_table(self, table_name: str, schema: dict) -&gt; bool:\n        \"\"\"\n        Create a table on the database\n        :param table_name: the name of the table\n        :param schema: the schema associated to the table\n        :return: Is the table created ?\n        \"\"\"\n        create_query = f\".create-merge table {table_name}(\"\n        for column_name, column_type in schema.items():\n            create_query += f\"{column_name}:{column_type},\"\n        create_query = create_query[:-1] + \")\"\n        try:\n            self.run_query(create_query)\n        except Exception as e:\n            print(e)\n            return False\n        return True\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.create_table","title":"<code>create_table(table_name, schema)</code>","text":"<p>Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ?</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def create_table(self, table_name: str, schema: dict) -&gt; bool:\n    \"\"\"\n    Create a table on the database\n    :param table_name: the name of the table\n    :param schema: the schema associated to the table\n    :return: Is the table created ?\n    \"\"\"\n    create_query = f\".create-merge table {table_name}(\"\n    for column_name, column_type in schema.items():\n        create_query += f\"{column_name}:{column_type},\"\n    create_query = create_query[:-1] + \")\"\n    try:\n        self.run_query(create_query)\n    except Exception as e:\n        print(e)\n        return False\n    return True\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.ingest_dataframe","title":"<code>ingest_dataframe(table_name, dataframe, drop_by_tag=None)</code>","text":"<p>Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def ingest_dataframe(self, table_name: str, dataframe: pd.DataFrame, drop_by_tag: str = None):\n    \"\"\"\n    Write the content of dataframe to a table\n    :param table_name: name of the target table\n    :param dataframe: dataframe containing the data to be written\n    :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n    :return: None\n    \"\"\"\n    drop_by_tags = [drop_by_tag] if (drop_by_tag is not None) else None\n    properties = IngestionProperties(database=self.database, table=table_name, data_format=DataFormat.CSV,\n                                     drop_by_tags=drop_by_tags, report_level=ReportLevel.FailuresAndSuccesses)\n    client = self.ingest_client\n    ingestion_result = client.ingest_from_dataframe(dataframe, ingestion_properties=properties)\n    self.ingest_status[str(ingestion_result.source_id)] = IngestionStatus.QUEUED\n    self.ingest_times[str(ingestion_result.source_id)] = time.time()\n    return ingestion_result\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_command_query","title":"<code>run_command_query(query)</code>","text":"<p>Execute a command query on the database :param query: the query to execute :return: the results of the query</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def run_command_query(self, query: str):\n    \"\"\"\n    Execute a command query on the database\n    :param query: the query to execute\n    :return: the results of the query\n    \"\"\"\n    client = self.kusto_client\n    return client.execute_mgmt(self.database, query)\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_query","title":"<code>run_query(query)</code>","text":"<p>Execute a simple query on the database :param query: the query to execute :return: the results of the query</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def run_query(self, query: str):\n    \"\"\"\n    Execute a simple query on the database\n    :param query: the query to execute\n    :return: the results of the query\n    \"\"\"\n    client = self.kusto_client\n    return client.execute(self.database, query)\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.send_to_adx","title":"<code>send_to_adx(dict_list, table_name, ignore_table_creation=True, drop_by_tag=None)</code>","text":"<p>Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                drop_by_tag: str = None):\n    \"\"\"\n    Will take a list of dict items and send them to a given table in ADX\n    :param dict_list: list of dict objects requiring to have the same keys\n    :param table_name: The name of the table in which the data should be sent\n    :param ignore_table_creation: If set to True won't try to create a table to send the data\n    :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n    :return: A boolean check if the data have been sent to ADX\n    \"\"\"\n\n    if not ignore_table_creation:\n        # If the target table does not exist create it\n        # First create the columns types needed for the table\n        types = {k: self.type_mapping(k, dict_list[0][k]) for k in dict_list[0].keys()}\n        # Then try to create the table\n        if not self.create_table(table_name, types):\n            print(f\"Error creating table {table_name}.\")\n            return False\n\n    # Create a dataframe with the data to write and send them to ADX\n    df = pd.DataFrame(dict_list)\n    ingestion_result = self.ingest_dataframe(table_name, df, drop_by_tag)\n    return ingestion_result\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.table_exists","title":"<code>table_exists(table_name)</code>","text":"<p>Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ?</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def table_exists(self, table_name: str) -&gt; bool:\n    \"\"\"\n    Check if a table exists on the database\n    :param table_name: The table to look for\n    :return: does the table exits ?\n    \"\"\"\n    get_tables_query = f\".show database ['{self.database}'] schema| distinct TableName\"\n    tables = self.run_query(get_tables_query)\n    for r in tables.primary_results[0]:\n        if table_name == r[0]:\n            return True\n    return False\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.type_mapping","title":"<code>type_mapping(key, key_example_value)</code>  <code>staticmethod</code>","text":"<p>This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>@staticmethod\ndef type_mapping(key: str, key_example_value) -&gt; str:\n    \"\"\"\n    This method is used to replace the type name from python to the one used in ADX\n    :param key: the name of the key\n    :param key_example_value: a possible value of the key\n    :return: the name of the type used in ADX\n    \"\"\"\n\n    if key == \"SimulationRun\":\n        return \"guid\"\n\n    try:\n        # Use dateutil parser to test if the value could be a date, in case of error it is not\n        dateutil.parser.parse(key_example_value, fuzzy=False)\n        return \"datetime\"\n    except (ValueError, TypeError):\n        pass\n\n    if type(key_example_value) is float:\n        return \"real\"\n\n    if type(key_example_value) is int:\n        return \"long\"\n\n    # Default case to string\n    return \"string\"\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.IngestionStatus","title":"<code>IngestionStatus</code>","text":"<p>             Bases: <code>Enum</code></p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>class IngestionStatus(Enum):\n    QUEUED = 'QUEUED'\n    SUCCESS = 'SUCCESS'\n    FAILURE = 'FAILURE'\n    UNKNOWN = 'UNKNOWN'\n    TIMEOUT = 'TIMED OUT'\n</code></pre>"},{"location":"references/Accelerators/cosmo_api/","title":"CosmoTech_Acceleration_Library.Accelerators.cosmo_api","text":""},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api","title":"<code>cosmo_api</code>","text":""},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.get_current_scenario_data","title":"<code>get_current_scenario_data()</code>","text":"<p>Uses environment vars to find the current scenario data from the cosmotech api :return: a dict containing the data of the scenario from the API or None in another context</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py</code> <pre><code>def get_current_scenario_data():\n    \"\"\"\n    Uses environment vars to find the current scenario data from the cosmotech api\n    :return: a dict containing the data of the scenario from the API or None in another context\n    \"\"\"\n    organization_id = os.environ.get(\"CSM_ORGANIZATION_ID\")\n    workspace_id = os.environ.get(\"CSM_WORKSPACE_ID\")\n    scenario_id = os.environ.get(\"CSM_SCENARIO_ID\")\n\n    if not all([organization_id, workspace_id, scenario_id]):\n        return None\n\n    with cosmotech_api.ApiClient(__get_configuration()) as api_client:\n        api_instance = ScenarioApi(api_client)\n        scenario_data = api_instance.find_scenario_by_id(organization_id=organization_id,\n                                                         workspace_id=workspace_id,\n                                                         scenario_id=scenario_id)\n    return scenario_data\n</code></pre>"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.send_dataframe_to_api","title":"<code>send_dataframe_to_api(dataframe, file_name)</code>","text":"<p>Send a dataframe to the API</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py</code> <pre><code>def send_dataframe_to_api(dataframe, file_name: str):\n    \"\"\"Send a dataframe to the API\"\"\"\n    file_content = io.StringIO()\n    dataframe.to_csv(file_content, index=False)\n    file_content.seek(0)\n    file_content.name = file_name.split('/')[-1]\n    send_file_to_api(file_content, file_name)\n</code></pre>"},{"location":"references/Accelerators/cosmo_api/#CosmoTech_Acceleration_Library.Accelerators.cosmo_api.send_file_to_api","title":"<code>send_file_to_api(file_content, file_name)</code>","text":"<p>Send a file to the api</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/cosmo_api.py</code> <pre><code>def send_file_to_api(file_content, file_name: str):\n    \"\"\"Send a file to the api\"\"\"\n    organization_id = os.environ.get(\"CSM_ORGANIZATION_ID\")\n    workspace_id = os.environ.get(\"CSM_WORKSPACE_ID\")\n\n    with cosmotech_api.ApiClient(__get_configuration()) as api_client:\n        api_ws = WorkspaceApi(api_client)\n        api_ws.upload_workspace_file(organization_id=organization_id,\n                                     workspace_id=workspace_id,\n                                     file=file_content,\n                                     overwrite=True,\n                                     destination=file_name)\n</code></pre>"},{"location":"references/Accelerators/csm_engine/","title":"CosmoTech_Acceleration_Library.Accelerators.csm_engine","text":""},{"location":"references/Accelerators/csm_engine/#CosmoTech_Acceleration_Library.Accelerators.csm_engine","title":"<code>csm_engine</code>","text":""},{"location":"references/Accelerators/csm_engine/#CosmoTech_Acceleration_Library.Accelerators.csm_engine.apply_simple_csv_parameter_to_simulator","title":"<code>apply_simple_csv_parameter_to_simulator(simulator, parameter_name, target_attribute_name, csv_id_column='id', csv_value_column='value')</code>","text":"<p>Accelerator used to apply CSV parameters directly to a simulator Will raise a ValueError if the parameter does not exist If an entity is not found, will skip the row in the CSV :param simulator: The simulator object to which the parameter will be applied :param parameter_name: The name of the parameter fetched from the API :param target_attribute_name: Target attribute of the entities listed in the CSV :param csv_id_column: Column in the CSV file used for the entity ID :param csv_value_column: Column in the CSV file used for the attribute value to change :return: None</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/csm_engine.py</code> <pre><code>def apply_simple_csv_parameter_to_simulator(simulator,\n                                            parameter_name: str,\n                                            target_attribute_name: str,\n                                            csv_id_column: str = \"id\",\n                                            csv_value_column: str = \"value\"):\n    \"\"\"\n    Accelerator used to apply CSV parameters directly to a simulator\n    Will raise a ValueError if the parameter does not exist\n    If an entity is not found, will skip the row in the CSV\n    :param simulator: The simulator object to which the parameter will be applied\n    :param parameter_name: The name of the parameter fetched from the API\n    :param target_attribute_name: Target attribute of the entities listed in the CSV\n    :param csv_id_column: Column in the CSV file used for the entity ID\n    :param csv_value_column: Column in the CSV file used for the attribute value to change\n    :return: None\n    \"\"\"\n    parameter_path = os.path.join(parametersPath, parameter_name)\n    if os.path.exists(parameter_path):\n        csv_files = glob.glob(os.path.join(parameter_path, \"*.csv\"))\n        for csv_filename in csv_files:\n            model = simulator.GetModel()\n            with open(csv_filename, \"r\") as csv_file:\n                for row in csv.DictReader(csv_file):\n                    entity_name = row.get(csv_id_column)\n                    value = json.loads(row.get(csv_value_column))\n                    entity = model.FindEntityByName(entity_name)\n                    if entity:\n                        entity.SetAttributeAsString(target_attribute_name, json.dumps(value))\n    else:\n        raise ValueError(f\"Parameter {parameter_name} does not exists.\")\n</code></pre>"},{"location":"references/Accelerators/scenario_download/azure_function_main/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main","text":""},{"location":"references/Accelerators/scenario_download/azure_function_main/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main","title":"<code>azure_function_main</code>","text":""},{"location":"references/Accelerators/scenario_download/download_command/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.download_command","text":""},{"location":"references/Accelerators/scenario_download/download_command/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.download_command","title":"<code>download_command</code>","text":""},{"location":"references/Accelerators/scenario_download/download_command/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.download_command.download_scenario_data","title":"<code>download_scenario_data(organization_id, workspace_id, scenario_id, dataset_folder, parameter_folder)</code>","text":"<p>Download the datas from a scenario from the CosmoTech API to the local file system :param scenario_id: The id of the Scenario as defined in the CosmoTech API :param organization_id: The id of the Organization as defined in the CosmoTech API :param workspace_id: The id of the Workspace as defined in the CosmoTech API :param dataset_folder: a local folder where the main dataset of the scenario will be downloaded :param parameter_folder: a local folder where all parameters will be downloaded :return: Nothing</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/download_command.py</code> <pre><code>def download_scenario_data(\n    organization_id: str, workspace_id: str, scenario_id: str, dataset_folder: str, parameter_folder: str\n) -&gt; None:\n    \"\"\"\n    Download the datas from a scenario from the CosmoTech API to the local file system\n    :param scenario_id: The id of the Scenario as defined in the CosmoTech API\n    :param organization_id: The id of the Organization as defined in the CosmoTech API\n    :param workspace_id: The id of the Workspace as defined in the CosmoTech API\n    :param dataset_folder: a local folder where the main dataset of the scenario will be downloaded\n    :param parameter_folder: a local folder where all parameters will be downloaded\n    :return: Nothing\n    \"\"\"\n    logger.info(\"Starting connector\")\n    dl = ScenarioDownloader(workspace_id=workspace_id,\n                            organization_id=organization_id,\n                            read_files=False)\n    logger.info(\"Initialized downloader\")\n    content = dict()\n    content['datasets'] = dl.get_all_datasets(scenario_id=scenario_id)\n\n    content['parameters'] = dl.get_all_parameters(scenario_id=scenario_id)\n    logger.info(\"Downloaded content\")\n    dataset_paths = dict()\n\n    dataset_dir = dataset_folder\n\n    for k in content['datasets'].keys():\n        dataset_paths[k] = dl.dataset_to_file(k, content['datasets'][k])\n        if k not in content['parameters'].values():\n            copy_tree(dataset_paths[k], dataset_dir)\n\n    logger.info(\"Stored datasets\")\n    tmp_parameter_dir = parameter_folder\n\n    tmp_parameter_file = os.path.join(tmp_parameter_dir, \"parameters.json\")\n\n    parameters = []\n\n    for parameter_name, value in content['parameters'].items():\n        def add_file_parameter(compared_parameter_name: str, dataset_id: str):\n            if parameter_name == compared_parameter_name:\n                param_dir = os.path.join(tmp_parameter_dir, compared_parameter_name)\n                pathlib.Path(param_dir).mkdir(exist_ok=True)\n                dataset_content_path = dataset_paths[dataset_id]\n                copy_tree(dataset_content_path, param_dir)\n                parameters.append({\n                    \"parameterId\": parameter_name,\n                    \"value\": parameter_name,\n                    \"varType\": \"%DATASETID%\"\n                })\n\n        if value in content['datasets']:\n            add_file_parameter(parameter_name, value)\n        parameters.append({\n            \"parameterId\": parameter_name,\n            \"value\": value,\n            \"varType\": str(type(value).__name__)\n        })\n\n    with open(tmp_parameter_file, \"w\") as _file:\n        json.dump(parameters, _file)\n    logger.info(\"Generated parameters.json\")\n</code></pre>"},{"location":"references/Accelerators/scenario_download/download_command/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.download_command.main","title":"<code>main()</code>","text":"<p>Uses environment variables to call the download_scenario_data function</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/download_command.py</code> <pre><code>def main():\n    \"\"\"\n    Uses environment variables to call the download_scenario_data function\n    \"\"\"\n    logger.setLevel(logging.INFO)\n    import os\n\n    required_environment = [\n        ('CSM_API_URL', \"The url to a cosmotech api\"),\n        ('CSM_API_SCOPE', \"The identification scope of a cosmotech api\"),\n        ('CSM_SCENARIO_ID', \"The id of a scenario in the cosmotech api\"),\n        ('CSM_WORKSPACE_ID', \"The id of a workspace in the cosmotech api\"),\n        ('CSM_ORGANIZATION_ID', \"The id of an organization in the cosmotech api\"),\n        ('CSM_DATASET_ABSOLUTE_PATH', \"A local folder to store the main dataset content\"),\n        ('CSM_PARAMETERS_ABSOLUTE_PATH', \"A local folder to store the parameters content\")\n    ]\n\n    s_id = os.environ.get('CSM_SCENARIO_ID')\n    w_id = os.environ.get('CSM_WORKSPACE_ID')\n    o_id = os.environ.get('CSM_ORGANIZATION_ID')\n    dataset_path = os.environ.get('CSM_DATASET_ABSOLUTE_PATH', \"/tmp/dataset\")\n    parameter_path = os.environ.get('CSM_PARAMETERS_ABSOLUTE_PATH', \"/tmp/parameters\")\n    if any(_var not in os.environ for _var, _ in required_environment):\n        print(\"An error exists in the environment to run this command.\")\n        print(\"The following values are required\")\n        for _var, _help in required_environment:\n            print(f\"  {_var} : {_help}\")\n        exit(1)\n    download_scenario_data(o_id, w_id, s_id, dataset_path, parameter_path)\n</code></pre>"},{"location":"references/Accelerators/scenario_download/scenario_downloader/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader","text":""},{"location":"references/Accelerators/scenario_download/scenario_downloader/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader.ScenarioDownloader","title":"<code>ScenarioDownloader</code>","text":"Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader.py</code> <pre><code>class ScenarioDownloader:\n\n    def __init__(self, workspace_id: str, organization_id: str, read_files=True, parallel=True):\n        self.credentials = DefaultAzureCredential()\n        scope = env.api_scope\n        token = self.credentials.get_token(scope)\n\n        self.configuration = cosmotech_api.Configuration(\n            host=env.api_host,\n            discard_unknown_keys=True,\n            access_token=token.token\n        )\n\n        self.workspace_id = workspace_id\n        self.organization_id = organization_id\n        self.dataset_file_temp_path = dict()\n        self.read_files = read_files\n        self.parallel = parallel\n\n    def get_scenario_data(self, scenario_id: str):\n        with cosmotech_api.ApiClient(self.configuration) as api_client:\n            api_instance = ScenarioApi(api_client)\n            scenario_data = api_instance.find_scenario_by_id(organization_id=self.organization_id,\n                                                             workspace_id=self.workspace_id,\n                                                             scenario_id=scenario_id)\n        return scenario_data\n\n    def download_dataset(self, dataset_id: str) -&gt; (str, str, Union[str, None]):\n        with cosmotech_api.ApiClient(self.configuration) as api_client:\n            api_instance = DatasetApi(api_client)\n\n            dataset = api_instance.find_dataset_by_id(\n                organization_id=self.organization_id,\n                dataset_id=dataset_id)\n            parameters = dataset['connector']['parameters_values']\n\n            is_adt = 'AZURE_DIGITAL_TWINS_URL' in parameters\n            is_twin_cache = 'TWIN_CACHE_NAME' in parameters\n\n            if is_adt:\n                return {\n                    \"type\": 'adt',\n                    \"content\": self._download_adt_content(\n                        adt_adress=parameters['AZURE_DIGITAL_TWINS_URL']),\n                    \"name\": dataset['name']}\n            elif is_twin_cache:\n                twin_cache_name = parameters['TWIN_CACHE_NAME']\n                return {\n                    \"type\": \"adt\",\n                    \"content\": self._read_twingraph_content(twin_cache_name),\n                    \"name\": dataset[\"name\"]\n                }\n            else:\n                _file_name = parameters['AZURE_STORAGE_CONTAINER_BLOB_PREFIX'].replace(\n                    '%WORKSPACE_FILE%/', '')\n                _content = self._download_file(_file_name)\n                self.dataset_file_temp_path[dataset_id] = self.dataset_file_temp_path[_file_name]\n                return {\n                    \"type\": _file_name.split('.')[-1],\n                    \"content\": _content,\n                    \"name\": dataset['name']\n                }\n\n    def _read_twingraph_content(self, cache_name: str) -&gt; dict:\n        with cosmotech_api.ApiClient(self.configuration) as api_client:\n            api_instance = TwingraphApi(api_client)\n            _query_nodes = TwinGraphQuery(\n                query=\"MATCH(n) RETURN n\"\n            )\n            nodes = api_instance.query(\n                organization_id=self.organization_id,\n                graph_id=cache_name,\n                twin_graph_query=_query_nodes\n            )\n            _query_rel = TwinGraphQuery(\n                query=\"MATCH(n)-[r]-&gt;(m) RETURN n as src, r as rel, m as dest\"\n            )\n            rel = api_instance.query(\n                organization_id=self.organization_id,\n                graph_id=cache_name,\n                twin_graph_query=_query_rel\n            )\n\n            content = dict()\n            # build keys\n            for item in rel:\n                content[item['src']['label']] = list()\n                content[item['dest']['label']] = list()\n                content[item['rel']['label']] = list()\n\n            for item in nodes:\n                label = item['n']['label']\n                prop = item['n']['properties']\n                prop.update({'id': item['n']['id']})\n                content.setdefault(label, list())\n                content[label].append(prop)\n\n            for item in rel:\n                src = item['src']\n                dest = item['dest']\n                rel = item['rel']\n                props = item['rel']['properties']\n                content[rel['label']].append({\n                    'id': rel['id'],\n                    'source': src['id'],\n                    'target': dest['id'],\n                    **props\n                })\n            return content\n\n    def _download_file(self, file_name: str):\n        tmp_dataset_dir = tempfile.mkdtemp()\n        self.dataset_file_temp_path[file_name] = tmp_dataset_dir\n        with cosmotech_api.ApiClient(self.configuration) as api_client:\n            api_ws = WorkspaceApi(api_client)\n\n            all_api_files = api_ws.find_all_workspace_files(\n                self.organization_id, self.workspace_id)\n\n            existing_files = list(\n                _f.to_dict().get('file_name') for _f in all_api_files\n                if _f.to_dict().get('file_name', '').startswith(file_name))\n\n            content = dict()\n\n            for _file_name in existing_files:\n                dl_file = api_ws.download_workspace_file(organization_id=self.organization_id,\n                                                         workspace_id=self.workspace_id,\n                                                         file_name=_file_name)\n\n                target_file = os.path.join(\n                    tmp_dataset_dir, _file_name.split('/')[-1])\n                with open(target_file, \"wb\") as tmp_file:\n                    tmp_file.write(dl_file.read())\n                if not self.read_files:\n                    continue\n                if \".xls\" in _file_name:\n                    wb = load_workbook(target_file, data_only=True)\n                    for sheet_name in wb.sheetnames:\n                        sheet = wb[sheet_name]\n                        content[sheet_name] = list()\n                        headers = next(sheet.iter_rows(\n                            max_row=1, values_only=True))\n\n                        def item(_row: tuple) -&gt; dict:\n                            return {k: v for k, v in zip(headers, _row)}\n\n                        for r in sheet.iter_rows(min_row=2, values_only=True):\n                            row = item(r)\n                            new_row = dict()\n                            for key, value in row.items():\n                                try:\n                                    converted_value = json.load(\n                                        io.StringIO(value))\n                                except (json.decoder.JSONDecodeError, TypeError):\n                                    converted_value = value\n                                if converted_value is not None:\n                                    new_row[key] = converted_value\n                            if new_row:\n                                content[sheet_name].append(new_row)\n                elif \".csv\" in _file_name:\n                    with open(target_file, \"r\") as file:\n                        # Read every file in the input folder\n                        current_filename = os.path.basename(target_file)[:-len(\".csv\")]\n                        content[current_filename] = list()\n                        for row in csv.DictReader(file):\n                            new_row = dict()\n                            for key, value in row.items():\n                                try:\n                                    # Try to convert any json row to dict object\n                                    converted_value = json.load(\n                                        io.StringIO(value))\n                                except json.decoder.JSONDecodeError:\n                                    converted_value = value\n                                if converted_value == '':\n                                    converted_value = None\n                                if converted_value is not None:\n                                    new_row[key] = converted_value\n                            content[current_filename].append(new_row)\n                elif \".json\" in _file_name:\n                    with open(target_file, \"r\") as _file:\n                        current_filename = os.path.basename(target_file)\n                        content[current_filename] = json.load(_file)\n                else:\n                    with open(target_file, \"r\") as _file:\n                        current_filename = os.path.basename(target_file)\n                        content[current_filename] = \"\\n\".join(\n                            line for line in _file)\n        return content\n\n    def _download_adt_content(self, adt_adress: str) -&gt; dict:\n        client = DigitalTwinsClient(adt_adress, self.credentials)\n        query_expression = 'SELECT * FROM digitaltwins'\n        query_result = client.query_twins(query_expression)\n        json_content = dict()\n        for twin in query_result:\n            entity_type = twin.get('$metadata').get(\n                '$model').split(':')[-1].split(';')[0]\n            t_content = {k: v for k, v in twin.items()}\n            t_content['id'] = t_content['$dtId']\n            for k in twin.keys():\n                if k[0] == '$':\n                    del t_content[k]\n            json_content.setdefault(entity_type, [])\n            json_content[entity_type].append(t_content)\n\n        relations_query = 'SELECT * FROM relationships'\n        query_result = client.query_twins(relations_query)\n        for relation in query_result:\n            tr = {\n                \"$relationshipId\": \"id\",\n                \"$sourceId\": \"source\",\n                \"$targetId\": \"target\"\n            }\n            r_content = {k: v for k, v in relation.items()}\n            for k, v in tr.items():\n                r_content[v] = r_content[k]\n            for k in relation.keys():\n                if k[0] == '$':\n                    del r_content[k]\n            json_content.setdefault(relation['$relationshipName'], [])\n            json_content[relation['$relationshipName']].append(r_content)\n\n        return json_content\n\n    def get_all_parameters(self, scenario_id) -&gt; dict:\n        scenario_data = self.get_scenario_data(scenario_id=scenario_id)\n        content = dict()\n        for parameter in scenario_data['parameters_values']:\n            content[parameter['parameter_id']] = parameter['value']\n        return content\n\n    def get_all_datasets(self, scenario_id: str) -&gt; dict:\n        scenario_data = self.get_scenario_data(scenario_id=scenario_id)\n\n        datasets = scenario_data['dataset_list']\n\n        dataset_ids = datasets[:]\n\n        for parameter in scenario_data['parameters_values']:\n            if parameter['var_type'] == '%DATASETID%':\n                dataset_id = parameter['value']\n                dataset_ids.append(dataset_id)\n\n        def process(_dataset_id, _return_dict):\n            _c = self.download_dataset(_dataset_id)\n            if _dataset_id in self.dataset_file_temp_path:\n                _return_dict[_dataset_id] = (_c, self.dataset_file_temp_path[_dataset_id], _dataset_id)\n            else:\n                _return_dict[_dataset_id] = _c\n\n        if self.parallel:\n            manager = multiprocessing.Manager()\n            return_dict = manager.dict()\n            processes = [\n                multiprocessing.Process(target=process, args=(dataset_id, return_dict))\n                for dataset_id in dataset_ids\n            ]\n            [p.start() for p in processes]\n            [p.join() for p in processes]\n            for p in processes:\n                if p.exitcode != 0:\n                    raise ChildProcessError(\"One of the datasets was not downloaded.\")\n        else:\n            return_dict = {}\n            for dataset_id in dataset_ids:\n                process(dataset_id, return_dict)\n        content = dict()\n        for k, v in return_dict.items():\n            if isinstance(v, tuple):\n                content[k] = v[0]\n                self.dataset_file_temp_path[v[2]] = v[1]\n            else:\n                content[k] = v\n        return content\n\n    def dataset_to_file(self, dataset_id, dataset_info):\n        type = dataset_info['type']\n        content = dataset_info['content']\n        name = dataset_info['name']\n        if type == \"adt\":\n            return self.adt_dataset(content, name, type)\n        return self.dataset_file_temp_path[dataset_id]\n\n    @staticmethod\n    def sheet_to_header(sheet_content):\n        fieldnames = []\n        has_src = False\n        has_id = False\n        for r in sheet_content:\n            for k in r.keys():\n                if k not in fieldnames:\n                    if k in ['source', 'target']:\n                        has_src = True\n                    elif k == \"id\":\n                        has_id = True\n                    else:\n                        fieldnames.append(k)\n        if has_src:\n            fieldnames = ['source', 'target'] + fieldnames\n        if has_id:\n            fieldnames = ['id', ] + fieldnames\n        return fieldnames\n\n    def adt_dataset(self, content, _name, _type):\n        tmp_dataset_dir = tempfile.mkdtemp()\n        for _filename, _filecontent in content.items():\n            with open(tmp_dataset_dir + \"/\" + _filename + \".csv\", \"w\") as _file:\n                fieldnames = self.sheet_to_header(_filecontent)\n\n                _w = csv.DictWriter(_file, fieldnames=fieldnames, dialect=\"unix\", quoting=csv.QUOTE_MINIMAL)\n                _w.writeheader()\n                # _w.writerows(_filecontent)\n                for r in _filecontent:\n                    _w.writerow({k: str(v).replace(\"'\", \"\\\"\").replace(\"True\",\"true\").replace(\"False\",\"false\") for k, v in r.items()})\n        return tmp_dataset_dir\n</code></pre>"},{"location":"references/Accelerators/utils/multi_environment/","title":"CosmoTech_Acceleration_Library.Accelerators.utils.multi_environment","text":""},{"location":"references/Accelerators/utils/multi_environment/#CosmoTech_Acceleration_Library.Accelerators.utils.multi_environment.MultiEnvironment","title":"<code>MultiEnvironment</code>","text":"Source code in <code>CosmoTech_Acceleration_Library/Accelerators/utils/multi_environment.py</code> <pre><code>class MultiEnvironment:\n\n    def __init__(self):\n        self.api_host = None\n        self.api_scope = None\n\n        for host_var in ['COSMOTECH_API_SCOPE', 'CSM_API_SCOPE']:\n            if host_var in os.environ:\n                self.api_scope = os.environ.get(host_var)\n                break\n\n        for host_var in ['COSMOTECH_API_HOST', 'COSMOTECH_API_URL', 'CSM_API_HOST', 'CSM_API_URL']:\n            if host_var in os.environ:\n                self.api_host = os.environ.get(host_var)\n                break\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler","text":""},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler","title":"<code>GraphHandler</code>","text":"<p>             Bases: <code>RedisHandler</code></p> <p>Class that handle Graph Redis information</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>class GraphHandler(RedisHandler):\n    \"\"\"\n    Class that handle Graph Redis information\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None):\n        super().__init__(host=host, port=port, name=name, password=password)\n        logger.debug(\"GraphHandler init\")\n        self.name = name\n        self.graph = self.r.graph(name)\n\n    def do_if_graph_exist(function):\n        \"\"\"\n        Function decorator that run the function annotated if graph exists\n        :param function: the function annotated\n        \"\"\"\n\n        @functools.wraps(function)\n        def wrapper(self, *args, **kwargs):\n            if self.r.exists(self.name) != 0:\n                function(self, *args, **kwargs)\n            else:\n                raise Exception(f\"{self.name} does not exist!\")\n\n        return wrapper\n\n    def handle_graph_replace(func):\n        \"\"\"\n        Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)\n        \"\"\"\n\n        def handle(self, *args, **kwargs):\n            self.graph = self.r.graph(f'{self.name}_tmp')\n            logger.debug(f'Using graph {self.name}_tmp for copy')\n\n            # do function on new graph\n            func(self, *args, **kwargs)\n\n            # action complete on graph_tmp with no error replacing graph by graph_tmp\n            self.r.eval(\n                \"\"\"local o = redis.call('DUMP', KEYS[1]);\\\n                   redis.call('RENAME', KEYS[1], KEYS[2]);\\\n                   redis.call('RESTORE', KEYS[1], 0, o)\"\"\", 2, f'{self.name}_tmp', self.name)\n            # remove tmp graph\n            self.r.delete(f'{self.name}_tmp')\n            # set back the graph\n            self.graph = self.r.graph(self.name)\n\n        return handle\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler.do_if_graph_exist","title":"<code>do_if_graph_exist(function)</code>","text":"<p>Function decorator that run the function annotated if graph exists :param function: the function annotated</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>def do_if_graph_exist(function):\n    \"\"\"\n    Function decorator that run the function annotated if graph exists\n    :param function: the function annotated\n    \"\"\"\n\n    @functools.wraps(function)\n    def wrapper(self, *args, **kwargs):\n        if self.r.exists(self.name) != 0:\n            function(self, *args, **kwargs)\n        else:\n            raise Exception(f\"{self.name} does not exist!\")\n\n    return wrapper\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler.handle_graph_replace","title":"<code>handle_graph_replace(func)</code>","text":"<p>Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>def handle_graph_replace(func):\n    \"\"\"\n    Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)\n    \"\"\"\n\n    def handle(self, *args, **kwargs):\n        self.graph = self.r.graph(f'{self.name}_tmp')\n        logger.debug(f'Using graph {self.name}_tmp for copy')\n\n        # do function on new graph\n        func(self, *args, **kwargs)\n\n        # action complete on graph_tmp with no error replacing graph by graph_tmp\n        self.r.eval(\n            \"\"\"local o = redis.call('DUMP', KEYS[1]);\\\n               redis.call('RENAME', KEYS[1], KEYS[2]);\\\n               redis.call('RESTORE', KEYS[1], 0, o)\"\"\", 2, f'{self.name}_tmp', self.name)\n        # remove tmp graph\n        self.r.delete(f'{self.name}_tmp')\n        # set back the graph\n        self.graph = self.r.graph(self.name)\n\n    return handle\n</code></pre>"},{"location":"references/Modelops/core/common/redis_handler/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler","text":""},{"location":"references/Modelops/core/common/redis_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler.RedisHandler","title":"<code>RedisHandler</code>","text":"<p>Class that handle Redis informations</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/redis_handler.py</code> <pre><code>class RedisHandler:\n    \"\"\"\n    Class that handle Redis informations\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None):\n        logger.debug(\"RedisHandler init\")\n        self.host = host\n        self.port = port\n        self.name = name\n        self.password = password\n        self.r = redis.Redis(host=host, port=port, password=password, decode_responses=True)\n</code></pre>"},{"location":"references/Modelops/core/common/writer/CsvWriter/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter","text":""},{"location":"references/Modelops/core/common/writer/CsvWriter/#CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter.CsvWriter","title":"<code>CsvWriter</code>","text":"<p>Csv Writer class</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/writer/CsvWriter.py</code> <pre><code>class CsvWriter:\n    \"\"\"\n    Csv Writer class\n    \"\"\"\n\n    @staticmethod\n    def _to_csv_format(val: any) -&gt; str:\n        if isinstance(val, bool):\n            return str(val).lower()\n        if isinstance(val, dict):\n            return json.dumps(val)\n        if str(val) == 'True' or str(val) == 'False':\n            return str(val).lower()\n        if str(val).startswith('{') and str(val).endswith('}'):\n            try:\n                return json.dumps(json.loads(val))\n            except json.decoder.JSONDecodeError:\n                return json.dumps(ast.literal_eval(str(val)))\n        return str(val)\n\n    @staticmethod\n    def _to_cosmo_key(val: any) -&gt; str:\n        if str(val) == ModelUtil.dt_id_key:\n            return ModelUtil.id_key\n        return val\n\n    @staticmethod\n    def write_twin_data(export_dir: str,\n                        file_name: str,\n                        query_result: QueryResult,\n                        delimiter: str = ',',\n                        quote_char: str = '\\\"') -&gt; None:\n        headers = set()\n        rows = []\n        for raw_data in query_result.result_set:\n            row = {}\n            # read all graph link properties\n            for i in range(len(raw_data)):  # TODO for the moment its only a len 1 list with the node\n                row.update({\n                    CsvWriter._to_cosmo_key(k): CsvWriter._to_csv_format(v)\n                    for k, v in raw_data[i].properties.items()\n                })\n            headers.update(row.keys())\n            rows.append(row)\n\n        output_file_name = f'{export_dir}/{file_name}.csv'\n        logger.debug(f\"Writing CSV file {output_file_name}\")\n        with open(output_file_name, 'w') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            csv_writer.writeheader()\n            csv_writer.writerows(rows)\n        logger.debug(f\"... CSV file {output_file_name} has been written\")\n\n    @staticmethod\n    def write_relationship_data(export_dir: str,\n                                file_name: str,\n                                query_result: QueryResult,\n                                headers: list = [],\n                                delimiter: str = ',',\n                                quote_char: str = '\\\"') -&gt; None:\n        headers = {'source', 'target'}\n        rows = []\n        for raw_data in query_result.result_set:\n            row = {'source': raw_data[0], 'target': raw_data[1]}\n            row.update({k: CsvWriter._to_csv_format(v) for k, v in raw_data[2].properties.items()})\n            headers.update(row.keys())\n            rows.append(row)\n\n        output_file_name = f'{export_dir}/{file_name}.csv'\n        logger.debug(f\"Writing CSV file {output_file_name}\")\n        with open(output_file_name, 'w') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            csv_writer.writeheader()\n            csv_writer.writerows(rows)\n        logger.debug(f\"... CSV file {output_file_name} has been written\")\n\n    @staticmethod\n    def write_data(export_dir: str,\n                   file_name: str,\n                   input_rows: dict,\n                   delimiter: str = ',',\n                   quote_char: str = '\\\"') -&gt; None:\n        output_file_name = export_dir + file_name + '.csv'\n        write_header = False\n        if not os.path.exists(output_file_name):\n            write_header = True\n\n        headers = set()\n        output_rows = []\n        for row in input_rows:\n            output_rows.append({CsvWriter._to_cosmo_key(k): CsvWriter._to_csv_format(v) for k, v in row.items()})\n            headers.update(row.keys())\n\n        logger.info(f\"Writing file {output_file_name} ...\")\n        with open(output_file_name, 'a') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            if write_header:\n                csv_writer.writeheader()\n            csv_writer.writerows(output_rows)\n        logger.debug(f\"... file {output_file_name} has been written\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter","text":""},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter","title":"<code>ModelExporter</code>","text":"<p>             Bases: <code>GraphHandler</code></p> <p>Model Exporter for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>class ModelExporter(GraphHandler):\n    \"\"\"\n    Model Exporter for cached data\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None, export_dir: str = \"/\"):\n        super().__init__(host=host, port=port, name=name, password=password)\n        Path(export_dir).mkdir(parents=True, exist_ok=True)\n        self.export_dir = export_dir\n\n        self.mr = ModelReader(host=host, port=port, name=name, password=password)\n        self.labels = [label[0] for label in self.graph.labels()]\n        self.relationships = [relation[0] for relation in self.graph.relationship_types()]\n        self.already_exported_nodes = {}\n        self.already_exported_edges = []\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_twins(self):\n        \"\"\"\n        Export all twins\n        :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n        \"\"\"\n        logger.debug(\"Start exporting twins...\")\n        logger.debug(\"Get twin types...\")\n        get_types_start = time.time()\n        twin_names = self.mr.get_twin_types()\n        get_types_end = time.time() - get_types_start\n        logger.debug(f\"Get twin types took {get_types_end} s\")\n\n        for twin_name in twin_names:\n            logger.debug(f\"Get twin info for type {twin_name} ...\")\n            get_twin_info_start = time.time()\n            twin_results = self.mr.get_twins_by_type(twin_name)\n            get_twin_info_end = time.time() - get_twin_info_start\n            logger.debug(f\"Get twin info for type {twin_name} took {get_twin_info_end} s\")\n\n            logger.debug(f\"Export twin info for type {twin_name} ...\")\n            export_twin_info_start = time.time()\n            CsvWriter.write_twin_data(self.export_dir, twin_name, twin_results)\n            export_twin_info_end = time.time() - export_twin_info_start\n            logger.debug(f\"Export twin info for type {twin_name} took {export_twin_info_end} s\")\n\n            logger.debug(f\"Twins exported :{twin_name}\")\n        logger.debug(\"... End exporting twins\")\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_relationships(self):\n        \"\"\"\n        Export all relationships\n        :return: Csv files containing all relationship instances exported into {export_dir}\n        folder named by relationship type\n        \"\"\"\n        logger.debug(\"Start exporting relationships...\")\n        logger.debug(\"Get relationship types...\")\n        get_relationship_types_start = time.time()\n        relationship_names = self.mr.get_relationship_types()\n        get_relationship_types_end = time.time() - get_relationship_types_start\n        logger.debug(f\"Get relationship types took {get_relationship_types_end} s\")\n\n        for relationship_name in relationship_names:\n            logger.debug(f\"Get relationship info for type {relationship_name} ...\")\n            get_relationship_info_start = time.time()\n            relationship_result = self.mr.get_relationships_by_type(relationship_name)\n            get_relationship_info_end = time.time() - get_relationship_info_start\n            logger.debug(f\"Get relationship info for type {relationship_name} took {get_relationship_info_end} s\")\n\n            logger.debug(f\"Export relationship info for type {relationship_name} ...\")\n            export_relationship_info_start = time.time()\n            CsvWriter.write_relationship_data(self.export_dir, relationship_name, relationship_result)\n            export_relationship_info_end = time.time() - export_relationship_info_start\n            logger.debug(f\"Export relationship info for type {relationship_name} took {export_relationship_info_end} s\")\n\n            logger.debug(f\"Relationships exported :{relationship_name}\")\n        logger.debug(\"... End exporting relationships\")\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_data(self):\n        \"\"\"\n        Export all data\n        :return: a bunch of csv files corresponding to graph data\n        \"\"\"\n        self.export_all_twins()\n        self.export_all_relationships()\n\n    @GraphHandler.do_if_graph_exist\n    def export_from_queries(self, queries: list):\n        \"\"\"\n        Export data from queries\n        Queries must be Cypher queries and return nodes and relationships objects to be exported\n        Multiple instances of the same node or relationship will not be exported\n\n        :param queries: list of queries to execute (Cypher queries)\n        :return: None writes csv files corresponding to the results of the queries in the parameters\n        \"\"\"\n        logger.info(\"Start exporting data from queries...\")\n        # foreach query, execute it and get nodes and relationships\n        for query in queries:\n            logger.info(f\"Export data from query {query} ...\")\n            export_data_from_query_start = time.time()\n            query_result = self.mr.query(query, read_only=True)\n\n            # foreach query result, get nodes and relationships\n            nodes_by_label = {key: [] for key in self.labels}\n            edges_by_relation = {key: [] for key in self.relationships}\n            for result in query_result.result_set:\n                for data in result:\n                    if type(data) == redis.commands.graph.node.Node:\n                        if data.id not in self.already_exported_nodes:\n                            self.already_exported_nodes.update({data.id: data.properties.get('id')})\n                            nodes_by_label[data.label].append(data)\n                    elif type(data) == redis.commands.graph.edge.Edge:\n                        if data.id not in self.already_exported_edges:\n                            self.already_exported_edges.append(data.id)\n                            edges_by_relation[data.relation].append(data)\n\n            # write node data into csv file\n            for label, nodes in nodes_by_label.items():\n                if nodes:\n                    nodes_rows = [node.properties for node in nodes]\n                    CsvWriter.write_data(self.export_dir, label, nodes_rows)\n\n            # write edge data into csv file\n            for relation, edges in edges_by_relation.items():\n                if edges:\n                    # add source and target to edge properties\n                    edges_rows = []\n                    for edge in edges:\n                        logger.debug(f\"Get source and target for edge {edge.id} ...\")\n                        edge.properties['source'] = self.get_node_id_from_sys_id(edge.src_node)\n                        edge.properties['target'] = self.get_node_id_from_sys_id(edge.dest_node)\n                        edges_rows.append(edge.properties)\n                    CsvWriter.write_data(self.export_dir, relation, edges_rows)\n\n            export_data_from_query_end = time.time() - export_data_from_query_start\n            logger.debug(f\"Export data from query took {export_data_from_query_end} s\")\n\n            logger.debug(\"Data from query exported\")\n        logger.info(\"... End exporting data from queries\")\n\n    @lru_cache\n    def get_node_id_from_sys_id(self, sys_id: int) -&gt; int:\n        \"\"\"\n        Get node id from system id (RedisGraph id)\n        :param sys_id: system id\n        :return: node id\n        \"\"\"\n        if sys_id in self.already_exported_nodes:\n            return self.already_exported_nodes[sys_id]\n        node_query = \"MATCH (n) WHERE ID(n) = $id RETURN n.id\"\n        return self.mr.query(node_query, params={'id': sys_id}).result_set[0][0]\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_data","title":"<code>export_all_data()</code>","text":"<p>Export all data :return: a bunch of csv files corresponding to graph data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_data(self):\n    \"\"\"\n    Export all data\n    :return: a bunch of csv files corresponding to graph data\n    \"\"\"\n    self.export_all_twins()\n    self.export_all_relationships()\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_relationships","title":"<code>export_all_relationships()</code>","text":"<p>Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_relationships(self):\n    \"\"\"\n    Export all relationships\n    :return: Csv files containing all relationship instances exported into {export_dir}\n    folder named by relationship type\n    \"\"\"\n    logger.debug(\"Start exporting relationships...\")\n    logger.debug(\"Get relationship types...\")\n    get_relationship_types_start = time.time()\n    relationship_names = self.mr.get_relationship_types()\n    get_relationship_types_end = time.time() - get_relationship_types_start\n    logger.debug(f\"Get relationship types took {get_relationship_types_end} s\")\n\n    for relationship_name in relationship_names:\n        logger.debug(f\"Get relationship info for type {relationship_name} ...\")\n        get_relationship_info_start = time.time()\n        relationship_result = self.mr.get_relationships_by_type(relationship_name)\n        get_relationship_info_end = time.time() - get_relationship_info_start\n        logger.debug(f\"Get relationship info for type {relationship_name} took {get_relationship_info_end} s\")\n\n        logger.debug(f\"Export relationship info for type {relationship_name} ...\")\n        export_relationship_info_start = time.time()\n        CsvWriter.write_relationship_data(self.export_dir, relationship_name, relationship_result)\n        export_relationship_info_end = time.time() - export_relationship_info_start\n        logger.debug(f\"Export relationship info for type {relationship_name} took {export_relationship_info_end} s\")\n\n        logger.debug(f\"Relationships exported :{relationship_name}\")\n    logger.debug(\"... End exporting relationships\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_twins","title":"<code>export_all_twins()</code>","text":"<p>Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_twins(self):\n    \"\"\"\n    Export all twins\n    :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n    \"\"\"\n    logger.debug(\"Start exporting twins...\")\n    logger.debug(\"Get twin types...\")\n    get_types_start = time.time()\n    twin_names = self.mr.get_twin_types()\n    get_types_end = time.time() - get_types_start\n    logger.debug(f\"Get twin types took {get_types_end} s\")\n\n    for twin_name in twin_names:\n        logger.debug(f\"Get twin info for type {twin_name} ...\")\n        get_twin_info_start = time.time()\n        twin_results = self.mr.get_twins_by_type(twin_name)\n        get_twin_info_end = time.time() - get_twin_info_start\n        logger.debug(f\"Get twin info for type {twin_name} took {get_twin_info_end} s\")\n\n        logger.debug(f\"Export twin info for type {twin_name} ...\")\n        export_twin_info_start = time.time()\n        CsvWriter.write_twin_data(self.export_dir, twin_name, twin_results)\n        export_twin_info_end = time.time() - export_twin_info_start\n        logger.debug(f\"Export twin info for type {twin_name} took {export_twin_info_end} s\")\n\n        logger.debug(f\"Twins exported :{twin_name}\")\n    logger.debug(\"... End exporting twins\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_from_queries","title":"<code>export_from_queries(queries)</code>","text":"<p>Export data from queries Queries must be Cypher queries and return nodes and relationships objects to be exported Multiple instances of the same node or relationship will not be exported</p> <p>:param queries: list of queries to execute (Cypher queries) :return: None writes csv files corresponding to the results of the queries in the parameters</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_from_queries(self, queries: list):\n    \"\"\"\n    Export data from queries\n    Queries must be Cypher queries and return nodes and relationships objects to be exported\n    Multiple instances of the same node or relationship will not be exported\n\n    :param queries: list of queries to execute (Cypher queries)\n    :return: None writes csv files corresponding to the results of the queries in the parameters\n    \"\"\"\n    logger.info(\"Start exporting data from queries...\")\n    # foreach query, execute it and get nodes and relationships\n    for query in queries:\n        logger.info(f\"Export data from query {query} ...\")\n        export_data_from_query_start = time.time()\n        query_result = self.mr.query(query, read_only=True)\n\n        # foreach query result, get nodes and relationships\n        nodes_by_label = {key: [] for key in self.labels}\n        edges_by_relation = {key: [] for key in self.relationships}\n        for result in query_result.result_set:\n            for data in result:\n                if type(data) == redis.commands.graph.node.Node:\n                    if data.id not in self.already_exported_nodes:\n                        self.already_exported_nodes.update({data.id: data.properties.get('id')})\n                        nodes_by_label[data.label].append(data)\n                elif type(data) == redis.commands.graph.edge.Edge:\n                    if data.id not in self.already_exported_edges:\n                        self.already_exported_edges.append(data.id)\n                        edges_by_relation[data.relation].append(data)\n\n        # write node data into csv file\n        for label, nodes in nodes_by_label.items():\n            if nodes:\n                nodes_rows = [node.properties for node in nodes]\n                CsvWriter.write_data(self.export_dir, label, nodes_rows)\n\n        # write edge data into csv file\n        for relation, edges in edges_by_relation.items():\n            if edges:\n                # add source and target to edge properties\n                edges_rows = []\n                for edge in edges:\n                    logger.debug(f\"Get source and target for edge {edge.id} ...\")\n                    edge.properties['source'] = self.get_node_id_from_sys_id(edge.src_node)\n                    edge.properties['target'] = self.get_node_id_from_sys_id(edge.dest_node)\n                    edges_rows.append(edge.properties)\n                CsvWriter.write_data(self.export_dir, relation, edges_rows)\n\n        export_data_from_query_end = time.time() - export_data_from_query_start\n        logger.debug(f\"Export data from query took {export_data_from_query_end} s\")\n\n        logger.debug(\"Data from query exported\")\n    logger.info(\"... End exporting data from queries\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.get_node_id_from_sys_id","title":"<code>get_node_id_from_sys_id(sys_id)</code>  <code>cached</code>","text":"<p>Get node id from system id (RedisGraph id) :param sys_id: system id :return: node id</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@lru_cache\ndef get_node_id_from_sys_id(self, sys_id: int) -&gt; int:\n    \"\"\"\n    Get node id from system id (RedisGraph id)\n    :param sys_id: system id\n    :return: node id\n    \"\"\"\n    if sys_id in self.already_exported_nodes:\n        return self.already_exported_nodes[sys_id]\n    node_query = \"MATCH (n) WHERE ID(n) = $id RETURN n.id\"\n    return self.mr.query(node_query, params={'id': sys_id}).result_set[0][0]\n</code></pre>"},{"location":"references/Modelops/core/io/model_importer/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_importer","text":""},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter","title":"<code>ModelImporter</code>","text":"<p>             Bases: <code>GraphHandler</code></p> <p>Model Exporter for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py</code> <pre><code>class ModelImporter(GraphHandler):\n    \"\"\"\n    Model Exporter for cached data\n    \"\"\"\n\n    @GraphHandler.handle_graph_replace\n    def bulk_import(self, twin_file_paths: list = [], relationship_file_paths: list = [], enforce_schema: bool = False):\n        \"\"\"\n        Import all csv data\n        :param twin_file_paths: the file paths of all twin csv files\n        :param relationship_file_paths: the file paths of all relationship csv files\n        :param enforce_schema: True if the schema is defined within headers (default False)\n        `Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;`_\n        :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n        \"\"\"\n        command_parameters = ['--host', self.host, '--port', self.port]\n\n        if self.password is not None:\n            command_parameters.append('--password')\n            command_parameters.append(self.password)\n\n        if enforce_schema:\n            command_parameters.append('--enforce-schema')\n\n        for twin_file_path in twin_file_paths:\n            if twin_file_path != \"\":\n                command_parameters.append('--nodes')\n                command_parameters.append(twin_file_path)\n\n        for relationship_file_path in relationship_file_paths:\n            if relationship_file_path != \"\":\n                command_parameters.append('--relations')\n                command_parameters.append(relationship_file_path)\n\n        command_parameters.append(self.graph.name)\n        logger.debug(command_parameters)\n        # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties\n        try:\n            bulk_insert(command_parameters)\n        except SystemExit as e:\n            print(e)\n</code></pre>"},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter.bulk_import","title":"<code>bulk_import(twin_file_paths=[], relationship_file_paths=[], enforce_schema=False)</code>","text":"<p>Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) <code>Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;</code>_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py</code> <pre><code>@GraphHandler.handle_graph_replace\ndef bulk_import(self, twin_file_paths: list = [], relationship_file_paths: list = [], enforce_schema: bool = False):\n    \"\"\"\n    Import all csv data\n    :param twin_file_paths: the file paths of all twin csv files\n    :param relationship_file_paths: the file paths of all relationship csv files\n    :param enforce_schema: True if the schema is defined within headers (default False)\n    `Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;`_\n    :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n    \"\"\"\n    command_parameters = ['--host', self.host, '--port', self.port]\n\n    if self.password is not None:\n        command_parameters.append('--password')\n        command_parameters.append(self.password)\n\n    if enforce_schema:\n        command_parameters.append('--enforce-schema')\n\n    for twin_file_path in twin_file_paths:\n        if twin_file_path != \"\":\n            command_parameters.append('--nodes')\n            command_parameters.append(twin_file_path)\n\n    for relationship_file_path in relationship_file_paths:\n        if relationship_file_path != \"\":\n            command_parameters.append('--relations')\n            command_parameters.append(relationship_file_path)\n\n    command_parameters.append(self.graph.name)\n    logger.debug(command_parameters)\n    # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties\n    try:\n        bulk_insert(command_parameters)\n    except SystemExit as e:\n        print(e)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_reader","text":""},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader","title":"<code>ModelReader</code>","text":"<p>             Bases: <code>GraphHandler</code></p> <p>Model Reader for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>class ModelReader(GraphHandler):\n    \"\"\"\n    Model Reader for cached data\n    \"\"\"\n\n    def get_twin_types(self) -&gt; list:\n        \"\"\"\n        Get twin types\n        :return: twin types list\n        \"\"\"\n        return [item for sublist in self.graph.labels() for item in sublist]\n\n    def get_twins_by_type(self, twin_type: str, limit: int = 0) -&gt; QueryResult:\n        \"\"\"\n        Get twins by type\n        :param twin_type: the twin type requested\n        :param limit: the limit number of twin retrieved\n        :return: the twin list corresponding to twin type parameter\n        \"\"\"\n        twin_query = f'MATCH (node:{twin_type}) RETURN node'\n        if limit != 0:\n            twin_query = f'{twin_query} LIMIT {str(limit)}'\n        logger.debug(f\"Query : {twin_query}\")\n        return self.graph.query(twin_query, read_only=True)\n\n    def get_twin_properties_by_type(self, twin_type: str) -&gt; list:\n        \"\"\"\n        Get twin properties regarding a twin_type\n        Note: this will work if all twin (with the same type) have same properties set\n        :param twin_type: the twin type\n        :return: the properties list\n        \"\"\"\n        result = []\n        twin_result = self.get_twins_by_type(twin_type, 1)\n        result_set = twin_result.result_set\n        if result_set and result_set[0]:\n            for key, val in result_set[0][0].properties.items():\n                if str(key) != ModelUtil.dt_id_key:\n                    result.append(str(key))\n                else:\n                    result.append(ModelUtil.id_key)\n        return result\n\n    def get_relationship_types(self) -&gt; list:\n        \"\"\"\n        Get relationship types\n        :return: relationship types list\n        \"\"\"\n        return [item for sublist in self.graph.relationship_types() for item in sublist]\n\n    def get_relationships_by_type(self, relationship_type: str, limit: int = 0) -&gt; QueryResult:\n        \"\"\"\n        Get relationships by type\n        :param relationship_type: the relationship type requested\n        :param limit: the limit number of twin retrieved\n        :return: the relationship list corresponding to relationship type parameter\n        \"\"\"\n        rel_query = f'MATCH (n)-[relation:{relationship_type}]-&gt;(m) RETURN n.{ModelUtil.dt_id_key} as {ModelUtil.source_key}, ' \\\n                    f'm.{ModelUtil.dt_id_key} as {ModelUtil.target_key}, relation'\n        if limit != 0:\n            rel_query = f'{rel_query} LIMIT {str(limit)}'\n        logger.debug(f\"Query : {rel_query}\")\n        return self.graph.query(rel_query, read_only=True)\n\n    def get_relationship_properties_by_type(self, relationship_type: str) -&gt; list:\n        \"\"\"\n        Get relationship properties regarding a relationship_type\n        Note: this will work if all relationship (with the same type) have same properties set\n        :param relationship_type: the relationship type\n        :return: the properties list\n        \"\"\"\n        result = [ModelUtil.source_key, ModelUtil.target_key]\n        relationship_result = self.get_relationships_by_type(relationship_type, 1)\n        result_set = relationship_result.result_set\n        if result_set and result_set[0]:\n            # relationship\n            for key, val in result_set[0][2].properties.items():\n                if not str(key) in result:\n                    if str(key) == ModelUtil.dt_id_key:\n                        result.append(ModelUtil.id_key)\n                    elif str(key) != ModelUtil.src_key and str(key) != ModelUtil.dest_key:\n                        result.append(str(key))\n        return result\n\n    def query(self, query: str, params: dict = None, timeout: int = None, read_only: bool = False) -&gt; QueryResult:\n        \"\"\"\n        Run specified query\n        :param query: the query to run\n        :param params: the parameters for the query if any\n        :param timeout: a specific timeout\n        :param read_only: executes a readonly query if set to True\n        :return: the QueryResult corresponding to specified query\n        \"\"\"\n        logger.debug(f\"Query : {query} with params : {params}\")\n        return self.graph.query(q=query, params=params, timeout=timeout, read_only=read_only)\n\n    def exists(self, key) -&gt; bool:\n        \"\"\"\n        Check if a key exists in Redis\n        :param key: the key\n        :return: True if exists else False\n        \"\"\"\n        return False if self.r.exists(key) == 0 else True\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.exists","title":"<code>exists(key)</code>","text":"<p>Check if a key exists in Redis :param key: the key :return: True if exists else False</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def exists(self, key) -&gt; bool:\n    \"\"\"\n    Check if a key exists in Redis\n    :param key: the key\n    :return: True if exists else False\n    \"\"\"\n    return False if self.r.exists(key) == 0 else True\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_properties_by_type","title":"<code>get_relationship_properties_by_type(relationship_type)</code>","text":"<p>Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationship_properties_by_type(self, relationship_type: str) -&gt; list:\n    \"\"\"\n    Get relationship properties regarding a relationship_type\n    Note: this will work if all relationship (with the same type) have same properties set\n    :param relationship_type: the relationship type\n    :return: the properties list\n    \"\"\"\n    result = [ModelUtil.source_key, ModelUtil.target_key]\n    relationship_result = self.get_relationships_by_type(relationship_type, 1)\n    result_set = relationship_result.result_set\n    if result_set and result_set[0]:\n        # relationship\n        for key, val in result_set[0][2].properties.items():\n            if not str(key) in result:\n                if str(key) == ModelUtil.dt_id_key:\n                    result.append(ModelUtil.id_key)\n                elif str(key) != ModelUtil.src_key and str(key) != ModelUtil.dest_key:\n                    result.append(str(key))\n    return result\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_types","title":"<code>get_relationship_types()</code>","text":"<p>Get relationship types :return: relationship types list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationship_types(self) -&gt; list:\n    \"\"\"\n    Get relationship types\n    :return: relationship types list\n    \"\"\"\n    return [item for sublist in self.graph.relationship_types() for item in sublist]\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationships_by_type","title":"<code>get_relationships_by_type(relationship_type, limit=0)</code>","text":"<p>Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationships_by_type(self, relationship_type: str, limit: int = 0) -&gt; QueryResult:\n    \"\"\"\n    Get relationships by type\n    :param relationship_type: the relationship type requested\n    :param limit: the limit number of twin retrieved\n    :return: the relationship list corresponding to relationship type parameter\n    \"\"\"\n    rel_query = f'MATCH (n)-[relation:{relationship_type}]-&gt;(m) RETURN n.{ModelUtil.dt_id_key} as {ModelUtil.source_key}, ' \\\n                f'm.{ModelUtil.dt_id_key} as {ModelUtil.target_key}, relation'\n    if limit != 0:\n        rel_query = f'{rel_query} LIMIT {str(limit)}'\n    logger.debug(f\"Query : {rel_query}\")\n    return self.graph.query(rel_query, read_only=True)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_properties_by_type","title":"<code>get_twin_properties_by_type(twin_type)</code>","text":"<p>Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twin_properties_by_type(self, twin_type: str) -&gt; list:\n    \"\"\"\n    Get twin properties regarding a twin_type\n    Note: this will work if all twin (with the same type) have same properties set\n    :param twin_type: the twin type\n    :return: the properties list\n    \"\"\"\n    result = []\n    twin_result = self.get_twins_by_type(twin_type, 1)\n    result_set = twin_result.result_set\n    if result_set and result_set[0]:\n        for key, val in result_set[0][0].properties.items():\n            if str(key) != ModelUtil.dt_id_key:\n                result.append(str(key))\n            else:\n                result.append(ModelUtil.id_key)\n    return result\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_types","title":"<code>get_twin_types()</code>","text":"<p>Get twin types :return: twin types list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twin_types(self) -&gt; list:\n    \"\"\"\n    Get twin types\n    :return: twin types list\n    \"\"\"\n    return [item for sublist in self.graph.labels() for item in sublist]\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twins_by_type","title":"<code>get_twins_by_type(twin_type, limit=0)</code>","text":"<p>Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twins_by_type(self, twin_type: str, limit: int = 0) -&gt; QueryResult:\n    \"\"\"\n    Get twins by type\n    :param twin_type: the twin type requested\n    :param limit: the limit number of twin retrieved\n    :return: the twin list corresponding to twin type parameter\n    \"\"\"\n    twin_query = f'MATCH (node:{twin_type}) RETURN node'\n    if limit != 0:\n        twin_query = f'{twin_query} LIMIT {str(limit)}'\n    logger.debug(f\"Query : {twin_query}\")\n    return self.graph.query(twin_query, read_only=True)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.query","title":"<code>query(query, params=None, timeout=None, read_only=False)</code>","text":"<p>Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def query(self, query: str, params: dict = None, timeout: int = None, read_only: bool = False) -&gt; QueryResult:\n    \"\"\"\n    Run specified query\n    :param query: the query to run\n    :param params: the parameters for the query if any\n    :param timeout: a specific timeout\n    :param read_only: executes a readonly query if set to True\n    :return: the QueryResult corresponding to specified query\n    \"\"\"\n    logger.debug(f\"Query : {query} with params : {params}\")\n    return self.graph.query(q=query, params=params, timeout=timeout, read_only=read_only)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_writer","text":""},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter","title":"<code>ModelWriter</code>","text":"<p>             Bases: <code>GraphHandler</code></p> <p>Model Writer for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>class ModelWriter(GraphHandler):\n    \"\"\"\n    Model Writer for cached data\n    \"\"\"\n\n    def create_twin(self, twin_type: str, properties: dict):\n        \"\"\"\n        Create a twin\n        :param twin_type: the twin type\n        :param properties: the twin properties\n        \"\"\"\n        create_query = ModelUtil.create_twin_query(twin_type, properties)\n        logger.debug(f\"Query: {create_query}\")\n        self.graph.query(create_query)\n\n    def create_relationship(self, relationship_type: str, properties: dict):\n        \"\"\"\n        Create a relationship\n        :param relationship_type: the relationship type\n        :param properties: the relationship properties\n        \"\"\"\n        create_rel = ModelUtil.create_relationship_query(relationship_type, properties)\n        logger.debug(f\"Query: {create_rel}\")\n        self.graph.query(create_rel)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_relationship","title":"<code>create_relationship(relationship_type, properties)</code>","text":"<p>Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>def create_relationship(self, relationship_type: str, properties: dict):\n    \"\"\"\n    Create a relationship\n    :param relationship_type: the relationship type\n    :param properties: the relationship properties\n    \"\"\"\n    create_rel = ModelUtil.create_relationship_query(relationship_type, properties)\n    logger.debug(f\"Query: {create_rel}\")\n    self.graph.query(create_rel)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_twin","title":"<code>create_twin(twin_type, properties)</code>","text":"<p>Create a twin :param twin_type: the twin type :param properties: the twin properties</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>def create_twin(self, twin_type: str, properties: dict):\n    \"\"\"\n    Create a twin\n    :param twin_type: the twin type\n    :param properties: the twin properties\n    \"\"\"\n    create_query = ModelUtil.create_twin_query(twin_type, properties)\n    logger.debug(f\"Query: {create_query}\")\n    self.graph.query(create_query)\n</code></pre>"},{"location":"references/Modelops/core/tests/redis_test/","title":"CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test","text":""},{"location":"references/Modelops/core/tests/redis_test/#CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test","title":"<code>redis_test</code>","text":""},{"location":"references/Modelops/core/tests/redis_test/#CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test.redis_service","title":"<code>redis_service(docker_ip, docker_services)</code>","text":"<p>ensure redis is up and running</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/tests/redis_test.py</code> <pre><code>@pytest.fixture(scope='session')\ndef redis_service(docker_ip, docker_services):\n    \"\"\"ensure redis is up and running\"\"\"\n\n    host = docker_ip\n    port = docker_services.port_for(\"redis\", 6379)\n    redis_client = redis.Redis(host=host, port=port)\n\n    docker_services.wait_until_responsive(timeout=5, pause=0.2, check=redis_client.ping)\n    return {\"host\": host, \"port\": port}\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.model_util","text":""},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil","title":"<code>ModelUtil</code>","text":"<p>Utility class for Redis management</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>class ModelUtil:\n    \"\"\"\n    Utility class for Redis management\n    \"\"\"\n\n    # ADT variables\n    source_key = 'source'\n    target_key = 'target'\n    id_key = 'id'\n\n    # Redis/Csm variables\n    src_key = 'src'\n    dest_key = 'dest'\n    dt_id_key = 'id'\n\n    @staticmethod\n    def dict_to_cypher_parameters(parameters: dict) -&gt; str:\n        \"\"\"\n        Convert a dict to usable Cypher parameters object\n        :param parameters: parameters dict\n        :return: string representing parameters as Cyper Parameters\n        \"\"\"\n\n        cypher_list = []\n        for key, value in parameters.items():\n            formatted_value = stringify_param_value(value)\n            if isinstance(value, str):\n                try:\n                    json.loads(value)\n                    formatted_value = json.dumps(value)\n                except ValueError:\n                    logger.debug(f\"{value} is not a jsonString, use the raw value\")\n            cypher_list.append(f\"{key} : {formatted_value}\")\n        joined_list = ', '.join(cypher_list)\n        return '{' + joined_list + '}'\n\n    @staticmethod\n    def create_index_query(entity_name: str, entity_property_name: str) -&gt; str:\n        \"\"\"\n        Create an index query\n        :param entity_name: the entity name on which you want to define an index\n        :param entity_property_name:  the entity property name on which you want to define an index\n        :return: the create index query\n        \"\"\"\n        return f\"CREATE INDEX ON :{entity_name}({entity_property_name})\"\n\n    @staticmethod\n    def create_twin_query(twin_type: str, properties: dict) -&gt; str:\n        \"\"\"\n        Create a twin query\n        :param twin_type:the future twin name\n        :param properties: the properties of the twin\n        :return: the create twin query\n        \"\"\"\n        if ModelUtil.dt_id_key in properties:\n            cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n            return f\"CREATE (:{twin_type} {cypher_params})\"\n        raise Exception(f\"When you create a twin, you should define at least {ModelUtil.dt_id_key} properties \")\n\n    @staticmethod\n    def create_relationship_query(relationship_type: str, properties: dict) -&gt; str:\n        \"\"\"\n        Create a relationship query\n        :param relationship_type: the future relationship name\n        :param properties: the properties of the relationship (should contain 'src' and 'dest' properties)\n        :return: the create relationship query\n        \"\"\"\n\n        if ModelUtil.src_key in properties and ModelUtil.dest_key in properties:\n            cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n            return f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.src_key)}' \" \\\n                   f\"AND m.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.dest_key)}' \" \\\n                   f\"CREATE (n)-[r:{relationship_type} {cypher_params}]-&gt;(m) RETURN r\"\n        raise Exception(\n            f\"When you create a relationship, you should define at least {ModelUtil.src_key} and {ModelUtil.dest_key} properties \"\n        )\n\n    @staticmethod\n    def dict_to_json(obj: dict) -&gt; str:\n        \"\"\"\n        Transform a dict to a json string\n        :param obj: the dict\n        :return: the json string corresponding\n        \"\"\"\n        return json.dumps(obj, indent=2)\n\n    @staticmethod\n    def result_set_to_json(query_result: QueryResult) -&gt; list:\n        \"\"\"\n        Transform a QueryResult object to a json string list\n        :param query_result: the QueryResult object\n        :return: the json string list\n        \"\"\"\n        flattened_headers = [item for sublist in query_result.header for item in sublist]\n        headers_without_integers = [x for x in flattened_headers if not isinstance(x, int)]\n        result_list = []\n        for result in query_result.result_set:\n            result_dict = {}\n            for i in range(len(headers_without_integers)):\n                obj = result[i]\n                if isinstance(obj, Edge) or isinstance(obj, Node):\n                    result_dict[headers_without_integers[i]] = obj.properties\n                else:\n                    result_dict[headers_without_integers[i]] = obj\n            result_list.append(ModelUtil.dict_to_json(result_dict))\n        return result_list\n\n    @staticmethod\n    def print_query_result(query_result: QueryResult) -&gt; None:\n        \"\"\"\n        Pretty print a QueryResult\n        :param query_result: the QueryResult to print\n        \"\"\"\n        list_to_print = ModelUtil.result_set_to_json(query_result)\n        for result in list_to_print:\n            print(result)\n\n    @staticmethod\n    def convert_datetime_to_str(date: datetime) -&gt; str:\n        \"\"\"\n        Convert a datetime to a str\n        :param date: the datetime\n        :return: the string representing the datetime\n        \"\"\"\n        return date.strftime('%Y/%m/%d - %H:%M:%S')\n\n    @staticmethod\n    def convert_str_to_datetime(date_str: str) -&gt; datetime:\n        \"\"\"\n        Convert a datetime to a str\n        :param date_str: the str representing a date\n        :return: the datetime corresponding to date_str\n        \"\"\"\n        date_time_obj = datetime.strptime(date_str, '%Y/%m/%d - %H:%M:%S')\n        return date_time_obj\n\n    @staticmethod\n    def build_graph_key_pattern(graph_name: str) -&gt; str:\n        return graph_name + \":*\"\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_datetime_to_str","title":"<code>convert_datetime_to_str(date)</code>  <code>staticmethod</code>","text":"<p>Convert a datetime to a str :param date: the datetime :return: the string representing the datetime</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef convert_datetime_to_str(date: datetime) -&gt; str:\n    \"\"\"\n    Convert a datetime to a str\n    :param date: the datetime\n    :return: the string representing the datetime\n    \"\"\"\n    return date.strftime('%Y/%m/%d - %H:%M:%S')\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_str_to_datetime","title":"<code>convert_str_to_datetime(date_str)</code>  <code>staticmethod</code>","text":"<p>Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef convert_str_to_datetime(date_str: str) -&gt; datetime:\n    \"\"\"\n    Convert a datetime to a str\n    :param date_str: the str representing a date\n    :return: the datetime corresponding to date_str\n    \"\"\"\n    date_time_obj = datetime.strptime(date_str, '%Y/%m/%d - %H:%M:%S')\n    return date_time_obj\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_index_query","title":"<code>create_index_query(entity_name, entity_property_name)</code>  <code>staticmethod</code>","text":"<p>Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name:  the entity property name on which you want to define an index :return: the create index query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_index_query(entity_name: str, entity_property_name: str) -&gt; str:\n    \"\"\"\n    Create an index query\n    :param entity_name: the entity name on which you want to define an index\n    :param entity_property_name:  the entity property name on which you want to define an index\n    :return: the create index query\n    \"\"\"\n    return f\"CREATE INDEX ON :{entity_name}({entity_property_name})\"\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_relationship_query","title":"<code>create_relationship_query(relationship_type, properties)</code>  <code>staticmethod</code>","text":"<p>Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_relationship_query(relationship_type: str, properties: dict) -&gt; str:\n    \"\"\"\n    Create a relationship query\n    :param relationship_type: the future relationship name\n    :param properties: the properties of the relationship (should contain 'src' and 'dest' properties)\n    :return: the create relationship query\n    \"\"\"\n\n    if ModelUtil.src_key in properties and ModelUtil.dest_key in properties:\n        cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n        return f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.src_key)}' \" \\\n               f\"AND m.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.dest_key)}' \" \\\n               f\"CREATE (n)-[r:{relationship_type} {cypher_params}]-&gt;(m) RETURN r\"\n    raise Exception(\n        f\"When you create a relationship, you should define at least {ModelUtil.src_key} and {ModelUtil.dest_key} properties \"\n    )\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_twin_query","title":"<code>create_twin_query(twin_type, properties)</code>  <code>staticmethod</code>","text":"<p>Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_twin_query(twin_type: str, properties: dict) -&gt; str:\n    \"\"\"\n    Create a twin query\n    :param twin_type:the future twin name\n    :param properties: the properties of the twin\n    :return: the create twin query\n    \"\"\"\n    if ModelUtil.dt_id_key in properties:\n        cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n        return f\"CREATE (:{twin_type} {cypher_params})\"\n    raise Exception(f\"When you create a twin, you should define at least {ModelUtil.dt_id_key} properties \")\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_cypher_parameters","title":"<code>dict_to_cypher_parameters(parameters)</code>  <code>staticmethod</code>","text":"<p>Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef dict_to_cypher_parameters(parameters: dict) -&gt; str:\n    \"\"\"\n    Convert a dict to usable Cypher parameters object\n    :param parameters: parameters dict\n    :return: string representing parameters as Cyper Parameters\n    \"\"\"\n\n    cypher_list = []\n    for key, value in parameters.items():\n        formatted_value = stringify_param_value(value)\n        if isinstance(value, str):\n            try:\n                json.loads(value)\n                formatted_value = json.dumps(value)\n            except ValueError:\n                logger.debug(f\"{value} is not a jsonString, use the raw value\")\n        cypher_list.append(f\"{key} : {formatted_value}\")\n    joined_list = ', '.join(cypher_list)\n    return '{' + joined_list + '}'\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_json","title":"<code>dict_to_json(obj)</code>  <code>staticmethod</code>","text":"<p>Transform a dict to a json string :param obj: the dict :return: the json string corresponding</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef dict_to_json(obj: dict) -&gt; str:\n    \"\"\"\n    Transform a dict to a json string\n    :param obj: the dict\n    :return: the json string corresponding\n    \"\"\"\n    return json.dumps(obj, indent=2)\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.print_query_result","title":"<code>print_query_result(query_result)</code>  <code>staticmethod</code>","text":"<p>Pretty print a QueryResult :param query_result: the QueryResult to print</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef print_query_result(query_result: QueryResult) -&gt; None:\n    \"\"\"\n    Pretty print a QueryResult\n    :param query_result: the QueryResult to print\n    \"\"\"\n    list_to_print = ModelUtil.result_set_to_json(query_result)\n    for result in list_to_print:\n        print(result)\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.result_set_to_json","title":"<code>result_set_to_json(query_result)</code>  <code>staticmethod</code>","text":"<p>Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef result_set_to_json(query_result: QueryResult) -&gt; list:\n    \"\"\"\n    Transform a QueryResult object to a json string list\n    :param query_result: the QueryResult object\n    :return: the json string list\n    \"\"\"\n    flattened_headers = [item for sublist in query_result.header for item in sublist]\n    headers_without_integers = [x for x in flattened_headers if not isinstance(x, int)]\n    result_list = []\n    for result in query_result.result_set:\n        result_dict = {}\n        for i in range(len(headers_without_integers)):\n            obj = result[i]\n            if isinstance(obj, Edge) or isinstance(obj, Node):\n                result_dict[headers_without_integers[i]] = obj.properties\n            else:\n                result_dict[headers_without_integers[i]] = obj\n        result_list.append(ModelUtil.dict_to_json(result_dict))\n    return result_list\n</code></pre>"},{"location":"references/Modelops/core/utils/tests/model_util_test/","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test","text":""},{"location":"references/Modelops/core/utils/tests/model_util_test/#CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test.TestModelUtil","title":"<code>TestModelUtil</code>","text":"<p>             Bases: <code>TestCase</code></p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/tests/model_util_test.py</code> <pre><code>class TestModelUtil(unittest.TestCase):\n    # Global variables\n    simple_parameters = {\n        \"id\": \"Twin1\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": {\n            \"property1\": \"toto\",\n            \"property2\": \"tata\",\n        },\n        \"with_quotes\": \"'9999'\",\n        \"with_dbl_quotes\": '\"1234\"',\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    relationship_simple_parameters = {\n        \"src\": \"Node1\",\n        \"dest\": \"Node2\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": {\n            \"property1\": \"toto\",\n            \"property2\": \"tata\",\n        },\n        \"with_quotes\": \"'12345'\",\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    dict_with_simple_json_string = {\n        \"src\": \"Node1\",\n        \"dest\": \"Node2\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": \"{\\\"property1\\\": \\\"toto\\\", \\\"property2\\\": \\\"tata\\\"}\",\n        \"with_quotes\": \"'12345'\",\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    expected_simple_parameters = '{id : \"Twin1\", ' \\\n                                 'brand : \"Ford\", ' \\\n                                 'electric : False, ' \\\n                                 'year : 1964, ' \\\n                                 'dict_param : {property1:\\\"toto\\\",property2:\\\"tata\\\"}, ' \\\n                                 'with_quotes : \"\\'9999\\'\", ' \\\n                                 'with_dbl_quotes : \"\\\\\"1234\\\\\"\", ' \\\n                                 'colors : [\"red\",\"white\",\"blue\"]}'\n\n    expected_relationship_simple_parameters = '{src : \"Node1\", ' \\\n                                              'dest : \"Node2\", ' \\\n                                              'brand : \"Ford\", ' \\\n                                              'electric : False, ' \\\n                                              'year : 1964, ' \\\n                                              'dict_param : {property1:\\\"toto\\\",property2:\\\"tata\\\"}, ' \\\n                                              'with_quotes : \"\\'12345\\'\", ' \\\n                                              'colors : [\"red\",\"white\",\"blue\"]}'\n\n    def setUp(self):\n        self.model_util = ModelUtil()\n\n    def test_dict_to_cypher_parameters_with_simple_parameters(self):\n        self.assertEqual(self.expected_simple_parameters,\n                         self.model_util.dict_to_cypher_parameters(self.simple_parameters))\n\n    def test_create_index_query(self):\n        expected_result = \"CREATE INDEX ON :Entity_Test(property_name_test)\"\n        self.assertEqual(expected_result, self.model_util.create_index_query(\"Entity_Test\", \"property_name_test\"))\n\n    def test_create_twin_query(self):\n        expected_result = f\"CREATE (:Entity_Test {self.expected_simple_parameters})\"\n        self.assertEqual(expected_result, self.model_util.create_twin_query(\"Entity_Test\", self.simple_parameters))\n\n    def test_create_twin_query_Exception(self):\n        twin_name = 'Twin_name'\n        self.assertRaises(Exception, self.model_util.create_twin_query, twin_name, self.expected_simple_parameters)\n\n    def test_create_relationship_query(self):\n        source_id = 'Node1'\n        destination_id = 'Node2'\n        relation_name = 'Relation_Name'\n        expected_result = f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{source_id}' AND m.{ModelUtil.dt_id_key} = '{destination_id}' CREATE (n)-[r:{relation_name} {self.expected_relationship_simple_parameters}]-&gt;(m) RETURN r\"\n        self.assertEqual(expected_result,\n                         self.model_util.create_relationship_query(relation_name, self.relationship_simple_parameters))\n\n    def test_create_relationship_query_Exception(self):\n        relation_name = 'Relation_Name'\n        self.assertRaises(Exception, self.model_util.create_relationship_query, relation_name,\n                          self.expected_simple_parameters)\n</code></pre>"}]}