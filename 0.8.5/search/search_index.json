{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cosmotech Acceleration library","text":"<p>Acceleration library for CosmoTech cloud based solution development</p>"},{"location":"#csm-data","title":"csm-data","text":"<p><code>csm-data</code> is a CLI made to give CosmoTech solution modelers and integrators accelerators to start interacting with multiple systems.</p> <p>It gives a first entrypoint to get ready to use commands to send and retrieve data from a number of systems in which a Cosmo Tech API could be integrated</p>"},{"location":"#data-store","title":"data-store","text":"<p>The data store gives a way to keep local data during simulations and comes with <code>csm-data</code> commands to easily send those data to a target system allowing to easily send results anywhere.</p>"},{"location":"#legacy-part","title":"Legacy part","text":"<p>The following description is tied to the legacy part of CoAL that is getting slowly moved to the new code organization before a 1.0.0 release</p>"},{"location":"#code-organisation","title":"Code organisation","text":"<p>In project root directory you'll find 4 main directories:</p> <ul> <li>CosmoTech_Acceleration_Library: containing all Cosmo Tech libraries to accelerate interaction with Cosmo Tech solutions</li> <li>data: a bunch of csv files on which samples are based</li> <li>samples: a bunch of python scripts to demonstrate how to use the library</li> <li>doc: for schema or specific documentation</li> </ul>"},{"location":"#accelerators","title":"Accelerators","text":"<p>TODO</p>"},{"location":"#modelops-library","title":"Modelops library","text":"<p>The aim of this library is to simplify the model accesses via python code.</p> <p>The library can be used by Data Scientists, Modelers, Developers, ...</p>"},{"location":"#utility-classes","title":"Utility classes","text":"<ul> <li><code>ModelImporter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to bulk import data from csv files with schema enforced (<code>samples/Modelops/Bulk_Import_from_CSV_with_schema.py</code>) or not (<code>samples/Modelops/Bulk_Import_from_CSV_without_schema.py</code>) (see documentation for further details)</li> <li><code>ModelExporter(host: str, port: int, name: str, version: int, export_dir: str = '/')</code> : will allow you to export data from a model cache instance</li> <li><code>ModelReader(host: str, port: int, name: str, version: int)</code> : will allow you to read data from a model cache instance (object returned)</li> <li><code>ModelWriter(host: str, port: int, name: str, version: int, graph_rotation:int = 1)</code> : will allow you to write data into a model instance</li> <li><code>ModelUtil</code> : a bunch of utilities to manipulate and facilitate interaction with model instance (result_set_to_json, print_query_result, ... )</li> <li><code>ModelMetadata</code>: will allow you to management graph metadata</li> </ul>"},{"location":"dependencies/","title":"List of dependencies","text":"<p>Azure connection requirements </p> <p>Keycloak connection </p> <p>Modelops requirements </p> <p>Cosmotech specific requirements </p> <p>Commands requirements </p> <p>Orchestrator templates requirements </p> <p>Data store requirements </p> <p>CLI requirements </p> <p>Other requirements </p> <p>fix distutils missing from 3.12   Documentation generation   Extra requirements   Test requirements </p>"},{"location":"csm-data/","title":"csm-data","text":"<p>Help command</p> <pre><code>&gt; csm-data --help\n\n Usage: csm-data [OPTIONS] COMMAND [ARGS]...                                    \n\n Cosmo Tect Data Interface                                                      \n Command toolkit provinding quick implementation of data connections to use     \n inside the Cosmo Tech Platform                                                 \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --log-level    LVL  Either CRITICAL, ERROR, WARNING, INFO or DEBUG           \u2502\n\u2502                     ENV: LOG_LEVEL                                           \u2502\n\u2502 --version           Print version number and return.                         \u2502\n\u2502 --web-help          Open the web documentation                               \u2502\n\u2502 --help              Show this message and exit.                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 adx-send-scenariodata  Uses environment variables to send content of CSV     \u2502\n\u2502                        files to ADX Requires a valid Azure connection either \u2502\n\u2502                        with:                                                 \u2502\n\u2502                                                                              \u2502\n\u2502                         \u2022 The AZ cli command: az login                       \u2502\n\u2502                         \u2022 A triplet of env var AZURE_TENANT_ID,              \u2502\n\u2502                           AZURE_CLIENT_ID, AZURE_CLIENT_SECRET               \u2502\n\u2502 api                    Cosmo Tech API helper command                         \u2502\n\u2502 legacy                 Cosmo Tech legacy API group                           \u2502\n\u2502 s3-bucket-download     Download S3 bucket content to a given folder          \u2502\n\u2502 s3-bucket-upload       Upload a folder to a S3 Bucket                        \u2502\n\u2502 store                  CoAL Data Store command group                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/adx-send-scenariodata/","title":"adx-send-scenariodata","text":"<p>Help command</p> <pre><code>&gt; csm-data adx-send-scenariodata --help\n\n Usage: csm-data adx-send-scenariodata [OPTIONS]                                \n\n Uses environment variables to send content of CSV files to ADX Requires a      \n valid Azure connection either with:                                            \n\n  \u2022 The AZ cli command: az login                                                \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET  \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --dataset-absolute-path            PATH  A local folder to store the main \u2502\n\u2502                                             dataset content                  \u2502\n\u2502                                             ENV: CSM_DATASET_ABSOLUTE_PATH   \u2502\n\u2502                                             [required]                       \u2502\n\u2502 *  --parameters-absolute-path         PATH  A local folder to store the      \u2502\n\u2502                                             parameters content               \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             CSM_PARAMETERS_ABSOLUTE_PATH     \u2502\n\u2502                                             [required]                       \u2502\n\u2502 *  --simulation-id                    UUID  the Simulation Id to add to      \u2502\n\u2502                                             records                          \u2502\n\u2502                                             ENV: CSM_SIMULATION_ID           \u2502\n\u2502                                             [required]                       \u2502\n\u2502 *  --adx-uri                          URI   the ADX cluster path (URI info   \u2502\n\u2502                                             can be found into ADX cluster    \u2502\n\u2502                                             page)                            \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             AZURE_DATA_EXPLORER_RESOURCE_URI \u2502\n\u2502                                             [required]                       \u2502\n\u2502 *  --adx-ingest-uri                   URI   The ADX cluster ingest path (URI \u2502\n\u2502                                             info can be found into ADX       \u2502\n\u2502                                             cluster page)                    \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             AZURE_DATA_EXPLORER_RESOURCE_IN\u2026 \u2502\n\u2502                                             [required]                       \u2502\n\u2502 *  --database-name                    NAME  The targeted database name       \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             AZURE_DATA_EXPLORER_DATABASE_NA\u2026 \u2502\n\u2502                                             [required]                       \u2502\n\u2502    --send-parameters/--no-send-pa\u2026          whether or not to send           \u2502\n\u2502                                             parameters (parameters path is   \u2502\n\u2502                                             mandatory then)                  \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             CSM_SEND_DATAWAREHOUSE_PARAMETE\u2026 \u2502\n\u2502                                             DEFAULT: no-send-parameters      \u2502\n\u2502    --send-datasets/--no-send-data\u2026          whether or not to send datasets  \u2502\n\u2502                                             (parameters path is mandatory    \u2502\n\u2502                                             then)                            \u2502\n\u2502                                             ENV:                             \u2502\n\u2502                                             CSM_SEND_DATAWAREHOUSE_DATASETS  \u2502\n\u2502                                             DEFAULT: no-send-datasets        \u2502\n\u2502    --wait/--no-wait                         Toggle waiting for the ingestion \u2502\n\u2502                                             results                          \u2502\n\u2502                                             ENV: WAIT_FOR_INGESTION          \u2502\n\u2502                                             DEFAULT: no-wait                 \u2502\n\u2502    --web-help                               Open the web documentation       \u2502\n\u2502    --help                                   Show this message and exit.      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/s3-bucket-download/","title":"s3-bucket-download","text":"<p>Help command</p> <pre><code>&gt; csm-data s3-bucket-download --help\n\n Usage: csm-data s3-bucket-download [OPTIONS]                                   \n\n Download S3 bucket content to a given folder                                   \n Will download everything in the bucket unless a prefix is set, then only file  \n following the given prefix will be downloaded                                  \n\n Make use of the boto3 library to access the bucket                             \n\n More information is available on this page:                                    \n d=976122;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.ht\u001b]8;;\u001b\\ \n d=976122;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\ml\u001b]8;;\u001b\\                                                                             \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --target-folder       PATH    The folder in which to download the bucket  \u2502\n\u2502                                  content                                     \u2502\n\u2502                                  ENV: CSM_DATASET_ABSOLUTE_PATH              \u2502\n\u2502                                  [required]                                  \u2502\n\u2502 *  --bucket-name         BUCKET  The bucket on S3 to download                \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_NAME                   \u2502\n\u2502                                  [required]                                  \u2502\n\u2502    --prefix-filter       PREFIX  A prefix by which all downloaded files      \u2502\n\u2502                                  should start in the bucket                  \u2502\n\u2502                                  ENV: CSM_DATA_BUCKET_PREFIX                 \u2502\n\u2502    --use-ssl/--no-ssl            Use SSL to secure connection to S3          \u2502\n\u2502 *  --s3-url              URL     URL to connect to the S3 system             \u2502\n\u2502                                  ENV: AWS_ENDPOINT_URL                       \u2502\n\u2502                                  [required]                                  \u2502\n\u2502 *  --access-id           ID      Identity used to connect to the S3 system   \u2502\n\u2502                                  ENV: AWS_ACCESS_KEY_ID                      \u2502\n\u2502                                  [required]                                  \u2502\n\u2502 *  --secret-key          ID      Secret tied to the ID used to connect to    \u2502\n\u2502                                  the S3 system                               \u2502\n\u2502                                  ENV: AWS_SECRET_ACCESS_KEY                  \u2502\n\u2502                                  [required]                                  \u2502\n\u2502    --ssl-cert-bundle     PATH    Path to an alternate CA Bundle to validate  \u2502\n\u2502                                  SSL connections                             \u2502\n\u2502                                  ENV: CSM_S3_CA_BUNDLE                       \u2502\n\u2502    --web-help                    Open the web documentation                  \u2502\n\u2502    --help                        Show this message and exit.                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/s3-bucket-upload/","title":"s3-bucket-upload","text":"<p>Help command</p> <pre><code>&gt; csm-data s3-bucket-upload --help\n\n Usage: csm-data s3-bucket-upload [OPTIONS]                                     \n\n Upload a folder to a S3 Bucket                                                 \n Will upload everything from a given folder to a S3 bucket. If a single file is \n passed only it will be uploaded, and recursive will be ignored                 \n\n Giving a prefix will add it to every upload (finishing the prefix with a \"/\"   \n will allow to upload in a folder inside the bucket)                            \n\n Make use of the boto3 library to access the bucket                             \n\n More information is available on this page:                                    \n d=909940;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.ht\u001b]8;;\u001b\\ \n d=909940;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\ml\u001b]8;;\u001b\\                                                                             \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --source-folder               PATH    The folder/file to upload to the    \u2502\n\u2502                                          target bucket                       \u2502\n\u2502                                          ENV: CSM_DATASET_ABSOLUTE_PATH      \u2502\n\u2502                                          [required]                          \u2502\n\u2502    --recursive/--no-recursive            Recursively send the content of     \u2502\n\u2502                                          every folder inside the starting    \u2502\n\u2502                                          folder to the bucket                \u2502\n\u2502 *  --bucket-name                 BUCKET  The bucket on S3 to upload to       \u2502\n\u2502                                          ENV: CSM_DATA_BUCKET_NAME           \u2502\n\u2502                                          [required]                          \u2502\n\u2502    --prefix                      PREFIX  A prefix by which all uploaded      \u2502\n\u2502                                          files should start with in the      \u2502\n\u2502                                          bucket                              \u2502\n\u2502                                          ENV: CSM_DATA_BUCKET_PREFIX         \u2502\n\u2502    --use-ssl/--no-ssl                    Use SSL to secure connection to S3  \u2502\n\u2502 *  --s3-url                      URL     URL to connect to the S3 system     \u2502\n\u2502                                          ENV: AWS_ENDPOINT_URL               \u2502\n\u2502                                          [required]                          \u2502\n\u2502 *  --access-id                   ID      Identity used to connect to the S3  \u2502\n\u2502                                          system                              \u2502\n\u2502                                          ENV: AWS_ACCESS_KEY_ID              \u2502\n\u2502                                          [required]                          \u2502\n\u2502 *  --secret-key                  ID      Secret tied to the ID used to       \u2502\n\u2502                                          connect to the S3 system            \u2502\n\u2502                                          ENV: AWS_SECRET_ACCESS_KEY          \u2502\n\u2502                                          [required]                          \u2502\n\u2502    --ssl-cert-bundle             PATH    Path to an alternate CA Bundle to   \u2502\n\u2502                                          validate SSL connections            \u2502\n\u2502                                          ENV: CSM_S3_CA_BUNDLE               \u2502\n\u2502    --web-help                            Open the web documentation          \u2502\n\u2502    --help                                Show this message and exit.         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/","title":"api","text":"<p>Help command</p> <pre><code>&gt; csm-data api --help\n\n Usage: csm-data api [OPTIONS] COMMAND [ARGS]...                                \n\n Cosmo Tech API helper command                                                  \n This command will inform you of which connection is available to use for the   \n Cosmo Tech API                                                                 \n\n If no connection is available, will list all possible set of parameters and    \n return an error code,                                                          \n\n You can use this command in a csm-orc template to make sure that API           \n connection is available.                                                       \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                   \u2502\n\u2502 --help          Show this message and exit.                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 rds-load-csv              Download a CSV file from the Cosmo Tech Run API    \u2502\n\u2502                           using a given SQL query                            \u2502\n\u2502 rds-send-csv              Send all csv files from a folder to the results    \u2502\n\u2502                           service of the Cosmo Tech API                      \u2502\n\u2502 rds-send-store            Send all CoAL Datastore content to the results     \u2502\n\u2502                           service of the Cosmo Tech API                      \u2502\n\u2502 run-load-data             Download a runner data from the Cosmo Tech API     \u2502\n\u2502                           Requires a valid Azure connection either with:     \u2502\n\u2502                                                                              \u2502\n\u2502                            \u2022 The AZ cli command: az login                    \u2502\n\u2502                            \u2022 A triplet of env var AZURE_TENANT_ID,           \u2502\n\u2502                              AZURE_CLIENT_ID, AZURE_CLIENT_SECRET            \u2502\n\u2502                                                                              \u2502\n\u2502                           Requires env var CSM_API_URL     The URL to a      \u2502\n\u2502                           Cosmotech API                                      \u2502\n\u2502                           Requires env var CSM_API_SCOPE   The               \u2502\n\u2502                           identification scope of a Cosmotech API            \u2502\n\u2502 runtemplate-load-handler  Uses environment variables to download cloud based \u2502\n\u2502                           Template steps                                     \u2502\n\u2502 scenariorun-load-data     Uses environment variables to call the             \u2502\n\u2502                           download_scenario_data function Requires a valid   \u2502\n\u2502                           Azure connection either with:                      \u2502\n\u2502                                                                              \u2502\n\u2502                            \u2022 The AZ cli command: az login                    \u2502\n\u2502                            \u2022 A triplet of env var AZURE_TENANT_ID,           \u2502\n\u2502                              AZURE_CLIENT_ID, AZURE_CLIENT_SECRET            \u2502\n\u2502 tdl-load-files            Query a twingraph and loads all the data from it   \u2502\n\u2502 tdl-send-files            Reads a folder CSVs and send those to the Cosmo    \u2502\n\u2502                           Tech API as a Dataset                              \u2502\n\u2502 wsf-load-file             Load files from a workspace inside the API         \u2502\n\u2502 wsf-send-file             Send a file to a workspace inside the API          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-load-csv/","title":"rds-load-csv","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-load-csv --help\n\n Usage: csm-data api rds-load-csv [OPTIONS]                                     \n\n Download a CSV file from the Cosmo Tech Run API using a given SQL query        \n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --target-folder      PATH        The folder where the csv will be written \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH           \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API          \u2502\n\u2502                                     ENV: CSM_RUN_ID                          \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --file-name          NAME        A file name to write the query results   \u2502\n\u2502                                     DEFAULT: results                         \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --query              SQL_QUERY   A run id for the Cosmo Tech API          \u2502\n\u2502                                     DEFAULT: SELECT table_name FROM          \u2502\n\u2502                                     information_schema.tables WHERE          \u2502\n\u2502                                     table_schema='public'                    \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-send-csv/","title":"rds-send-csv","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-send-csv --help\n\n Usage: csm-data api rds-send-csv [OPTIONS]                                     \n\n Send all csv files from a folder to the results service of the Cosmo Tech API  \n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --source-folder      PATH        The folder containing csvs to send       \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH           \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API          \u2502\n\u2502                                     ENV: CSM_RUN_ID                          \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/rds-send-store/","title":"rds-send-store","text":"<p>Help command</p> <pre><code>&gt; csm-data api rds-send-store --help\n\n Usage: csm-data api rds-send-store [OPTIONS]                                   \n\n Send all CoAL Datastore content to the results service of the Cosmo Tech API   \n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder       PATH        The folder containing the store files    \u2502\n\u2502                                     ENV: CSM_PARAMETERS_ABSOLUTE_PATH        \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API          \u2502\n\u2502                                     ENV: CSM_RUN_ID                          \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/run-load-data/","title":"run-load-data","text":"<p>Help command</p> <pre><code>&gt; csm-data api run-load-data --help\n\n Usage: csm-data api run-load-data [OPTIONS]                                    \n\n Download a runner data from the Cosmo Tech API Requires a valid Azure          \n connection either with:                                                        \n\n  \u2022 The AZ cli command: az login                                                \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET  \n\n Requires env var CSM_API_URL     The URL to a Cosmotech API                    \n Requires env var CSM_API_SCOPE   The identification scope of a Cosmotech API   \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id             o-##########  The id of an organization in  \u2502\n\u2502                                                the cosmotech api             \u2502\n\u2502                                                ENV: CSM_ORGANIZATION_ID      \u2502\n\u2502                                                [required]                    \u2502\n\u2502 *  --workspace-id                w-##########  The id of a workspace in the  \u2502\n\u2502                                                cosmotech api                 \u2502\n\u2502                                                ENV: CSM_WORKSPACE_ID         \u2502\n\u2502                                                [required]                    \u2502\n\u2502 *  --runner-id                   s-##########  The id of a runner in the     \u2502\n\u2502                                                cosmotech api                 \u2502\n\u2502                                                ENV: CSM_RUNNER_ID            \u2502\n\u2502                                                [required]                    \u2502\n\u2502 *  --parameters-absolute-path    PATH          A local folder to store the   \u2502\n\u2502                                                parameters content            \u2502\n\u2502                                                ENV:                          \u2502\n\u2502                                                CSM_PARAMETERS_ABSOLUTE_PATH  \u2502\n\u2502                                                [required]                    \u2502\n\u2502    --web-help                                  Open the web documentation    \u2502\n\u2502    --help                                      Show this message and exit.   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/runtemplate-load-handler/","title":"runtemplate-load-handler","text":"<p>Help command</p> <pre><code>&gt; csm-data api runtemplate-load-handler --help\n\n Usage: csm-data api runtemplate-load-handler [OPTIONS]                         \n\n Uses environment variables to download cloud based Template steps              \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-##########         The id of an organization in    \u2502\n\u2502                                              the cosmotech api               \u2502\n\u2502                                              ENV: CSM_ORGANIZATION_ID        \u2502\n\u2502                                              [required]                      \u2502\n\u2502 *  --workspace-id       w-##########         The id of a solution in the     \u2502\n\u2502                                              cosmotech api                   \u2502\n\u2502                                              ENV: CSM_WORKSPACE_ID           \u2502\n\u2502                                              [required]                      \u2502\n\u2502 *  --run-template-id    NAME                 The name of the run template in \u2502\n\u2502                                              the cosmotech api               \u2502\n\u2502                                              ENV: CSM_RUN_TEMPLATE_ID        \u2502\n\u2502                                              [required]                      \u2502\n\u2502 *  --handler-list       HANDLER,...,HANDLER  A list of handlers to download  \u2502\n\u2502                                              (comma separated)               \u2502\n\u2502                                              ENV: CSM_CONTAINER_MODE         \u2502\n\u2502                                              [required]                      \u2502\n\u2502    --web-help                                Open the web documentation      \u2502\n\u2502    --help                                    Show this message and exit.     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/scenariorun-load-data/","title":"scenariorun-load-data","text":"<p>Help command</p> <pre><code>&gt; csm-data api scenariorun-load-data --help\n\n Usage: csm-data api scenariorun-load-data [OPTIONS]                            \n\n Uses environment variables to call the download_scenario_data function         \n Requires a valid Azure connection either with:                                 \n\n  \u2022 The AZ cli command: az login                                                \n  \u2022 A triplet of env var AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET  \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id              o-##########  The id of an organization in \u2502\n\u2502                                                 the cosmotech api            \u2502\n\u2502                                                 ENV: CSM_ORGANIZATION_ID     \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --workspace-id                 w-##########  The id of a workspace in the \u2502\n\u2502                                                 cosmotech api                \u2502\n\u2502                                                 ENV: CSM_WORKSPACE_ID        \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --scenario-id                  s-##########  The id of a scenario in the  \u2502\n\u2502                                                 cosmotech api                \u2502\n\u2502                                                 ENV: CSM_SCENARIO_ID         \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --dataset-absolute-path        PATH          A local folder to store the  \u2502\n\u2502                                                 main dataset content         \u2502\n\u2502                                                 ENV:                         \u2502\n\u2502                                                 CSM_DATASET_ABSOLUTE_PATH    \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --parameters-absolute-path     PATH          A local folder to store the  \u2502\n\u2502                                                 parameters content           \u2502\n\u2502                                                 ENV:                         \u2502\n\u2502                                                 CSM_PARAMETERS_ABSOLUTE_PATH \u2502\n\u2502                                                 [required]                   \u2502\n\u2502    --write-json/--no-write-js\u2026                  Toggle writing of parameters \u2502\n\u2502                                                 in json format               \u2502\n\u2502                                                 ENV: WRITE_JSON              \u2502\n\u2502                                                 DEFAULT: no-write-json       \u2502\n\u2502    --write-csv/--no-write-csv                   Toggle writing of parameters \u2502\n\u2502                                                 in csv format                \u2502\n\u2502                                                 ENV: WRITE_CSV               \u2502\n\u2502                                                 DEFAULT: write-csv           \u2502\n\u2502    --fetch-dataset/--no-fetch\u2026                  Toggle fetching datasets     \u2502\n\u2502                                                 ENV: FETCH_DATASET           \u2502\n\u2502                                                 DEFAULT: fetch-dataset       \u2502\n\u2502    --parallel/--no-parallel                     Toggle parallelization while \u2502\n\u2502                                                 fetching datasets,           \u2502\n\u2502                                                 ENV:                         \u2502\n\u2502                                                 FETCH_DATASETS_IN_PARALLEL   \u2502\n\u2502                                                 DEFAULT: parallel            \u2502\n\u2502    --web-help                                   Open the web documentation   \u2502\n\u2502    --help                                       Show this message and exit.  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/tdl-load-files/","title":"tdl-load-files","text":"<p>Help command</p> <pre><code>&gt; csm-data api tdl-load-files --help\n\n Usage: csm-data api tdl-load-files [OPTIONS]                                   \n\n Query a twingraph and loads all the data from it                               \n Will create 1 csv file per node type / relationship type                       \n\n The twingraph must have been populated using the \"tdl-send-files\" command for  \n this to work correctly                                                         \n\n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --scenario-id        s-XXXXXXXX  A scenario id for the Cosmo Tech API     \u2502\n\u2502                                     ENV: CSM_SCENARIO_ID                     \u2502\n\u2502    --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502 *  --dir                PATH        Path to the directory to write the       \u2502\n\u2502                                     results to                               \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH           \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/tdl-send-files/","title":"tdl-send-files","text":"<p>Help command</p> <pre><code>&gt; csm-data api tdl-send-files --help\n\n Usage: csm-data api tdl-send-files [OPTIONS]                                   \n\n Reads a folder CSVs and send those to the Cosmo Tech API as a Dataset          \n CSVs must follow a given format :                                              \n\n  \u2022 Nodes files must have an id column                                          \n  \u2022 Relationship files must have id, src and dest columns                       \n\n Non-existing relationship (aka dest or src does not point to existing node)    \n won't trigger an error, the relationship will not be created instead.          \n\n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --api-url            URI         The URI to a Cosmo Tech API instance     \u2502\n\u2502                                     ENV: CSM_API_URL                         \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --dir                PATH        Path to the directory containing csvs to \u2502\n\u2502                                     send                                     \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH           \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --clear/--keep                   Flag to clear the target dataset first   \u2502\n\u2502                                     (if set to True will clear the dataset   \u2502\n\u2502                                     before sending anything, irreversibly)   \u2502\n\u2502                                     DEFAULT: clear                           \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/wsf-load-file/","title":"wsf-load-file","text":"<p>Help command</p> <pre><code>&gt; csm-data api wsf-load-file --help\n\n Usage: csm-data api wsf-load-file [OPTIONS]                                    \n\n Load files from a workspace inside the API                                     \n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --workspace-path     PATH        Path inside the workspace to load (end   \u2502\n\u2502                                     with '/' for a folder)                   \u2502\n\u2502 *  --target-folder      PATH        Folder in which to send the downloaded   \u2502\n\u2502                                     file                                     \u2502\n\u2502                                     ENV: CSM_DATASET_ABSOLUTE_PATH           \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/api/wsf-send-file/","title":"wsf-send-file","text":"<p>Help command</p> <pre><code>&gt; csm-data api wsf-send-file --help\n\n Usage: csm-data api wsf-send-file [OPTIONS]                                    \n\n Send a file to a workspace inside the API                                      \n Requires a valid connection to the API to send the data                        \n\n This implementation make use of an API Key                                     \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id     o-XXXXXXXX  An organization id for the Cosmo Tech   \u2502\n\u2502                                      API                                     \u2502\n\u2502                                      ENV: CSM_ORGANIZATION_ID                \u2502\n\u2502                                      [required]                              \u2502\n\u2502 *  --workspace-id        w-XXXXXXXX  A workspace id for the Cosmo Tech API   \u2502\n\u2502                                      ENV: CSM_WORKSPACE_ID                   \u2502\n\u2502                                      [required]                              \u2502\n\u2502 *  --file-path           PATH        Path to the file to send as a workspace \u2502\n\u2502                                      file                                    \u2502\n\u2502                                      [required]                              \u2502\n\u2502 *  --workspace-path      PATH        Path inside the workspace to store the  \u2502\n\u2502                                      file (end with '/' for a folder)        \u2502\n\u2502                                      [required]                              \u2502\n\u2502    --overwrite/--keep                Flag to overwrite the target file       \u2502\n\u2502                                      DEFAULT: overwrite                      \u2502\n\u2502    --web-help                        Open the web documentation              \u2502\n\u2502    --help                            Show this message and exit.             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/","title":"legacy","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy --help\n\n Usage: csm-data legacy [OPTIONS] COMMAND [ARGS]...                             \n\n Cosmo Tech legacy API group                                                    \n This group will allow you to connect to the CosmoTech API and migrate          \n solutions from pre-3.0 version to 3.X compatible solutions                     \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                   \u2502\n\u2502 --help          Show this message and exit.                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 generate-orchestrator        Base command for the json generator using       \u2502\n\u2502                              legacy files                                    \u2502\n\u2502                              Check the help of the sub commands for more     \u2502\n\u2502                              information:                                    \u2502\n\u2502                                                                              \u2502\n\u2502                               \u2022 cloud requires access to a fully deployed    \u2502\n\u2502                                 solution                                     \u2502\n\u2502                               \u2022 solution requires a Solution.yaml file       \u2502\n\u2502 init-local-parameter-folder  Base command to initialize parameter folders    \u2502\n\u2502                              Will create:                                    \u2502\n\u2502                                                                              \u2502\n\u2502                               \u2022 A parameters.json/parameters.csv in the      \u2502\n\u2502                                 folder with all parameters                   \u2502\n\u2502                               \u2022 A folder per %DATASETID% datasets with the   \u2502\n\u2502                                 name of the parameter                        \u2502\n\u2502                                 Check the help of the sub commands for more  \u2502\n\u2502                                 information:                                 \u2502\n\u2502                               \u2022 cloud requires access to a fully deployed    \u2502\n\u2502                                 solution                                     \u2502\n\u2502                               \u2022 solution requires a Solution.yaml file       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/","title":"generate-orchestrator","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator --help\n\n Usage: csm-data legacy generate-orchestrator [OPTIONS] COMMAND [ARGS]...       \n\n Base command for the json generator using legacy files                         \n Check the help of the sub commands for more information:                       \n\n  \u2022 cloud requires access to a fully deployed solution                          \n  \u2022 solution requires a Solution.yaml file                                      \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                   \u2502\n\u2502 --help          Show this message and exit.                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 from-api   Connect to the cosmotech API to download a run template and       \u2502\n\u2502            generate an orchestrator file at OUTPUT                           \u2502\n\u2502 from-file  Read SOLUTION_FILE to get a RUN_TEMPLATE_ID and generate an       \u2502\n\u2502            orchestrator file at OUTPUT                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/from-api/","title":"from-api","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator from-api --help\n\n Usage: csm-data legacy generate-orchestrator from-api [OPTIONS] OUTPUT         \n\n Connect to the cosmotech API to download a run template and generate an        \n orchestrator file at OUTPUT                                                    \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  OUTPUT    FILE  [required]                                                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id           o-##########  The id of an organization in    \u2502\n\u2502                                              the cosmotech api               \u2502\n\u2502                                              ENV: CSM_ORGANIZATION_ID        \u2502\n\u2502                                              [required]                      \u2502\n\u2502 *  --workspace-id              w-##########  The id of a solution in the     \u2502\n\u2502                                              cosmotech api                   \u2502\n\u2502                                              ENV: CSM_WORKSPACE_ID           \u2502\n\u2502                                              [required]                      \u2502\n\u2502 *  --run-template-id           NAME          The name of the run template in \u2502\n\u2502                                              the cosmotech api               \u2502\n\u2502                                              ENV: CSM_RUN_TEMPLATE_ID        \u2502\n\u2502                                              [required]                      \u2502\n\u2502    --describe/--no-describe                  Show a description of the       \u2502\n\u2502                                              generated template after        \u2502\n\u2502                                              generation                      \u2502\n\u2502                                              DEFAULT: no-describe            \u2502\n\u2502    --web-help                                Open the web documentation      \u2502\n\u2502    --help                                    Show this message and exit.     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/generate-orchestrator/from-file/","title":"from-file","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy generate-orchestrator from-file --help\n\n Usage:                                                                         \n csm-data legacy generate-orchestrator from-file                                \n [OPTIONS] SOLUTION_FILE OUTPUT RUN_TEMPLATE_ID                                 \n\n Read SOLUTION_FILE to get a RUN_TEMPLATE_ID and generate an orchestrator file  \n at OUTPUT                                                                      \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  SOLUTION_FILE      FILE  [required]                                       \u2502\n\u2502 *  OUTPUT             FILE  [required]                                       \u2502\n\u2502 *  RUN-TEMPLATE-ID    TEXT  [required]                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --describe/--no-describe      Show a description of the generated template   \u2502\n\u2502                               after generation                               \u2502\n\u2502                               DEFAULT: no-describe                           \u2502\n\u2502 --web-help                    Open the web documentation                     \u2502\n\u2502 --help                        Show this message and exit.                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/","title":"init-local-parameter-folder","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder --help\n\n Usage: csm-data legacy init-local-parameter-folder [OPTIONS] COMMAND [ARGS]... \n\n Base command to initialize parameter folders                                   \n Will create:                                                                   \n\n  \u2022 A parameters.json/parameters.csv in the folder with all parameters          \n  \u2022 A folder per %DATASETID% datasets with the name of the parameter            \n    Check the help of the sub commands for more information:                    \n  \u2022 cloud requires access to a fully deployed solution                          \n  \u2022 solution requires a Solution.yaml file                                      \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                   \u2502\n\u2502 --help          Show this message and exit.                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 cloud     Initialize parameter folder for given run template from CosmoTech  \u2502\n\u2502           cloud API                                                          \u2502\n\u2502 solution  Initialize parameter folder for given run template from a Solution \u2502\n\u2502           yaml file                                                          \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/cloud/","title":"cloud","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder cloud --help\n\n Usage:                  csm-data legacy init-local-parameter-folder cloud      \n [OPTIONS] OUTPUT_FOLDER                                                        \n\n Initialize parameter folder for given run template from CosmoTech cloud API    \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  OUTPUT_FOLDER    PATH  [required]                                         \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --organization-id              o-##########  The id of an organization in \u2502\n\u2502                                                 the cosmotech api            \u2502\n\u2502                                                 ENV: CSM_ORGANIZATION_ID     \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --workspace-id                 w-##########  The id of a solution in the  \u2502\n\u2502                                                 cosmotech api                \u2502\n\u2502                                                 ENV: CSM_WORKSPACE_ID        \u2502\n\u2502                                                 [required]                   \u2502\n\u2502 *  --run-template-id              NAME          The name of the run template \u2502\n\u2502                                                 in the cosmotech api         \u2502\n\u2502                                                 ENV: CSM_RUN_TEMPLATE_ID     \u2502\n\u2502                                                 [required]                   \u2502\n\u2502    --write-json/--no-write-js\u2026                  Toggle writing of parameters \u2502\n\u2502                                                 in json format               \u2502\n\u2502                                                 ENV: WRITE_JSON              \u2502\n\u2502                                                 DEFAULT: no-write-json       \u2502\n\u2502    --write-csv/--no-write-csv                   Toggle writing of parameters \u2502\n\u2502                                                 in csv format                \u2502\n\u2502                                                 ENV: WRITE_CSV               \u2502\n\u2502                                                 DEFAULT: write-csv           \u2502\n\u2502    --web-help                                   Open the web documentation   \u2502\n\u2502    --help                                       Show this message and exit.  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/legacy/init-local-parameter-folder/solution/","title":"solution","text":"<p>Help command</p> <pre><code>&gt; csm-data legacy init-local-parameter-folder solution --help\n\n Usage:                                                                         \n csm-data legacy init-local-parameter-folder solution                           \n [OPTIONS] SOLUTION_FILE OUTPUT_FOLDER RUN_TEMPLATE_ID                          \n\n Initialize parameter folder for given run template from a Solution yaml file   \n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  SOLUTION_FILE      FILE  [required]                                       \u2502\n\u2502 *  OUTPUT_FOLDER      PATH  [required]                                       \u2502\n\u2502 *  RUN_TEMPLATE_ID    TEXT  [required]                                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --write-json/--no-write-json      Toggle writing of parameters in json       \u2502\n\u2502                                   format                                     \u2502\n\u2502                                   ENV: WRITE_JSON                            \u2502\n\u2502                                   DEFAULT: no-write-json                     \u2502\n\u2502 --write-csv/--no-write-csv        Toggle writing of parameters in csv format \u2502\n\u2502                                   ENV: WRITE_CSV                             \u2502\n\u2502                                   DEFAULT: write-csv                         \u2502\n\u2502 --web-help                        Open the web documentation                 \u2502\n\u2502 --help                            Show this message and exit.                \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/","title":"store","text":"<p>Help command</p> <pre><code>&gt; csm-data store --help\n\n Usage: csm-data store [OPTIONS] COMMAND [ARGS]...                              \n\n CoAL Data Store command group                                                  \n This group of commands will give you helper commands to interact with the      \n datastore                                                                      \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --web-help      Open the web documentation                                   \u2502\n\u2502 --help          Show this message and exit.                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 dump-to-postgresql  Running this command will dump your store to a given     \u2502\n\u2502                     postgresql database                                      \u2502\n\u2502 dump-to-s3          Dump a datastore to a S3                                 \u2502\n\u2502 list-tables         Running this command will list the existing tables in    \u2502\n\u2502                     your datastore                                           \u2502\n\u2502 load-csv-folder     Running this command will find all csvs in the given     \u2502\n\u2502                     folder and put them in the store                         \u2502\n\u2502 rds-send-store      Send all CoAL Datastore content to the results service   \u2502\n\u2502                     of the Cosmo Tech API                                    \u2502\n\u2502 reset               Running this command will reset the state of your store  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/dump-to-postgresql/","title":"dump-to-postgresql","text":"<p>Help command</p> <pre><code>&gt; csm-data store dump-to-postgresql --help\n\n Usage: csm-data store dump-to-postgresql [OPTIONS]                             \n\n Running this command will dump your store to a given postgresql database       \n Tables names from the store will be prepended with table-prefix in target      \n database                                                                       \n\n The postgresql user must have USAGE granted on the schema for this script to   \n work due to the use of the command COPY FROM STDIN                             \n\n You can simply give him that grant by running the command : GRANT USAGE ON     \n SCHEMA &lt;schema&gt; TO &lt;username&gt;                                                  \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder         PATH     The folder containing the store files     \u2502\n\u2502                                    ENV: CSM_PARAMETERS_ABSOLUTE_PATH         \u2502\n\u2502                                    [required]                                \u2502\n\u2502    --table-prefix         PREFIX   Prefix to add to the table name           \u2502\n\u2502 *  --postgres-host        TEXT     Postgresql host URI                       \u2502\n\u2502                                    ENV: POSTGRES_HOST_URI                    \u2502\n\u2502                                    [required]                                \u2502\n\u2502    --postgres-port        INTEGER  Postgresql database port                  \u2502\n\u2502                                    ENV: POSTGRES_HOST_PORT                   \u2502\n\u2502 *  --postgres-db          TEXT     Postgresql database name                  \u2502\n\u2502                                    ENV: POSTGRES_DB_NAME                     \u2502\n\u2502                                    [required]                                \u2502\n\u2502 *  --postgres-schema      TEXT     Postgresql schema name                    \u2502\n\u2502                                    ENV: POSTGRES_DB_SCHEMA                   \u2502\n\u2502                                    [required]                                \u2502\n\u2502 *  --postgres-user        TEXT     Postgresql connection user name           \u2502\n\u2502                                    ENV: POSTGRES_USER_NAME                   \u2502\n\u2502                                    [required]                                \u2502\n\u2502 *  --postgres-password    TEXT     Postgresql connection password            \u2502\n\u2502                                    ENV: POSTGRES_USER_PASSWORD               \u2502\n\u2502                                    [required]                                \u2502\n\u2502    --replace/--append              Append data on existing tables            \u2502\n\u2502                                    DEFAULT: replace                          \u2502\n\u2502    --help                          Show this message and exit.               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/dump-to-s3/","title":"dump-to-s3","text":"<p>Help command</p> <pre><code>&gt; csm-data store dump-to-s3 --help\n\n Usage: csm-data store dump-to-s3 [OPTIONS]                                     \n\n Dump a datastore to a S3                                                       \n Will upload everything from a given data store to a S3 bucket.                 \n\n 3 modes currently exists :                                                     \n\n  \u2022 sqlite : will dump the data store underlying database as is                 \n  \u2022 csv : will convert every table of the datastore to csv and send them as     \n    separate files                                                              \n  \u2022 parquet : will convert every table of the datastore to parquet and send     \n    them as separate files                                                      \n\n Giving a prefix will add it to every upload (finishing the prefix with a \"/\"   \n will allow to upload in a folder inside the bucket)                            \n\n Make use of the boto3 library to access the bucket                             \n\n More information is available on this page:                                    \n d=784712;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.ht\u001b]8;;\u001b\\ \n d=784712;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\u001b\\ml\u001b]8;;\u001b\\                                                                             \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder        PATH                  The folder containing the     \u2502\n\u2502                                                store files                   \u2502\n\u2502                                                ENV:                          \u2502\n\u2502                                                CSM_PARAMETERS_ABSOLUTE_PATH  \u2502\n\u2502                                                [required]                    \u2502\n\u2502    --output-type         [sqlite|csv|parquet]  Choose the type of file       \u2502\n\u2502                                                output to use                 \u2502\n\u2502 *  --bucket-name         BUCKET                The bucket on S3 to upload to \u2502\n\u2502                                                ENV: CSM_DATA_BUCKET_NAME     \u2502\n\u2502                                                [required]                    \u2502\n\u2502    --prefix              PREFIX                A prefix by which all         \u2502\n\u2502                                                uploaded files should start   \u2502\n\u2502                                                with in the bucket            \u2502\n\u2502                                                ENV: CSM_DATA_BUCKET_PREFIX   \u2502\n\u2502    --use-ssl/--no-ssl                          Use SSL to secure connection  \u2502\n\u2502                                                to S3                         \u2502\n\u2502 *  --s3-url              URL                   URL to connect to the S3      \u2502\n\u2502                                                system                        \u2502\n\u2502                                                ENV: AWS_ENDPOINT_URL         \u2502\n\u2502                                                [required]                    \u2502\n\u2502 *  --access-id           ID                    Identity used to connect to   \u2502\n\u2502                                                the S3 system                 \u2502\n\u2502                                                ENV: AWS_ACCESS_KEY_ID        \u2502\n\u2502                                                [required]                    \u2502\n\u2502 *  --secret-key          ID                    Secret tied to the ID used to \u2502\n\u2502                                                connect to the S3 system      \u2502\n\u2502                                                ENV: AWS_SECRET_ACCESS_KEY    \u2502\n\u2502                                                [required]                    \u2502\n\u2502    --ssl-cert-bundle     PATH                  Path to an alternate CA       \u2502\n\u2502                                                Bundle to validate SSL        \u2502\n\u2502                                                connections                   \u2502\n\u2502                                                ENV: CSM_S3_CA_BUNDLE         \u2502\n\u2502    --web-help                                  Open the web documentation    \u2502\n\u2502    --help                                      Show this message and exit.   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/list-tables/","title":"list-tables","text":"<p>Help command</p> <pre><code>&gt; csm-data store list-tables --help\n\n Usage: csm-data store list-tables [OPTIONS]                                    \n\n Running this command will list the existing tables in your datastore           \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder          PATH  The folder containing the store files       \u2502\n\u2502                                  ENV: CSM_PARAMETERS_ABSOLUTE_PATH           \u2502\n\u2502                                  [required]                                  \u2502\n\u2502    --schema/--no-schema          Display the schema of the tables            \u2502\n\u2502    --help                        Show this message and exit.                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/load-csv-folder/","title":"load-csv-folder","text":"<p>Help command</p> <pre><code>&gt; csm-data store load-csv-folder --help\n\n Usage: csm-data store load-csv-folder [OPTIONS]                                \n\n Running this command will find all csvs in the given folder and put them in    \n the store                                                                      \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder    PATH  The folder containing the store files             \u2502\n\u2502                            ENV: CSM_PARAMETERS_ABSOLUTE_PATH                 \u2502\n\u2502                            [required]                                        \u2502\n\u2502 *  --csv-folder      PATH  The folder containing the csv files to store      \u2502\n\u2502                            ENV: CSM_DATASET_ABSOLUTE_PATH                    \u2502\n\u2502                            [required]                                        \u2502\n\u2502    --help                  Show this message and exit.                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/rds-send-store/","title":"rds-send-store","text":"<p>Help command</p> <pre><code>&gt; csm-data store rds-send-store --help\n\n Usage: csm-data store rds-send-store [OPTIONS]                                 \n\n Send all CoAL Datastore content to the results service of the Cosmo Tech API   \n Requires a valid connection to the API to send the data                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder       PATH        The folder containing the store files    \u2502\n\u2502                                     ENV: CSM_PARAMETERS_ABSOLUTE_PATH        \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --organization-id    o-XXXXXXXX  An organization id for the Cosmo Tech    \u2502\n\u2502                                     API                                      \u2502\n\u2502                                     ENV: CSM_ORGANIZATION_ID                 \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --workspace-id       w-XXXXXXXX  A workspace id for the Cosmo Tech API    \u2502\n\u2502                                     ENV: CSM_WORKSPACE_ID                    \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --runner-id          r-XXXXXXXX  A runner id for the Cosmo Tech API       \u2502\n\u2502                                     ENV: CSM_RUNNER_ID                       \u2502\n\u2502                                     [required]                               \u2502\n\u2502 *  --run-id             run-XXXXXX  A run id for the Cosmo Tech API          \u2502\n\u2502                                     ENV: CSM_RUN_ID                          \u2502\n\u2502                                     [required]                               \u2502\n\u2502    --web-help                       Open the web documentation               \u2502\n\u2502    --help                           Show this message and exit.              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"csm-data/store/reset/","title":"reset","text":"<p>Help command</p> <pre><code>&gt; csm-data store reset --help\n\n Usage: csm-data store reset [OPTIONS]                                          \n\n Running this command will reset the state of your store                        \n\n\u256d\u2500 OPTIONS \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *  --store-folder    PATH  The folder containing the store files             \u2502\n\u2502                            ENV: CSM_PARAMETERS_ABSOLUTE_PATH                 \u2502\n\u2502                            [required]                                        \u2502\n\u2502    --help                  Show this message and exit.                       \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"references/SUMMARY/","title":"SUMMARY","text":"<ul> <li>References<ul> <li>Accelerators<ul> <li>adx_wrapper</li> <li>scenario_download<ul> <li>scenario_downloader_test</li> <li>scenario_downloader</li> <li>azure_function_main</li> </ul> </li> </ul> </li> <li>Modelops<ul> <li>core<ul> <li>io<ul> <li>model_exporter</li> <li>model_writer</li> <li>model_reader</li> <li>model_importer</li> </ul> </li> <li>common<ul> <li>redis_handler</li> <li>graph_handler</li> <li>writer<ul> <li>CsvWriter</li> </ul> </li> </ul> </li> <li>tests<ul> <li>redis_test</li> </ul> </li> <li>utils<ul> <li>model_util</li> <li>tests<ul> <li>model_util_test</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"references/Accelerators/adx_wrapper/","title":"CosmoTech_Acceleration_Library.Accelerators.adx_wrapper","text":""},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper","title":"<code>ADXQueriesWrapper</code>","text":"<p>Wrapping class to ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>class ADXQueriesWrapper:\n    \"\"\"\n    Wrapping class to ADX\n    \"\"\"\n\n    def __init__(self,\n                 database: str,\n                 cluster_url: Union[str, None] = None,\n                 ingest_url: Union[str, None] = None,\n                 cluster_name: Union[str, None] = None,\n                 cluster_region: Union[str, None] = None):\n\n        if cluster_name and cluster_region:\n            cluster_url = f\"https://{cluster_name}.{cluster_region}.kusto.windows.net\"\n            ingest_url = f\"https://ingest-{cluster_name}.{cluster_region}.kusto.windows.net\"\n\n        try:\n            az_client_id = os.environ['AZURE_CLIENT_ID']\n            az_client_secret = os.environ['AZURE_CLIENT_SECRET']\n            az_tenant_id = os.environ['AZURE_TENANT_ID']\n\n            self.cluster_kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(cluster_url,\n                                                                                                     az_client_id,\n                                                                                                     az_client_secret,\n                                                                                                     az_tenant_id)\n            self.ingest_kcsb = KustoConnectionStringBuilder.with_aad_application_key_authentication(ingest_url,\n                                                                                                    az_client_id,\n                                                                                                    az_client_secret,\n                                                                                                    az_tenant_id)\n        except KeyError:\n            self.cluster_kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(cluster_url)\n            self.ingest_kcsb = KustoConnectionStringBuilder.with_az_cli_authentication(ingest_url)\n        self.kusto_client = KustoClient(self.cluster_kcsb)\n        self.ingest_client = QueuedIngestClient(self.ingest_kcsb)\n        self.database = database\n\n        self.timeout = 900\n\n        self.ingest_status = dict()\n        self.ingest_times = dict()\n\n    @staticmethod\n    def type_mapping(key: str, key_example_value) -&gt; str:\n        \"\"\"\n        This method is used to replace the type name from python to the one used in ADX\n        :param key: the name of the key\n        :param key_example_value: a possible value of the key\n        :return: the name of the type used in ADX\n        \"\"\"\n\n        if key == \"SimulationRun\":\n            return \"guid\"\n\n        try:\n            # Use dateutil parser to test if the value could be a date, in case of error it is not\n            dateutil.parser.parse(key_example_value, fuzzy=False)\n            return \"datetime\"\n        except (ValueError, TypeError):\n            pass\n\n        if type(key_example_value) is float:\n            return \"real\"\n\n        if type(key_example_value) is int:\n            return \"long\"\n\n        # Default case to string\n        return \"string\"\n\n    def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                    drop_by_tag: str = None):\n        \"\"\"\n        Will take a list of dict items and send them to a given table in ADX\n        :param dict_list: list of dict objects requiring to have the same keys\n        :param table_name: The name of the table in which the data should be sent\n        :param ignore_table_creation: If set to True won't try to create a table to send the data\n        :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n        :return: A boolean check if the data have been sent to ADX\n        \"\"\"\n\n        if not ignore_table_creation:\n            # If the target table does not exist create it\n            # First create the columns types needed for the table\n            types = {k: self.type_mapping(k, dict_list[0][k]) for k in dict_list[0].keys()}\n            # Then try to create the table\n            if not self.create_table(table_name, types):\n                print(f\"Error creating table {table_name}.\")\n                return False\n\n        # Create a dataframe with the data to write and send them to ADX\n        df = pd.DataFrame(dict_list)\n        ingestion_result = self.ingest_dataframe(table_name, df, drop_by_tag)\n        return ingestion_result\n\n    def ingest_dataframe(self, table_name: str, dataframe: pd.DataFrame, drop_by_tag: str = None):\n        \"\"\"\n        Write the content of dataframe to a table\n        :param table_name: name of the target table\n        :param dataframe: dataframe containing the data to be written\n        :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n        :return: None\n        \"\"\"\n        drop_by_tags = [drop_by_tag] if (drop_by_tag is not None) else None\n        properties = IngestionProperties(database=self.database, table=table_name, data_format=DataFormat.CSV,\n                                         drop_by_tags=drop_by_tags, report_level=ReportLevel.FailuresAndSuccesses)\n        client = self.ingest_client\n        ingestion_result = client.ingest_from_dataframe(dataframe, ingestion_properties=properties)\n        self.ingest_status[str(ingestion_result.source_id)] = IngestionStatus.QUEUED\n        self.ingest_times[str(ingestion_result.source_id)] = time.time()\n        return ingestion_result\n\n    def check_ingestion_status(self, source_ids: list[str],\n                               timeout: int = None,\n                               logs: bool = False) -&gt; Iterator[tuple[str, IngestionStatus]]:\n        remaining_ids = []\n        for source_id in source_ids:\n            if source_id not in self.ingest_status:\n                self.ingest_status[source_id] = IngestionStatus.UNKNOWN\n                self.ingest_times[source_id] = time.time()\n            if self.ingest_status[source_id] not in [IngestionStatus.QUEUED, IngestionStatus.UNKNOWN]:\n                yield source_id, self.ingest_status[source_id]\n            else:\n                remaining_ids.append(source_id)\n\n        qs = KustoIngestStatusQueues(self.ingest_client)\n\n        def get_messages(queues):\n            _r = []\n            for q in queues:\n                _r.extend(((q, m) for m in q.receive_messages(messages_per_page=32, visibility_timeout=1)))\n            return _r\n\n        successes = get_messages(qs.success._get_queues())\n        failures = get_messages(qs.failure._get_queues())\n\n        if logs:\n            print(f\"Success messages: {len(successes)}\")\n            print(f\"Failure messages: {len(failures)}\")\n        non_sent_ids = remaining_ids[:]\n        for messages, cast_func, status in [(successes, SuccessMessage, IngestionStatus.SUCCESS),\n                                            (failures, FailureMessage, IngestionStatus.FAILURE)]:\n            for _q, _m in messages:\n                dm = cast_func(_m.content)\n                to_check_ids = remaining_ids[:]\n                for source_id in to_check_ids:\n                    if dm.IngestionSourceId == str(source_id):\n                        self.ingest_status[source_id] = status\n                        if logs:\n                            print(f\"Found status for {source_id}: {status.value}\")\n                        _q.delete_message(_m)\n                        remaining_ids.remove(source_id)\n                        break\n                else:\n                    # The message did not correspond to a known ID\n                    continue\n                break\n            else:\n                # No message was found on the current list of messages for the given IDs\n                continue\n            break\n        else:\n            for source_id in remaining_ids:\n                if time.time() - self.ingest_times[source_id] &gt; ([timeout, self.timeout][timeout is None]):\n                    self.ingest_status[source_id] = IngestionStatus.TIMEOUT\n        for source_id in non_sent_ids:\n            yield source_id, self.ingest_status[source_id]\n\n    def _clear_ingestion_status_queues(self, confirmation: bool = False):\n        \"\"\"\n        Dangerous operation that will fully clear all data in the ingestion status queues\n        Those queues are common to all databases in the ADX Cluster so don't ut this unless you know what you are doing\n        :param confirmation: Unless confirmation is set to True, won't do anything\n        :return:\n        \"\"\"\n        if confirmation:\n            qs = KustoIngestStatusQueues(self.ingest_client)\n            while not qs.success.is_empty():\n                qs.success.pop(32)\n            while not qs.failure.is_empty():\n                qs.failure.pop(32)\n\n    def run_command_query(self, query: str):\n        \"\"\"\n        Execute a command query on the database\n        :param query: the query to execute\n        :return: the results of the query\n        \"\"\"\n        client = self.kusto_client\n        return client.execute_mgmt(self.database, query)\n\n    def run_query(self, query: str):\n        \"\"\"\n        Execute a simple query on the database\n        :param query: the query to execute\n        :return: the results of the query\n        \"\"\"\n        client = self.kusto_client\n        return client.execute(self.database, query)\n\n    def table_exists(self, table_name: str) -&gt; bool:\n        \"\"\"\n        Check if a table exists on the database\n        :param table_name: The table to look for\n        :return: does the table exits ?\n        \"\"\"\n        get_tables_query = f\".show database ['{self.database}'] schema| distinct TableName\"\n        tables = self.run_query(get_tables_query)\n        for r in tables.primary_results[0]:\n            if table_name == r[0]:\n                return True\n        return False\n\n    def create_table(self, table_name: str, schema: dict) -&gt; bool:\n        \"\"\"\n        Create a table on the database\n        :param table_name: the name of the table\n        :param schema: the schema associated to the table\n        :return: Is the table created ?\n        \"\"\"\n        create_query = f\".create-merge table {table_name}(\"\n        for column_name, column_type in schema.items():\n            create_query += f\"{column_name}:{column_type},\"\n        create_query = create_query[:-1] + \")\"\n        try:\n            self.run_query(create_query)\n        except Exception as e:\n            print(e)\n            return False\n        return True\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.create_table","title":"<code>create_table(table_name, schema)</code>","text":"<p>Create a table on the database :param table_name: the name of the table :param schema: the schema associated to the table :return: Is the table created ?</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def create_table(self, table_name: str, schema: dict) -&gt; bool:\n    \"\"\"\n    Create a table on the database\n    :param table_name: the name of the table\n    :param schema: the schema associated to the table\n    :return: Is the table created ?\n    \"\"\"\n    create_query = f\".create-merge table {table_name}(\"\n    for column_name, column_type in schema.items():\n        create_query += f\"{column_name}:{column_type},\"\n    create_query = create_query[:-1] + \")\"\n    try:\n        self.run_query(create_query)\n    except Exception as e:\n        print(e)\n        return False\n    return True\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.ingest_dataframe","title":"<code>ingest_dataframe(table_name, dataframe, drop_by_tag=None)</code>","text":"<p>Write the content of dataframe to a table :param table_name: name of the target table :param dataframe: dataframe containing the data to be written :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: None</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def ingest_dataframe(self, table_name: str, dataframe: pd.DataFrame, drop_by_tag: str = None):\n    \"\"\"\n    Write the content of dataframe to a table\n    :param table_name: name of the target table\n    :param dataframe: dataframe containing the data to be written\n    :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n    :return: None\n    \"\"\"\n    drop_by_tags = [drop_by_tag] if (drop_by_tag is not None) else None\n    properties = IngestionProperties(database=self.database, table=table_name, data_format=DataFormat.CSV,\n                                     drop_by_tags=drop_by_tags, report_level=ReportLevel.FailuresAndSuccesses)\n    client = self.ingest_client\n    ingestion_result = client.ingest_from_dataframe(dataframe, ingestion_properties=properties)\n    self.ingest_status[str(ingestion_result.source_id)] = IngestionStatus.QUEUED\n    self.ingest_times[str(ingestion_result.source_id)] = time.time()\n    return ingestion_result\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_command_query","title":"<code>run_command_query(query)</code>","text":"<p>Execute a command query on the database :param query: the query to execute :return: the results of the query</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def run_command_query(self, query: str):\n    \"\"\"\n    Execute a command query on the database\n    :param query: the query to execute\n    :return: the results of the query\n    \"\"\"\n    client = self.kusto_client\n    return client.execute_mgmt(self.database, query)\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.run_query","title":"<code>run_query(query)</code>","text":"<p>Execute a simple query on the database :param query: the query to execute :return: the results of the query</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def run_query(self, query: str):\n    \"\"\"\n    Execute a simple query on the database\n    :param query: the query to execute\n    :return: the results of the query\n    \"\"\"\n    client = self.kusto_client\n    return client.execute(self.database, query)\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.send_to_adx","title":"<code>send_to_adx(dict_list, table_name, ignore_table_creation=True, drop_by_tag=None)</code>","text":"<p>Will take a list of dict items and send them to a given table in ADX :param dict_list: list of dict objects requiring to have the same keys :param table_name: The name of the table in which the data should be sent :param ignore_table_creation: If set to True won't try to create a table to send the data :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API :return: A boolean check if the data have been sent to ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def send_to_adx(self, dict_list: list, table_name: str, ignore_table_creation: bool = True,\n                drop_by_tag: str = None):\n    \"\"\"\n    Will take a list of dict items and send them to a given table in ADX\n    :param dict_list: list of dict objects requiring to have the same keys\n    :param table_name: The name of the table in which the data should be sent\n    :param ignore_table_creation: If set to True won't try to create a table to send the data\n    :param drop_by_tag: Tag used for the drop by capacity of the Cosmotech API\n    :return: A boolean check if the data have been sent to ADX\n    \"\"\"\n\n    if not ignore_table_creation:\n        # If the target table does not exist create it\n        # First create the columns types needed for the table\n        types = {k: self.type_mapping(k, dict_list[0][k]) for k in dict_list[0].keys()}\n        # Then try to create the table\n        if not self.create_table(table_name, types):\n            print(f\"Error creating table {table_name}.\")\n            return False\n\n    # Create a dataframe with the data to write and send them to ADX\n    df = pd.DataFrame(dict_list)\n    ingestion_result = self.ingest_dataframe(table_name, df, drop_by_tag)\n    return ingestion_result\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.table_exists","title":"<code>table_exists(table_name)</code>","text":"<p>Check if a table exists on the database :param table_name: The table to look for :return: does the table exits ?</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>def table_exists(self, table_name: str) -&gt; bool:\n    \"\"\"\n    Check if a table exists on the database\n    :param table_name: The table to look for\n    :return: does the table exits ?\n    \"\"\"\n    get_tables_query = f\".show database ['{self.database}'] schema| distinct TableName\"\n    tables = self.run_query(get_tables_query)\n    for r in tables.primary_results[0]:\n        if table_name == r[0]:\n            return True\n    return False\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.ADXQueriesWrapper.type_mapping","title":"<code>type_mapping(key, key_example_value)</code>  <code>staticmethod</code>","text":"<p>This method is used to replace the type name from python to the one used in ADX :param key: the name of the key :param key_example_value: a possible value of the key :return: the name of the type used in ADX</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>@staticmethod\ndef type_mapping(key: str, key_example_value) -&gt; str:\n    \"\"\"\n    This method is used to replace the type name from python to the one used in ADX\n    :param key: the name of the key\n    :param key_example_value: a possible value of the key\n    :return: the name of the type used in ADX\n    \"\"\"\n\n    if key == \"SimulationRun\":\n        return \"guid\"\n\n    try:\n        # Use dateutil parser to test if the value could be a date, in case of error it is not\n        dateutil.parser.parse(key_example_value, fuzzy=False)\n        return \"datetime\"\n    except (ValueError, TypeError):\n        pass\n\n    if type(key_example_value) is float:\n        return \"real\"\n\n    if type(key_example_value) is int:\n        return \"long\"\n\n    # Default case to string\n    return \"string\"\n</code></pre>"},{"location":"references/Accelerators/adx_wrapper/#CosmoTech_Acceleration_Library.Accelerators.adx_wrapper.IngestionStatus","title":"<code>IngestionStatus</code>","text":"<p>               Bases: <code>Enum</code></p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/adx_wrapper.py</code> <pre><code>class IngestionStatus(Enum):\n    QUEUED = 'QUEUED'\n    SUCCESS = 'SUCCESS'\n    FAILURE = 'FAILURE'\n    UNKNOWN = 'UNKNOWN'\n    TIMEOUT = 'TIMED OUT'\n</code></pre>"},{"location":"references/Accelerators/scenario_download/azure_function_main/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main","text":""},{"location":"references/Accelerators/scenario_download/azure_function_main/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.azure_function_main","title":"<code>azure_function_main</code>","text":""},{"location":"references/Accelerators/scenario_download/scenario_downloader/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader","text":""},{"location":"references/Accelerators/scenario_download/scenario_downloader/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader","title":"<code>scenario_downloader</code>","text":""},{"location":"references/Accelerators/scenario_download/scenario_downloader/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader.get_content_from_twin_graph_data","title":"<code>get_content_from_twin_graph_data(nodes, relationships, restore_names=False)</code>","text":"<p>When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)</p> <p>Example with a sample of cypher response: [{   n: {     id: \"50\"  &lt;-- this id is used if restore_names is False     label: \"Customer\"     properties: {       Satisfaction: 0       SurroundingSatisfaction: 0       Thirsty: false       id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True     }     type: \"NODE\"   } }]</p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader.py</code> <pre><code>def get_content_from_twin_graph_data(nodes, relationships, restore_names=False):\n    '''\n    When restore_names is True, the \"id\" value inside the \"properties\" field in the cypher query response is used\n    instead of the numerical id found in the \"id\" field. When restore_names is set to False, this function\n    keeps the previous behavior implemented when adding support for twingraph in v2 (default: False)\n\n    Example with a sample of cypher response:\n    [{\n      n: {\n        id: \"50\"  &lt;-- this id is used if restore_names is False\n        label: \"Customer\"\n        properties: {\n          Satisfaction: 0\n          SurroundingSatisfaction: 0\n          Thirsty: false\n          id: \"Lars_Coret\"  &lt;-- this id is used if restore_names is True\n        }\n        type: \"NODE\"\n      }\n    }]\n    '''\n    content = dict()\n    # build keys\n    for item in relationships:\n        content[item['src']['label']] = list()\n        content[item['dest']['label']] = list()\n        content[item['rel']['label']] = list()\n\n    for item in nodes:\n        label = item['n']['label']\n        props = item['n']['properties']\n        if not restore_names:\n            props.update({'id': item['n']['id']})\n        content.setdefault(label, list())\n        content[label].append(props)\n\n    for item in relationships:\n        src = item['src']\n        dest = item['dest']\n        rel = item['rel']\n        props = item['rel']['properties']\n        content[rel['label']].append({\n            'id': rel['id'],\n            'source': src['properties']['id'] if restore_names else src['id'],\n            'target': dest['properties']['id'] if restore_names else dest['id'],\n            **props\n        })\n    return content\n</code></pre>"},{"location":"references/Accelerators/scenario_download/scenario_downloader/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader.ScenarioDownloader","title":"<code>ScenarioDownloader</code>","text":"Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader.py</code> <pre><code>class ScenarioDownloader:\n    def __init__(\n        self,\n        workspace_id: str,\n        organization_id: str,\n        access_token: str = None,\n        read_files=True,\n        parallel=True\n    ):\n        if get_api_client()[1] == \"Azure Entra Connection\":\n            self.credentials = DefaultAzureCredential()\n        else:\n            self.credentials = None\n\n\n        self.workspace_id = workspace_id\n        self.organization_id = organization_id\n        self.dataset_file_temp_path = dict()\n        self.read_files = read_files\n        self.parallel = parallel\n\n    def get_scenario_data(self, scenario_id: str):\n        with get_api_client()[0] as api_client:\n            api_instance = ScenarioApi(api_client)\n            scenario_data = api_instance.find_scenario_by_id(organization_id=self.organization_id,\n                                                             workspace_id=self.workspace_id,\n                                                             scenario_id=scenario_id)\n        return scenario_data\n\n    def download_dataset(self, dataset_id: str) -&gt; (str, str, Union[str, None]):\n        with get_api_client()[0] as api_client:\n            api_instance = DatasetApi(api_client)\n\n            dataset = api_instance.find_dataset_by_id(\n                organization_id=self.organization_id,\n                dataset_id=dataset_id)\n            parameters = dataset.connector.parameters_values\n\n            is_adt = 'AZURE_DIGITAL_TWINS_URL' in parameters\n            is_storage = 'AZURE_STORAGE_CONTAINER_BLOB_PREFIX' in parameters\n            is_legacy_twin_cache = 'TWIN_CACHE_NAME' in parameters and dataset.twingraph_id is None  # Legacy twingraph dataset with specific connector\n            is_in_workspace_file = 'workspaceFile' in dataset.tags\n\n            if is_adt:\n                return {\n                    \"type\": 'adt',\n                    \"content\": self._download_adt_content(\n                        adt_adress=parameters['AZURE_DIGITAL_TWINS_URL']),\n                    \"name\": dataset.name}\n            elif is_legacy_twin_cache:\n                twin_cache_name = parameters['TWIN_CACHE_NAME']\n                return {\n                    \"type\": \"twincache\",\n                    \"content\": self._read_legacy_twingraph_content(twin_cache_name),\n                    \"name\": dataset.name\n                }\n            elif is_storage:\n                _file_name = parameters['AZURE_STORAGE_CONTAINER_BLOB_PREFIX'].replace(\n                    '%WORKSPACE_FILE%/', '')\n                _content = self._download_file(_file_name)\n                self.dataset_file_temp_path[dataset_id] = self.dataset_file_temp_path[_file_name]\n                return {\n                    \"type\": _file_name.split('.')[-1],\n                    \"content\": _content,\n                    \"name\": dataset.name\n                }\n            elif is_in_workspace_file:\n                _file_name = dataset.source.location\n                _content = self._download_file(_file_name)\n                self.dataset_file_temp_path[dataset_id] = self.dataset_file_temp_path[_file_name]\n                return {\n                    \"type\": _file_name.split('.')[-1],\n                    \"content\": _content,\n                    \"name\": dataset.name\n                }\n\n            else:\n                return {\n                    \"type\": \"twincache\",\n                    \"content\": self._read_twingraph_content(dataset_id),\n                    \"name\": dataset.name\n                }\n\n    def _read_twingraph_content(self, dataset_id: str) -&gt; dict:\n        with get_api_client()[0] as api_client:\n            dataset_api = DatasetApi(api_client)\n            nodes_query = DatasetTwinGraphQuery(query=\"MATCH(n) RETURN n\")\n            edges_query = DatasetTwinGraphQuery(query=\"MATCH(n)-[r]-&gt;(m) RETURN n as src, r as rel, m as dest\")\n\n            nodes = dataset_api.twingraph_query(\n                organization_id=self.organization_id,\n                dataset_id=dataset_id,\n                dataset_twin_graph_query=nodes_query\n            )\n            edges = dataset_api.twingraph_query(\n                organization_id=self.organization_id,\n                dataset_id=dataset_id,\n                dataset_twin_graph_query=edges_query\n            )\n            return get_content_from_twin_graph_data(nodes, edges, True)\n\n    def _read_legacy_twingraph_content(self, cache_name: str) -&gt; dict:\n        with get_api_client()[0] as api_client:\n            api_instance = TwingraphApi(api_client)\n            _query_nodes = TwinGraphQuery(\n                query=\"MATCH(n) RETURN n\"\n            )\n\n            nodes = api_instance.query(\n                organization_id=self.organization_id,\n                graph_id=cache_name,\n                twin_graph_query=_query_nodes\n            )\n            _query_rel = TwinGraphQuery(\n                query=\"MATCH(n)-[r]-&gt;(m) RETURN n as src, r as rel, m as dest\"\n            )\n            rel = api_instance.query(\n                organization_id=self.organization_id,\n                graph_id=cache_name,\n                twin_graph_query=_query_rel\n            )\n            return get_content_from_twin_graph_data(nodes, rel, False)\n\n    def _download_file(self, file_name: str):\n        tmp_dataset_dir = tempfile.mkdtemp()\n        self.dataset_file_temp_path[file_name] = tmp_dataset_dir\n        with get_api_client()[0] as api_client:\n            api_ws = WorkspaceApi(api_client)\n\n            all_api_files = api_ws.find_all_workspace_files(\n                self.organization_id, self.workspace_id)\n\n            existing_files = list(\n                _f.file_name for _f in all_api_files\n                if _f.file_name.startswith(file_name))\n\n            content = dict()\n\n            for _file_name in existing_files:\n                dl_file = api_ws.download_workspace_file(organization_id=self.organization_id,\n                                                         workspace_id=self.workspace_id,\n                                                         file_name=_file_name)\n\n                target_file = os.path.join(\n                    tmp_dataset_dir, _file_name.split('/')[-1])\n                with open(target_file, \"wb\") as tmp_file:\n                    tmp_file.write(dl_file)\n                if not self.read_files:\n                    continue\n                if \".xls\" in _file_name:\n                    wb = load_workbook(target_file, data_only=True)\n                    for sheet_name in wb.sheetnames:\n                        sheet = wb[sheet_name]\n                        content[sheet_name] = list()\n                        headers = next(sheet.iter_rows(\n                            max_row=1, values_only=True))\n\n                        def item(_row: tuple) -&gt; dict:\n                            return {k: v for k, v in zip(headers, _row)}\n\n                        for r in sheet.iter_rows(min_row=2, values_only=True):\n                            row = item(r)\n                            new_row = dict()\n                            for key, value in row.items():\n                                try:\n                                    converted_value = json.load(\n                                        io.StringIO(value))\n                                except (json.decoder.JSONDecodeError, TypeError):\n                                    converted_value = value\n                                if converted_value is not None:\n                                    new_row[key] = converted_value\n                            if new_row:\n                                content[sheet_name].append(new_row)\n                elif \".csv\" in _file_name:\n                    with open(target_file, \"r\") as file:\n                        # Read every file in the input folder\n                        current_filename = os.path.basename(target_file)[:-len(\".csv\")]\n                        content[current_filename] = list()\n                        for csv_row in csv.DictReader(file):\n                            csv_row: dict\n                            new_row = dict()\n                            for key, value in csv_row.items():\n                                try:\n                                    # Try to convert any json row to dict object\n                                    converted_value = json.load(\n                                        io.StringIO(value))\n                                except json.decoder.JSONDecodeError:\n                                    converted_value = value\n                                if converted_value == '':\n                                    converted_value = None\n                                if converted_value is not None:\n                                    new_row[key] = converted_value\n                            content[current_filename].append(new_row)\n                elif \".json\" in _file_name:\n                    with open(target_file, \"r\") as _file:\n                        current_filename = os.path.basename(target_file)\n                        content[current_filename] = json.load(_file)\n                else:\n                    with open(target_file, \"r\") as _file:\n                        current_filename = os.path.basename(target_file)\n                        content[current_filename] = \"\\n\".join(\n                            line for line in _file)\n        return content\n\n    def _download_adt_content(self, adt_adress: str) -&gt; dict:\n        client = DigitalTwinsClient(adt_adress, self.credentials)\n        query_expression = 'SELECT * FROM digitaltwins'\n        query_result = client.query_twins(query_expression)\n        json_content = dict()\n        for twin in query_result:\n            entity_type = twin.get('$metadata').get(\n                '$model').split(':')[-1].split(';')[0]\n            t_content = {k: v for k, v in twin.items()}\n            t_content['id'] = t_content['$dtId']\n            for k in twin.keys():\n                if k[0] == '$':\n                    del t_content[k]\n            json_content.setdefault(entity_type, [])\n            json_content[entity_type].append(t_content)\n\n        relations_query = 'SELECT * FROM relationships'\n        query_result = client.query_twins(relations_query)\n        for relation in query_result:\n            tr = {\n                \"$relationshipId\": \"id\",\n                \"$sourceId\": \"source\",\n                \"$targetId\": \"target\"\n            }\n            r_content = {k: v for k, v in relation.items()}\n            for k, v in tr.items():\n                r_content[v] = r_content[k]\n            for k in relation.keys():\n                if k[0] == '$':\n                    del r_content[k]\n            json_content.setdefault(relation['$relationshipName'], [])\n            json_content[relation['$relationshipName']].append(r_content)\n\n        return json_content\n\n    def get_all_parameters(self, scenario_id) -&gt; dict:\n        scenario_data = self.get_scenario_data(scenario_id=scenario_id)\n        content = dict()\n        for parameter in scenario_data.parameters_values:\n            content[parameter.parameter_id] = parameter.value\n        return content\n\n    def get_all_datasets(self, scenario_id: str) -&gt; dict:\n        scenario_data = self.get_scenario_data(scenario_id=scenario_id)\n\n        datasets = scenario_data.dataset_list\n\n        dataset_ids = datasets[:]\n\n        for parameter in scenario_data.parameters_values:\n            if parameter.var_type == '%DATASETID%':\n                dataset_id = parameter.value\n                dataset_ids.append(dataset_id)\n\n        def download_dataset_process(_dataset_id, _return_dict, _error_dict):\n            try:\n                _c = self.download_dataset(_dataset_id)\n                if _dataset_id in self.dataset_file_temp_path:\n                    _return_dict[_dataset_id] = (_c, self.dataset_file_temp_path[_dataset_id], _dataset_id)\n                else:\n                    _return_dict[_dataset_id] = _c\n            except Exception as e:\n                _error_dict[_dataset_id] = f'{type(e).__name__}: {str(e)}'\n                raise e\n\n        if self.parallel:\n            manager = multiprocessing.Manager()\n            return_dict = manager.dict()\n            error_dict = manager.dict()\n            processes = [\n                (dataset_id, multiprocessing.Process(target=download_dataset_process,\n                                                     args=(dataset_id, return_dict, error_dict)))\n                for dataset_id in dataset_ids\n            ]\n            [p.start() for _, p in processes]\n            [p.join() for _, p in processes]\n\n            for dataset_id, p in processes:\n                # We might hit the following bug: https://bugs.python.org/issue43944\n                # As a workaround, only treat non-null exit code as a real issue if we also have stored an error\n                # message\n                if p.exitcode != 0 and dataset_id in error_dict:\n                    raise ChildProcessError(\n                        f\"Failed to download dataset '{dataset_id}': {error_dict[dataset_id]}\")\n        else:\n            return_dict = {}\n            error_dict = {}\n            for dataset_id in dataset_ids:\n                try:\n                    download_dataset_process(dataset_id, return_dict, error_dict)\n                except Exception as e:\n                    raise ChildProcessError(\n                        f\"Failed to download dataset '{dataset_id}': {error_dict.get(dataset_id, '')}\")\n        content = dict()\n        for k, v in return_dict.items():\n            if isinstance(v, tuple):\n                content[k] = v[0]\n                self.dataset_file_temp_path[v[2]] = v[1]\n            else:\n                content[k] = v\n        return content\n\n    def dataset_to_file(self, dataset_id, dataset_info):\n        type = dataset_info['type']\n        content = dataset_info['content']\n        name = dataset_info['name']\n        if type in [\"adt\", \"twincache\"]:\n            return self.adt_dataset(content, name, type)\n        return self.dataset_file_temp_path[dataset_id]\n\n    @staticmethod\n    def sheet_to_header(sheet_content):\n        fieldnames = []\n        has_src = False\n        has_id = False\n        for r in sheet_content:\n            for k in r.keys():\n                if k not in fieldnames:\n                    if k in ['source', 'target']:\n                        has_src = True\n                    elif k == \"id\":\n                        has_id = True\n                    else:\n                        fieldnames.append(k)\n        if has_src:\n            fieldnames = ['source', 'target'] + fieldnames\n        if has_id:\n            fieldnames = ['id', ] + fieldnames\n        return fieldnames\n\n    def adt_dataset(self, content, _name, _type):\n        tmp_dataset_dir = tempfile.mkdtemp()\n        for _filename, _filecontent in content.items():\n            with open(tmp_dataset_dir + \"/\" + _filename + \".csv\", \"w\") as _file:\n                fieldnames = self.sheet_to_header(_filecontent)\n\n                _w = csv.DictWriter(_file, fieldnames=fieldnames, dialect=\"unix\", quoting=csv.QUOTE_MINIMAL)\n                _w.writeheader()\n                # _w.writerows(_filecontent)\n                for r in _filecontent:\n                    _w.writerow(\n                        {k: str(v).replace(\"'\", \"\\\"\").replace(\"True\", \"true\").replace(\"False\", \"false\") for k, v in\n                         r.items()})\n        return tmp_dataset_dir\n</code></pre>"},{"location":"references/Accelerators/scenario_download/scenario_downloader_test/","title":"CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader_test","text":""},{"location":"references/Accelerators/scenario_download/scenario_downloader_test/#CosmoTech_Acceleration_Library.Accelerators.scenario_download.scenario_downloader_test.TestModelUtil","title":"<code>TestModelUtil</code>","text":"<p>               Bases: <code>TestCase</code></p> Source code in <code>CosmoTech_Acceleration_Library/Accelerators/scenario_download/scenario_downloader_test.py</code> <pre><code>class TestModelUtil(unittest.TestCase):\n    maxDiff = None\n\n    nodes = [{\n        \"n\": {\n            \"id\": \"43\",\n            \"label\": \"Customer\",\n            \"properties\": {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Kyra_van_den_Hoek\"\n            },\n            \"type\": \"NODE\",\n        },\n    }, {\n        \"n\": {\n            \"id\": \"44\",\n            \"label\": \"Customer\",\n            \"properties\": {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Tyler_Post\"\n            },\n            \"type\": \"NODE\",\n        },\n    }, {\n        \"n\": {\n            \"id\": \"50\",\n            \"label\": \"Customer\",\n            \"properties\": {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Lars_Coret\"\n            },\n            \"type\": \"NODE\",\n        }\n    }]\n\n    edges = [\n        {\n            \"dest\": {\n                \"id\": \"43\",\n                \"label\": \"Customer\",\n                \"properties\": {\n                    \"Satisfaction\": 0,\n                    \"SurroundingSatisfaction\": 0,\n                    \"Thirsty\": False,\n                    \"id\": \"Kyra_van_den_Hoek\",\n                },\n                \"type\": \"NODE\",\n            },\n            \"rel\": {\n                \"id\": \"175\",\n                \"label\": \"arc_Satisfaction\",\n                \"properties\": {\n                    \"name\": \"arc_from_Lars_Coret_to_Kyra_van_den_Hoek\",\n                },\n                \"type\": \"RELATION\",\n            },\n            \"src\": {\n                \"id\": \"50\",\n                \"label\": \"Customer\",\n                \"properties\": {\n                    \"Satisfaction\": 0,\n                    \"SurroundingSatisfaction\": 0,\n                    \"Thirsty\": False,\n                    \"id\": \"Lars_Coret\",\n                },\n                \"type\": \"NODE\",\n            },\n        },\n        {\n            \"dest\": {\n                \"id\": \"44\",\n                \"label\": \"Customer\",\n                \"properties\": {\n                    \"Satisfaction\": 0,\n                    \"SurroundingSatisfaction\": 0,\n                    \"Thirsty\": False,\n                    \"id\": \"Tyler_Post\",\n                },\n                \"type\": \"NODE\",\n            },\n            \"rel\": {\n                \"id\": \"179\",\n                \"label\": \"arc_Satisfaction\",\n                \"properties\": {\n                    \"name\": \"arc_from_Lars_Coret_to_Tyler_Post\",\n                },\n                \"type\": \"RELATION\",\n            },\n            \"src\": {\n                \"id\": \"50\",\n                \"label\": \"Customer\",\n                \"properties\": {\n                    \"Satisfaction\": 0,\n                    \"SurroundingSatisfaction\": 0,\n                    \"Thirsty\": False,\n                    \"id\": \"Lars_Coret\",\n                },\n                \"type\": \"NODE\",\n            },\n        },\n    ]\n\n    expected_v2_twingraph_content = {\n        \"Customer\": [\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"43\",\n            },\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"44\",\n            },\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"50\",\n            },\n        ],\n        \"arc_Satisfaction\": [{\n            \"id\": \"175\",\n            \"name\": \"arc_from_Lars_Coret_to_Kyra_van_den_Hoek\",\n            \"source\": \"50\",\n            \"target\": \"43\"\n        }, {\n            \"id\": \"179\",\n            \"name\": \"arc_from_Lars_Coret_to_Tyler_Post\",\n            \"source\": \"50\",\n            \"target\": \"44\"\n        }]\n    }\n    expected_v3_twingraph_content = {\n        \"Customer\": [\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Kyra_van_den_Hoek\",\n            },\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Tyler_Post\",\n            },\n            {\n                \"Satisfaction\": 0,\n                \"SurroundingSatisfaction\": 0,\n                \"Thirsty\": False,\n                \"id\": \"Lars_Coret\",\n            },\n        ],\n        \"arc_Satisfaction\": [{\n            \"id\": \"175\",\n            \"name\": \"arc_from_Lars_Coret_to_Kyra_van_den_Hoek\",\n            \"source\": \"Lars_Coret\",\n            \"target\": \"Kyra_van_den_Hoek\"\n        }, {\n            \"id\": \"179\",\n            \"name\": \"arc_from_Lars_Coret_to_Tyler_Post\",\n            \"source\": \"Lars_Coret\",\n            \"target\": \"Tyler_Post\"\n        }]\n    }\n\n    def test_v2_twingraph_get_content(self):\n        self.assertEqual(\n            self.expected_v2_twingraph_content,\n            get_content_from_twin_graph_data(copy.deepcopy(self.nodes), copy.deepcopy(self.edges)))\n\n    def test_v3_twingraph_get_content(self):\n        self.assertEqual(\n            self.expected_v3_twingraph_content,\n            get_content_from_twin_graph_data(copy.deepcopy(self.nodes), copy.deepcopy(self.edges), True))\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler","text":""},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler","title":"<code>GraphHandler</code>","text":"<p>               Bases: <code>RedisHandler</code></p> <p>Class that handle Graph Redis information</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>class GraphHandler(RedisHandler):\n    \"\"\"\n    Class that handle Graph Redis information\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None):\n        super().__init__(host=host, port=port, name=name, password=password)\n        logger.debug(\"GraphHandler init\")\n        self.name = name\n        self.graph = self.r.graph(name)\n\n    def do_if_graph_exist(function):\n        \"\"\"\n        Function decorator that run the function annotated if graph exists\n        :param function: the function annotated\n        \"\"\"\n\n        @functools.wraps(function)\n        def wrapper(self, *args, **kwargs):\n            if self.r.exists(self.name) != 0:\n                function(self, *args, **kwargs)\n            else:\n                raise Exception(f\"{self.name} does not exist!\")\n\n        return wrapper\n\n    def handle_graph_replace(func):\n        \"\"\"\n        Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)\n        \"\"\"\n\n        def handle(self, *args, **kwargs):\n            self.graph = self.r.graph(f'{self.name}_tmp')\n            logger.debug(f'Using graph {self.name}_tmp for copy')\n\n            # do function on new graph\n            func(self, *args, **kwargs)\n\n            # action complete on graph_tmp with no error replacing graph by graph_tmp\n            self.r.eval(\n                \"\"\"local o = redis.call('DUMP', KEYS[1]);\\\n                   redis.call('RENAME', KEYS[1], KEYS[2]);\\\n                   redis.call('RESTORE', KEYS[1], 0, o)\"\"\", 2, f'{self.name}_tmp', self.name)\n            # remove tmp graph\n            self.r.delete(f'{self.name}_tmp')\n            # set back the graph\n            self.graph = self.r.graph(self.name)\n\n        return handle\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler.do_if_graph_exist","title":"<code>do_if_graph_exist(function)</code>","text":"<p>Function decorator that run the function annotated if graph exists :param function: the function annotated</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>def do_if_graph_exist(function):\n    \"\"\"\n    Function decorator that run the function annotated if graph exists\n    :param function: the function annotated\n    \"\"\"\n\n    @functools.wraps(function)\n    def wrapper(self, *args, **kwargs):\n        if self.r.exists(self.name) != 0:\n            function(self, *args, **kwargs)\n        else:\n            raise Exception(f\"{self.name} does not exist!\")\n\n    return wrapper\n</code></pre>"},{"location":"references/Modelops/core/common/graph_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.graph_handler.GraphHandler.handle_graph_replace","title":"<code>handle_graph_replace(func)</code>","text":"<p>Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/graph_handler.py</code> <pre><code>def handle_graph_replace(func):\n    \"\"\"\n    Decorator to do stuff then handle graph rotation (delete the oldest graph if the amount of graph is greater than graph rotation)\n    \"\"\"\n\n    def handle(self, *args, **kwargs):\n        self.graph = self.r.graph(f'{self.name}_tmp')\n        logger.debug(f'Using graph {self.name}_tmp for copy')\n\n        # do function on new graph\n        func(self, *args, **kwargs)\n\n        # action complete on graph_tmp with no error replacing graph by graph_tmp\n        self.r.eval(\n            \"\"\"local o = redis.call('DUMP', KEYS[1]);\\\n               redis.call('RENAME', KEYS[1], KEYS[2]);\\\n               redis.call('RESTORE', KEYS[1], 0, o)\"\"\", 2, f'{self.name}_tmp', self.name)\n        # remove tmp graph\n        self.r.delete(f'{self.name}_tmp')\n        # set back the graph\n        self.graph = self.r.graph(self.name)\n\n    return handle\n</code></pre>"},{"location":"references/Modelops/core/common/redis_handler/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler","text":""},{"location":"references/Modelops/core/common/redis_handler/#CosmoTech_Acceleration_Library.Modelops.core.common.redis_handler.RedisHandler","title":"<code>RedisHandler</code>","text":"<p>Class that handle Redis informations</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/redis_handler.py</code> <pre><code>class RedisHandler:\n    \"\"\"\n    Class that handle Redis informations\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None):\n        logger.debug(\"RedisHandler init\")\n        self.host = host\n        self.port = port\n        self.name = name\n        self.password = password\n        self.r = redis.Redis(host=host, port=port, password=password, decode_responses=True)\n</code></pre>"},{"location":"references/Modelops/core/common/writer/CsvWriter/","title":"CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter","text":""},{"location":"references/Modelops/core/common/writer/CsvWriter/#CosmoTech_Acceleration_Library.Modelops.core.common.writer.CsvWriter.CsvWriter","title":"<code>CsvWriter</code>","text":"<p>Csv Writer class</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/common/writer/CsvWriter.py</code> <pre><code>class CsvWriter:\n    \"\"\"\n    Csv Writer class\n    \"\"\"\n\n    @staticmethod\n    def _to_csv_format(val: any) -&gt; str:\n        if isinstance(val, bool):\n            return str(val).lower()\n        if isinstance(val, dict):\n            return json.dumps(val)\n        if str(val) == 'True' or str(val) == 'False':\n            return str(val).lower()\n        if str(val).startswith('{') and str(val).endswith('}'):\n            try:\n                return json.dumps(json.loads(val))\n            except json.decoder.JSONDecodeError:\n                return json.dumps(ast.literal_eval(str(val)))\n        return str(val)\n\n    @staticmethod\n    def _to_cosmo_key(val: any) -&gt; str:\n        if str(val) == ModelUtil.dt_id_key:\n            return ModelUtil.id_key\n        return val\n\n    @staticmethod\n    def write_twin_data(export_dir: str,\n                        file_name: str,\n                        query_result: QueryResult,\n                        delimiter: str = ',',\n                        quote_char: str = '\\\"') -&gt; None:\n        headers = set()\n        rows = []\n        for raw_data in query_result.result_set:\n            row = {}\n            # read all graph link properties\n            for i in range(len(raw_data)):  # TODO for the moment its only a len 1 list with the node\n                row.update({\n                    CsvWriter._to_cosmo_key(k): CsvWriter._to_csv_format(v)\n                    for k, v in raw_data[i].properties.items()\n                })\n            headers.update(row.keys())\n            rows.append(row)\n\n        output_file_name = f'{export_dir}/{file_name}.csv'\n        logger.debug(f\"Writing CSV file {output_file_name}\")\n        with open(output_file_name, 'w') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            csv_writer.writeheader()\n            csv_writer.writerows(rows)\n        logger.debug(f\"... CSV file {output_file_name} has been written\")\n\n    @staticmethod\n    def write_relationship_data(export_dir: str,\n                                file_name: str,\n                                query_result: QueryResult,\n                                headers: list = [],\n                                delimiter: str = ',',\n                                quote_char: str = '\\\"') -&gt; None:\n        headers = {'source', 'target'}\n        rows = []\n        for raw_data in query_result.result_set:\n            row = {'source': raw_data[0], 'target': raw_data[1]}\n            row.update({k: CsvWriter._to_csv_format(v) for k, v in raw_data[2].properties.items()})\n            headers.update(row.keys())\n            rows.append(row)\n\n        output_file_name = f'{export_dir}/{file_name}.csv'\n        logger.debug(f\"Writing CSV file {output_file_name}\")\n        with open(output_file_name, 'w') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            csv_writer.writeheader()\n            csv_writer.writerows(rows)\n        logger.debug(f\"... CSV file {output_file_name} has been written\")\n\n    @staticmethod\n    def write_data(export_dir: str,\n                   file_name: str,\n                   input_rows: dict,\n                   delimiter: str = ',',\n                   quote_char: str = '\\\"') -&gt; None:\n        output_file_name = export_dir + file_name + '.csv'\n        write_header = False\n        if not os.path.exists(output_file_name):\n            write_header = True\n\n        headers = set()\n        output_rows = []\n        for row in input_rows:\n            output_rows.append({CsvWriter._to_cosmo_key(k): CsvWriter._to_csv_format(v) for k, v in row.items()})\n            headers.update(row.keys())\n\n        logger.info(f\"Writing file {output_file_name} ...\")\n        with open(output_file_name, 'a') as csvfile:\n            csv_writer = csv.DictWriter(csvfile,\n                                        fieldnames=headers,\n                                        delimiter=delimiter,\n                                        quotechar=quote_char,\n                                        quoting=csv.QUOTE_MINIMAL)\n            if write_header:\n                csv_writer.writeheader()\n            csv_writer.writerows(output_rows)\n        logger.debug(f\"... file {output_file_name} has been written\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter","text":""},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter","title":"<code>ModelExporter</code>","text":"<p>               Bases: <code>GraphHandler</code></p> <p>Model Exporter for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>class ModelExporter(GraphHandler):\n    \"\"\"\n    Model Exporter for cached data\n    \"\"\"\n\n    def __init__(self, host: str, port: int, name: str, password: str = None, export_dir: str = \"/\"):\n        super().__init__(host=host, port=port, name=name, password=password)\n        Path(export_dir).mkdir(parents=True, exist_ok=True)\n        self.export_dir = export_dir\n\n        self.mr = ModelReader(host=host, port=port, name=name, password=password)\n        self.labels = [label[0] for label in self.graph.labels()]\n        self.relationships = [relation[0] for relation in self.graph.relationship_types()]\n        self.already_exported_nodes = {}\n        self.already_exported_edges = []\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_twins(self):\n        \"\"\"\n        Export all twins\n        :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n        \"\"\"\n        logger.debug(\"Start exporting twins...\")\n        logger.debug(\"Get twin types...\")\n        get_types_start = time.time()\n        twin_names = self.mr.get_twin_types()\n        get_types_end = time.time() - get_types_start\n        logger.debug(f\"Get twin types took {get_types_end} s\")\n\n        for twin_name in twin_names:\n            logger.debug(f\"Get twin info for type {twin_name} ...\")\n            get_twin_info_start = time.time()\n            twin_results = self.mr.get_twins_by_type(twin_name)\n            get_twin_info_end = time.time() - get_twin_info_start\n            logger.debug(f\"Get twin info for type {twin_name} took {get_twin_info_end} s\")\n\n            logger.debug(f\"Export twin info for type {twin_name} ...\")\n            export_twin_info_start = time.time()\n            CsvWriter.write_twin_data(self.export_dir, twin_name, twin_results)\n            export_twin_info_end = time.time() - export_twin_info_start\n            logger.debug(f\"Export twin info for type {twin_name} took {export_twin_info_end} s\")\n\n            logger.debug(f\"Twins exported :{twin_name}\")\n        logger.debug(\"... End exporting twins\")\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_relationships(self):\n        \"\"\"\n        Export all relationships\n        :return: Csv files containing all relationship instances exported into {export_dir}\n        folder named by relationship type\n        \"\"\"\n        logger.debug(\"Start exporting relationships...\")\n        logger.debug(\"Get relationship types...\")\n        get_relationship_types_start = time.time()\n        relationship_names = self.mr.get_relationship_types()\n        get_relationship_types_end = time.time() - get_relationship_types_start\n        logger.debug(f\"Get relationship types took {get_relationship_types_end} s\")\n\n        for relationship_name in relationship_names:\n            logger.debug(f\"Get relationship info for type {relationship_name} ...\")\n            get_relationship_info_start = time.time()\n            relationship_result = self.mr.get_relationships_by_type(relationship_name)\n            get_relationship_info_end = time.time() - get_relationship_info_start\n            logger.debug(f\"Get relationship info for type {relationship_name} took {get_relationship_info_end} s\")\n\n            logger.debug(f\"Export relationship info for type {relationship_name} ...\")\n            export_relationship_info_start = time.time()\n            CsvWriter.write_relationship_data(self.export_dir, relationship_name, relationship_result)\n            export_relationship_info_end = time.time() - export_relationship_info_start\n            logger.debug(f\"Export relationship info for type {relationship_name} took {export_relationship_info_end} s\")\n\n            logger.debug(f\"Relationships exported :{relationship_name}\")\n        logger.debug(\"... End exporting relationships\")\n\n    @GraphHandler.do_if_graph_exist\n    def export_all_data(self):\n        \"\"\"\n        Export all data\n        :return: a bunch of csv files corresponding to graph data\n        \"\"\"\n        self.export_all_twins()\n        self.export_all_relationships()\n\n    @GraphHandler.do_if_graph_exist\n    def export_from_queries(self, queries: list):\n        \"\"\"\n        Export data from queries\n        Queries must be Cypher queries and return nodes and relationships objects to be exported\n        Multiple instances of the same node or relationship will not be exported\n\n        :param queries: list of queries to execute (Cypher queries)\n        :return: None writes csv files corresponding to the results of the queries in the parameters\n        \"\"\"\n        logger.info(\"Start exporting data from queries...\")\n        # foreach query, execute it and get nodes and relationships\n        for query in queries:\n            logger.info(f\"Export data from query {query} ...\")\n            export_data_from_query_start = time.time()\n            query_result = self.mr.query(query, read_only=True)\n\n            # foreach query result, get nodes and relationships\n            nodes_by_label = {key: [] for key in self.labels}\n            edges_by_relation = {key: [] for key in self.relationships}\n            for result in query_result.result_set:\n                for data in result:\n                    if type(data) == redis.commands.graph.node.Node:\n                        if data.id not in self.already_exported_nodes:\n                            self.already_exported_nodes.update({data.id: data.properties.get('id')})\n                            nodes_by_label[data.label].append(data)\n                    elif type(data) == redis.commands.graph.edge.Edge:\n                        if data.id not in self.already_exported_edges:\n                            self.already_exported_edges.append(data.id)\n                            edges_by_relation[data.relation].append(data)\n\n            # write node data into csv file\n            for label, nodes in nodes_by_label.items():\n                if nodes:\n                    nodes_rows = [node.properties for node in nodes]\n                    CsvWriter.write_data(self.export_dir, label, nodes_rows)\n\n            # write edge data into csv file\n            for relation, edges in edges_by_relation.items():\n                if edges:\n                    # add source and target to edge properties\n                    edges_rows = []\n                    for edge in edges:\n                        logger.debug(f\"Get source and target for edge {edge.id} ...\")\n                        edge.properties['source'] = self.get_node_id_from_sys_id(edge.src_node)\n                        edge.properties['target'] = self.get_node_id_from_sys_id(edge.dest_node)\n                        edges_rows.append(edge.properties)\n                    CsvWriter.write_data(self.export_dir, relation, edges_rows)\n\n            export_data_from_query_end = time.time() - export_data_from_query_start\n            logger.debug(f\"Export data from query took {export_data_from_query_end} s\")\n\n            logger.debug(\"Data from query exported\")\n        logger.info(\"... End exporting data from queries\")\n\n    @lru_cache\n    def get_node_id_from_sys_id(self, sys_id: int) -&gt; int:\n        \"\"\"\n        Get node id from system id (RedisGraph id)\n        :param sys_id: system id\n        :return: node id\n        \"\"\"\n        if sys_id in self.already_exported_nodes:\n            return self.already_exported_nodes[sys_id]\n        node_query = \"MATCH (n) WHERE ID(n) = $id RETURN n.id\"\n        return self.mr.query(node_query, params={'id': sys_id}).result_set[0][0]\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_data","title":"<code>export_all_data()</code>","text":"<p>Export all data :return: a bunch of csv files corresponding to graph data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_data(self):\n    \"\"\"\n    Export all data\n    :return: a bunch of csv files corresponding to graph data\n    \"\"\"\n    self.export_all_twins()\n    self.export_all_relationships()\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_relationships","title":"<code>export_all_relationships()</code>","text":"<p>Export all relationships :return: Csv files containing all relationship instances exported into {export_dir} folder named by relationship type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_relationships(self):\n    \"\"\"\n    Export all relationships\n    :return: Csv files containing all relationship instances exported into {export_dir}\n    folder named by relationship type\n    \"\"\"\n    logger.debug(\"Start exporting relationships...\")\n    logger.debug(\"Get relationship types...\")\n    get_relationship_types_start = time.time()\n    relationship_names = self.mr.get_relationship_types()\n    get_relationship_types_end = time.time() - get_relationship_types_start\n    logger.debug(f\"Get relationship types took {get_relationship_types_end} s\")\n\n    for relationship_name in relationship_names:\n        logger.debug(f\"Get relationship info for type {relationship_name} ...\")\n        get_relationship_info_start = time.time()\n        relationship_result = self.mr.get_relationships_by_type(relationship_name)\n        get_relationship_info_end = time.time() - get_relationship_info_start\n        logger.debug(f\"Get relationship info for type {relationship_name} took {get_relationship_info_end} s\")\n\n        logger.debug(f\"Export relationship info for type {relationship_name} ...\")\n        export_relationship_info_start = time.time()\n        CsvWriter.write_relationship_data(self.export_dir, relationship_name, relationship_result)\n        export_relationship_info_end = time.time() - export_relationship_info_start\n        logger.debug(f\"Export relationship info for type {relationship_name} took {export_relationship_info_end} s\")\n\n        logger.debug(f\"Relationships exported :{relationship_name}\")\n    logger.debug(\"... End exporting relationships\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_all_twins","title":"<code>export_all_twins()</code>","text":"<p>Export all twins :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_all_twins(self):\n    \"\"\"\n    Export all twins\n    :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n    \"\"\"\n    logger.debug(\"Start exporting twins...\")\n    logger.debug(\"Get twin types...\")\n    get_types_start = time.time()\n    twin_names = self.mr.get_twin_types()\n    get_types_end = time.time() - get_types_start\n    logger.debug(f\"Get twin types took {get_types_end} s\")\n\n    for twin_name in twin_names:\n        logger.debug(f\"Get twin info for type {twin_name} ...\")\n        get_twin_info_start = time.time()\n        twin_results = self.mr.get_twins_by_type(twin_name)\n        get_twin_info_end = time.time() - get_twin_info_start\n        logger.debug(f\"Get twin info for type {twin_name} took {get_twin_info_end} s\")\n\n        logger.debug(f\"Export twin info for type {twin_name} ...\")\n        export_twin_info_start = time.time()\n        CsvWriter.write_twin_data(self.export_dir, twin_name, twin_results)\n        export_twin_info_end = time.time() - export_twin_info_start\n        logger.debug(f\"Export twin info for type {twin_name} took {export_twin_info_end} s\")\n\n        logger.debug(f\"Twins exported :{twin_name}\")\n    logger.debug(\"... End exporting twins\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.export_from_queries","title":"<code>export_from_queries(queries)</code>","text":"<p>Export data from queries Queries must be Cypher queries and return nodes and relationships objects to be exported Multiple instances of the same node or relationship will not be exported</p> <p>:param queries: list of queries to execute (Cypher queries) :return: None writes csv files corresponding to the results of the queries in the parameters</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@GraphHandler.do_if_graph_exist\ndef export_from_queries(self, queries: list):\n    \"\"\"\n    Export data from queries\n    Queries must be Cypher queries and return nodes and relationships objects to be exported\n    Multiple instances of the same node or relationship will not be exported\n\n    :param queries: list of queries to execute (Cypher queries)\n    :return: None writes csv files corresponding to the results of the queries in the parameters\n    \"\"\"\n    logger.info(\"Start exporting data from queries...\")\n    # foreach query, execute it and get nodes and relationships\n    for query in queries:\n        logger.info(f\"Export data from query {query} ...\")\n        export_data_from_query_start = time.time()\n        query_result = self.mr.query(query, read_only=True)\n\n        # foreach query result, get nodes and relationships\n        nodes_by_label = {key: [] for key in self.labels}\n        edges_by_relation = {key: [] for key in self.relationships}\n        for result in query_result.result_set:\n            for data in result:\n                if type(data) == redis.commands.graph.node.Node:\n                    if data.id not in self.already_exported_nodes:\n                        self.already_exported_nodes.update({data.id: data.properties.get('id')})\n                        nodes_by_label[data.label].append(data)\n                elif type(data) == redis.commands.graph.edge.Edge:\n                    if data.id not in self.already_exported_edges:\n                        self.already_exported_edges.append(data.id)\n                        edges_by_relation[data.relation].append(data)\n\n        # write node data into csv file\n        for label, nodes in nodes_by_label.items():\n            if nodes:\n                nodes_rows = [node.properties for node in nodes]\n                CsvWriter.write_data(self.export_dir, label, nodes_rows)\n\n        # write edge data into csv file\n        for relation, edges in edges_by_relation.items():\n            if edges:\n                # add source and target to edge properties\n                edges_rows = []\n                for edge in edges:\n                    logger.debug(f\"Get source and target for edge {edge.id} ...\")\n                    edge.properties['source'] = self.get_node_id_from_sys_id(edge.src_node)\n                    edge.properties['target'] = self.get_node_id_from_sys_id(edge.dest_node)\n                    edges_rows.append(edge.properties)\n                CsvWriter.write_data(self.export_dir, relation, edges_rows)\n\n        export_data_from_query_end = time.time() - export_data_from_query_start\n        logger.debug(f\"Export data from query took {export_data_from_query_end} s\")\n\n        logger.debug(\"Data from query exported\")\n    logger.info(\"... End exporting data from queries\")\n</code></pre>"},{"location":"references/Modelops/core/io/model_exporter/#CosmoTech_Acceleration_Library.Modelops.core.io.model_exporter.ModelExporter.get_node_id_from_sys_id","title":"<code>get_node_id_from_sys_id(sys_id)</code>  <code>cached</code>","text":"<p>Get node id from system id (RedisGraph id) :param sys_id: system id :return: node id</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_exporter.py</code> <pre><code>@lru_cache\ndef get_node_id_from_sys_id(self, sys_id: int) -&gt; int:\n    \"\"\"\n    Get node id from system id (RedisGraph id)\n    :param sys_id: system id\n    :return: node id\n    \"\"\"\n    if sys_id in self.already_exported_nodes:\n        return self.already_exported_nodes[sys_id]\n    node_query = \"MATCH (n) WHERE ID(n) = $id RETURN n.id\"\n    return self.mr.query(node_query, params={'id': sys_id}).result_set[0][0]\n</code></pre>"},{"location":"references/Modelops/core/io/model_importer/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_importer","text":""},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter","title":"<code>ModelImporter</code>","text":"<p>               Bases: <code>GraphHandler</code></p> <p>Model Exporter for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py</code> <pre><code>class ModelImporter(GraphHandler):\n    \"\"\"\n    Model Exporter for cached data\n    \"\"\"\n\n    @GraphHandler.handle_graph_replace\n    def bulk_import(self, twin_file_paths: list = [], relationship_file_paths: list = [], enforce_schema: bool = False):\n        \"\"\"\n        Import all csv data\n        :param twin_file_paths: the file paths of all twin csv files\n        :param relationship_file_paths: the file paths of all relationship csv files\n        :param enforce_schema: True if the schema is defined within headers (default False)\n        `Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;`_\n        :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n        \"\"\"\n        command_parameters = ['--host', self.host, '--port', self.port]\n\n        if enforce_schema:\n            command_parameters.append('--enforce-schema')\n\n        for twin_file_path in twin_file_paths:\n            if twin_file_path != \"\":\n                command_parameters.append('--nodes')\n                command_parameters.append(twin_file_path)\n\n        for relationship_file_path in relationship_file_paths:\n            if relationship_file_path != \"\":\n                command_parameters.append('--relations')\n                command_parameters.append(relationship_file_path)\n\n        command_parameters.append(self.graph.name)\n        logger.debug(command_parameters)\n\n        if self.password is not None:\n            command_parameters.append('--password')\n            command_parameters.append(self.password)\n        # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties\n        try:\n            bulk_insert(command_parameters)\n        except SystemExit as e:\n            print(e)\n</code></pre>"},{"location":"references/Modelops/core/io/model_importer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_importer.ModelImporter.bulk_import","title":"<code>bulk_import(twin_file_paths=[], relationship_file_paths=[], enforce_schema=False)</code>","text":"<p>Import all csv data :param twin_file_paths: the file paths of all twin csv files :param relationship_file_paths: the file paths of all relationship csv files :param enforce_schema: True if the schema is defined within headers (default False) <code>Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;</code>_ :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_importer.py</code> <pre><code>@GraphHandler.handle_graph_replace\ndef bulk_import(self, twin_file_paths: list = [], relationship_file_paths: list = [], enforce_schema: bool = False):\n    \"\"\"\n    Import all csv data\n    :param twin_file_paths: the file paths of all twin csv files\n    :param relationship_file_paths: the file paths of all relationship csv files\n    :param enforce_schema: True if the schema is defined within headers (default False)\n    `Enforce_schema documentation &lt;https://github.com/RedisGraph/redisgraph-bulk-loader#input-schemas&gt;`_\n    :return: Csv files containing all twin instances exported into {export_dir} folder named by twin type\n    \"\"\"\n    command_parameters = ['--host', self.host, '--port', self.port]\n\n    if enforce_schema:\n        command_parameters.append('--enforce-schema')\n\n    for twin_file_path in twin_file_paths:\n        if twin_file_path != \"\":\n            command_parameters.append('--nodes')\n            command_parameters.append(twin_file_path)\n\n    for relationship_file_path in relationship_file_paths:\n        if relationship_file_path != \"\":\n            command_parameters.append('--relations')\n            command_parameters.append(relationship_file_path)\n\n    command_parameters.append(self.graph.name)\n    logger.debug(command_parameters)\n\n    if self.password is not None:\n        command_parameters.append('--password')\n        command_parameters.append(self.password)\n    # TODO: Think about use '--index Label:Property' command parameters to create indexes on default id properties\n    try:\n        bulk_insert(command_parameters)\n    except SystemExit as e:\n        print(e)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_reader","text":""},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader","title":"<code>ModelReader</code>","text":"<p>               Bases: <code>GraphHandler</code></p> <p>Model Reader for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>class ModelReader(GraphHandler):\n    \"\"\"\n    Model Reader for cached data\n    \"\"\"\n\n    def get_twin_types(self) -&gt; list:\n        \"\"\"\n        Get twin types\n        :return: twin types list\n        \"\"\"\n        return [item for sublist in self.graph.labels() for item in sublist]\n\n    def get_twins_by_type(self, twin_type: str, limit: int = 0) -&gt; QueryResult:\n        \"\"\"\n        Get twins by type\n        :param twin_type: the twin type requested\n        :param limit: the limit number of twin retrieved\n        :return: the twin list corresponding to twin type parameter\n        \"\"\"\n        twin_query = f'MATCH (node:{twin_type}) RETURN node'\n        if limit != 0:\n            twin_query = f'{twin_query} LIMIT {str(limit)}'\n        logger.debug(f\"Query : {twin_query}\")\n        return self.graph.query(twin_query, read_only=True)\n\n    def get_twin_properties_by_type(self, twin_type: str) -&gt; list:\n        \"\"\"\n        Get twin properties regarding a twin_type\n        Note: this will work if all twin (with the same type) have same properties set\n        :param twin_type: the twin type\n        :return: the properties list\n        \"\"\"\n        result = []\n        twin_result = self.get_twins_by_type(twin_type, 1)\n        result_set = twin_result.result_set\n        if result_set and result_set[0]:\n            for key, val in result_set[0][0].properties.items():\n                if str(key) != ModelUtil.dt_id_key:\n                    result.append(str(key))\n                else:\n                    result.append(ModelUtil.id_key)\n        return result\n\n    def get_relationship_types(self) -&gt; list:\n        \"\"\"\n        Get relationship types\n        :return: relationship types list\n        \"\"\"\n        return [item for sublist in self.graph.relationship_types() for item in sublist]\n\n    def get_relationships_by_type(self, relationship_type: str, limit: int = 0) -&gt; QueryResult:\n        \"\"\"\n        Get relationships by type\n        :param relationship_type: the relationship type requested\n        :param limit: the limit number of twin retrieved\n        :return: the relationship list corresponding to relationship type parameter\n        \"\"\"\n        rel_query = f'MATCH (n)-[relation:{relationship_type}]-&gt;(m) RETURN n.{ModelUtil.dt_id_key} as {ModelUtil.source_key}, ' \\\n                    f'm.{ModelUtil.dt_id_key} as {ModelUtil.target_key}, relation'\n        if limit != 0:\n            rel_query = f'{rel_query} LIMIT {str(limit)}'\n        logger.debug(f\"Query : {rel_query}\")\n        return self.graph.query(rel_query, read_only=True)\n\n    def get_relationship_properties_by_type(self, relationship_type: str) -&gt; list:\n        \"\"\"\n        Get relationship properties regarding a relationship_type\n        Note: this will work if all relationship (with the same type) have same properties set\n        :param relationship_type: the relationship type\n        :return: the properties list\n        \"\"\"\n        result = [ModelUtil.source_key, ModelUtil.target_key]\n        relationship_result = self.get_relationships_by_type(relationship_type, 1)\n        result_set = relationship_result.result_set\n        if result_set and result_set[0]:\n            # relationship\n            for key, val in result_set[0][2].properties.items():\n                if not str(key) in result:\n                    if str(key) == ModelUtil.dt_id_key:\n                        result.append(ModelUtil.id_key)\n                    elif str(key) != ModelUtil.src_key and str(key) != ModelUtil.dest_key:\n                        result.append(str(key))\n        return result\n\n    def query(self, query: str, params: dict = None, timeout: int = None, read_only: bool = False) -&gt; QueryResult:\n        \"\"\"\n        Run specified query\n        :param query: the query to run\n        :param params: the parameters for the query if any\n        :param timeout: a specific timeout\n        :param read_only: executes a readonly query if set to True\n        :return: the QueryResult corresponding to specified query\n        \"\"\"\n        logger.debug(f\"Query : {query} with params : {params}\")\n        return self.graph.query(q=query, params=params, timeout=timeout, read_only=read_only)\n\n    def exists(self, key) -&gt; bool:\n        \"\"\"\n        Check if a key exists in Redis\n        :param key: the key\n        :return: True if exists else False\n        \"\"\"\n        return False if self.r.exists(key) == 0 else True\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.exists","title":"<code>exists(key)</code>","text":"<p>Check if a key exists in Redis :param key: the key :return: True if exists else False</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def exists(self, key) -&gt; bool:\n    \"\"\"\n    Check if a key exists in Redis\n    :param key: the key\n    :return: True if exists else False\n    \"\"\"\n    return False if self.r.exists(key) == 0 else True\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_properties_by_type","title":"<code>get_relationship_properties_by_type(relationship_type)</code>","text":"<p>Get relationship properties regarding a relationship_type Note: this will work if all relationship (with the same type) have same properties set :param relationship_type: the relationship type :return: the properties list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationship_properties_by_type(self, relationship_type: str) -&gt; list:\n    \"\"\"\n    Get relationship properties regarding a relationship_type\n    Note: this will work if all relationship (with the same type) have same properties set\n    :param relationship_type: the relationship type\n    :return: the properties list\n    \"\"\"\n    result = [ModelUtil.source_key, ModelUtil.target_key]\n    relationship_result = self.get_relationships_by_type(relationship_type, 1)\n    result_set = relationship_result.result_set\n    if result_set and result_set[0]:\n        # relationship\n        for key, val in result_set[0][2].properties.items():\n            if not str(key) in result:\n                if str(key) == ModelUtil.dt_id_key:\n                    result.append(ModelUtil.id_key)\n                elif str(key) != ModelUtil.src_key and str(key) != ModelUtil.dest_key:\n                    result.append(str(key))\n    return result\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationship_types","title":"<code>get_relationship_types()</code>","text":"<p>Get relationship types :return: relationship types list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationship_types(self) -&gt; list:\n    \"\"\"\n    Get relationship types\n    :return: relationship types list\n    \"\"\"\n    return [item for sublist in self.graph.relationship_types() for item in sublist]\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_relationships_by_type","title":"<code>get_relationships_by_type(relationship_type, limit=0)</code>","text":"<p>Get relationships by type :param relationship_type: the relationship type requested :param limit: the limit number of twin retrieved :return: the relationship list corresponding to relationship type parameter</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_relationships_by_type(self, relationship_type: str, limit: int = 0) -&gt; QueryResult:\n    \"\"\"\n    Get relationships by type\n    :param relationship_type: the relationship type requested\n    :param limit: the limit number of twin retrieved\n    :return: the relationship list corresponding to relationship type parameter\n    \"\"\"\n    rel_query = f'MATCH (n)-[relation:{relationship_type}]-&gt;(m) RETURN n.{ModelUtil.dt_id_key} as {ModelUtil.source_key}, ' \\\n                f'm.{ModelUtil.dt_id_key} as {ModelUtil.target_key}, relation'\n    if limit != 0:\n        rel_query = f'{rel_query} LIMIT {str(limit)}'\n    logger.debug(f\"Query : {rel_query}\")\n    return self.graph.query(rel_query, read_only=True)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_properties_by_type","title":"<code>get_twin_properties_by_type(twin_type)</code>","text":"<p>Get twin properties regarding a twin_type Note: this will work if all twin (with the same type) have same properties set :param twin_type: the twin type :return: the properties list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twin_properties_by_type(self, twin_type: str) -&gt; list:\n    \"\"\"\n    Get twin properties regarding a twin_type\n    Note: this will work if all twin (with the same type) have same properties set\n    :param twin_type: the twin type\n    :return: the properties list\n    \"\"\"\n    result = []\n    twin_result = self.get_twins_by_type(twin_type, 1)\n    result_set = twin_result.result_set\n    if result_set and result_set[0]:\n        for key, val in result_set[0][0].properties.items():\n            if str(key) != ModelUtil.dt_id_key:\n                result.append(str(key))\n            else:\n                result.append(ModelUtil.id_key)\n    return result\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twin_types","title":"<code>get_twin_types()</code>","text":"<p>Get twin types :return: twin types list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twin_types(self) -&gt; list:\n    \"\"\"\n    Get twin types\n    :return: twin types list\n    \"\"\"\n    return [item for sublist in self.graph.labels() for item in sublist]\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.get_twins_by_type","title":"<code>get_twins_by_type(twin_type, limit=0)</code>","text":"<p>Get twins by type :param twin_type: the twin type requested :param limit: the limit number of twin retrieved :return: the twin list corresponding to twin type parameter</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def get_twins_by_type(self, twin_type: str, limit: int = 0) -&gt; QueryResult:\n    \"\"\"\n    Get twins by type\n    :param twin_type: the twin type requested\n    :param limit: the limit number of twin retrieved\n    :return: the twin list corresponding to twin type parameter\n    \"\"\"\n    twin_query = f'MATCH (node:{twin_type}) RETURN node'\n    if limit != 0:\n        twin_query = f'{twin_query} LIMIT {str(limit)}'\n    logger.debug(f\"Query : {twin_query}\")\n    return self.graph.query(twin_query, read_only=True)\n</code></pre>"},{"location":"references/Modelops/core/io/model_reader/#CosmoTech_Acceleration_Library.Modelops.core.io.model_reader.ModelReader.query","title":"<code>query(query, params=None, timeout=None, read_only=False)</code>","text":"<p>Run specified query :param query: the query to run :param params: the parameters for the query if any :param timeout: a specific timeout :param read_only: executes a readonly query if set to True :return: the QueryResult corresponding to specified query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_reader.py</code> <pre><code>def query(self, query: str, params: dict = None, timeout: int = None, read_only: bool = False) -&gt; QueryResult:\n    \"\"\"\n    Run specified query\n    :param query: the query to run\n    :param params: the parameters for the query if any\n    :param timeout: a specific timeout\n    :param read_only: executes a readonly query if set to True\n    :return: the QueryResult corresponding to specified query\n    \"\"\"\n    logger.debug(f\"Query : {query} with params : {params}\")\n    return self.graph.query(q=query, params=params, timeout=timeout, read_only=read_only)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/","title":"CosmoTech_Acceleration_Library.Modelops.core.io.model_writer","text":""},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter","title":"<code>ModelWriter</code>","text":"<p>               Bases: <code>GraphHandler</code></p> <p>Model Writer for cached data</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>class ModelWriter(GraphHandler):\n    \"\"\"\n    Model Writer for cached data\n    \"\"\"\n\n    def create_twin(self, twin_type: str, properties: dict):\n        \"\"\"\n        Create a twin\n        :param twin_type: the twin type\n        :param properties: the twin properties\n        \"\"\"\n        create_query = ModelUtil.create_twin_query(twin_type, properties)\n        logger.debug(f\"Query: {create_query}\")\n        self.graph.query(create_query)\n\n    def create_relationship(self, relationship_type: str, properties: dict):\n        \"\"\"\n        Create a relationship\n        :param relationship_type: the relationship type\n        :param properties: the relationship properties\n        \"\"\"\n        create_rel = ModelUtil.create_relationship_query(relationship_type, properties)\n        logger.debug(f\"Query: {create_rel}\")\n        self.graph.query(create_rel)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_relationship","title":"<code>create_relationship(relationship_type, properties)</code>","text":"<p>Create a relationship :param relationship_type: the relationship type :param properties: the relationship properties</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>def create_relationship(self, relationship_type: str, properties: dict):\n    \"\"\"\n    Create a relationship\n    :param relationship_type: the relationship type\n    :param properties: the relationship properties\n    \"\"\"\n    create_rel = ModelUtil.create_relationship_query(relationship_type, properties)\n    logger.debug(f\"Query: {create_rel}\")\n    self.graph.query(create_rel)\n</code></pre>"},{"location":"references/Modelops/core/io/model_writer/#CosmoTech_Acceleration_Library.Modelops.core.io.model_writer.ModelWriter.create_twin","title":"<code>create_twin(twin_type, properties)</code>","text":"<p>Create a twin :param twin_type: the twin type :param properties: the twin properties</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/io/model_writer.py</code> <pre><code>def create_twin(self, twin_type: str, properties: dict):\n    \"\"\"\n    Create a twin\n    :param twin_type: the twin type\n    :param properties: the twin properties\n    \"\"\"\n    create_query = ModelUtil.create_twin_query(twin_type, properties)\n    logger.debug(f\"Query: {create_query}\")\n    self.graph.query(create_query)\n</code></pre>"},{"location":"references/Modelops/core/tests/redis_test/","title":"CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test","text":""},{"location":"references/Modelops/core/tests/redis_test/#CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test","title":"<code>redis_test</code>","text":""},{"location":"references/Modelops/core/tests/redis_test/#CosmoTech_Acceleration_Library.Modelops.core.tests.redis_test.redis_service","title":"<code>redis_service(docker_ip, docker_services)</code>","text":"<p>ensure redis is up and running</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/tests/redis_test.py</code> <pre><code>@pytest.fixture(scope='session')\ndef redis_service(docker_ip, docker_services):\n    \"\"\"ensure redis is up and running\"\"\"\n\n    host = docker_ip\n    port = docker_services.port_for(\"redis\", 6379)\n    redis_client = redis.Redis(host=host, port=port)\n\n    docker_services.wait_until_responsive(timeout=5, pause=0.2, check=redis_client.ping)\n    return {\"host\": host, \"port\": port}\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.model_util","text":""},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil","title":"<code>ModelUtil</code>","text":"<p>Utility class for Redis management</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>class ModelUtil:\n    \"\"\"\n    Utility class for Redis management\n    \"\"\"\n\n    # ADT variables\n    source_key = 'source'\n    target_key = 'target'\n    id_key = 'id'\n\n    # Redis/Csm variables\n    src_key = 'src'\n    dest_key = 'dest'\n    dt_id_key = 'id'\n\n    @staticmethod\n    def dict_to_cypher_parameters(parameters: dict) -&gt; str:\n        \"\"\"\n        Convert a dict to usable Cypher parameters object\n        :param parameters: parameters dict\n        :return: string representing parameters as Cyper Parameters\n        \"\"\"\n\n        cypher_list = []\n        for key, value in parameters.items():\n            formatted_value = stringify_param_value(value)\n            if isinstance(value, str):\n                try:\n                    json.loads(value)\n                    formatted_value = json.dumps(value)\n                except ValueError:\n                    logger.debug(f\"{value} is not a jsonString, use the raw value\")\n            cypher_list.append(f\"{key} : {formatted_value}\")\n        joined_list = ', '.join(cypher_list)\n        return '{' + joined_list + '}'\n\n    @staticmethod\n    def create_index_query(entity_name: str, entity_property_name: str) -&gt; str:\n        \"\"\"\n        Create an index query\n        :param entity_name: the entity name on which you want to define an index\n        :param entity_property_name:  the entity property name on which you want to define an index\n        :return: the create index query\n        \"\"\"\n        return f\"CREATE INDEX ON :{entity_name}({entity_property_name})\"\n\n    @staticmethod\n    def create_twin_query(twin_type: str, properties: dict) -&gt; str:\n        \"\"\"\n        Create a twin query\n        :param twin_type:the future twin name\n        :param properties: the properties of the twin\n        :return: the create twin query\n        \"\"\"\n        if ModelUtil.dt_id_key in properties:\n            cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n            return f\"CREATE (:{twin_type} {cypher_params})\"\n        raise Exception(f\"When you create a twin, you should define at least {ModelUtil.dt_id_key} properties \")\n\n    @staticmethod\n    def create_relationship_query(relationship_type: str, properties: dict) -&gt; str:\n        \"\"\"\n        Create a relationship query\n        :param relationship_type: the future relationship name\n        :param properties: the properties of the relationship (should contain 'src' and 'dest' properties)\n        :return: the create relationship query\n        \"\"\"\n\n        if ModelUtil.src_key in properties and ModelUtil.dest_key in properties:\n            cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n            return f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.src_key)}' \" \\\n                   f\"AND m.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.dest_key)}' \" \\\n                   f\"CREATE (n)-[r:{relationship_type} {cypher_params}]-&gt;(m) RETURN r\"\n        raise Exception(\n            f\"When you create a relationship, you should define at least {ModelUtil.src_key} and {ModelUtil.dest_key} properties \"\n        )\n\n    @staticmethod\n    def dict_to_json(obj: dict) -&gt; str:\n        \"\"\"\n        Transform a dict to a json string\n        :param obj: the dict\n        :return: the json string corresponding\n        \"\"\"\n        return json.dumps(obj, indent=2)\n\n    @staticmethod\n    def result_set_to_json(query_result: QueryResult) -&gt; list:\n        \"\"\"\n        Transform a QueryResult object to a json string list\n        :param query_result: the QueryResult object\n        :return: the json string list\n        \"\"\"\n        flattened_headers = [item for sublist in query_result.header for item in sublist]\n        headers_without_integers = [x for x in flattened_headers if not isinstance(x, int)]\n        result_list = []\n        for result in query_result.result_set:\n            result_dict = {}\n            for i in range(len(headers_without_integers)):\n                obj = result[i]\n                if isinstance(obj, Edge) or isinstance(obj, Node):\n                    result_dict[headers_without_integers[i]] = obj.properties\n                else:\n                    result_dict[headers_without_integers[i]] = obj\n            result_list.append(ModelUtil.dict_to_json(result_dict))\n        return result_list\n\n    @staticmethod\n    def print_query_result(query_result: QueryResult) -&gt; None:\n        \"\"\"\n        Pretty print a QueryResult\n        :param query_result: the QueryResult to print\n        \"\"\"\n        list_to_print = ModelUtil.result_set_to_json(query_result)\n        for result in list_to_print:\n            print(result)\n\n    @staticmethod\n    def convert_datetime_to_str(date: datetime) -&gt; str:\n        \"\"\"\n        Convert a datetime to a str\n        :param date: the datetime\n        :return: the string representing the datetime\n        \"\"\"\n        return date.strftime('%Y/%m/%d - %H:%M:%S')\n\n    @staticmethod\n    def convert_str_to_datetime(date_str: str) -&gt; datetime:\n        \"\"\"\n        Convert a datetime to a str\n        :param date_str: the str representing a date\n        :return: the datetime corresponding to date_str\n        \"\"\"\n        date_time_obj = datetime.strptime(date_str, '%Y/%m/%d - %H:%M:%S')\n        return date_time_obj\n\n    @staticmethod\n    def build_graph_key_pattern(graph_name: str) -&gt; str:\n        return graph_name + \":*\"\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_datetime_to_str","title":"<code>convert_datetime_to_str(date)</code>  <code>staticmethod</code>","text":"<p>Convert a datetime to a str :param date: the datetime :return: the string representing the datetime</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef convert_datetime_to_str(date: datetime) -&gt; str:\n    \"\"\"\n    Convert a datetime to a str\n    :param date: the datetime\n    :return: the string representing the datetime\n    \"\"\"\n    return date.strftime('%Y/%m/%d - %H:%M:%S')\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.convert_str_to_datetime","title":"<code>convert_str_to_datetime(date_str)</code>  <code>staticmethod</code>","text":"<p>Convert a datetime to a str :param date_str: the str representing a date :return: the datetime corresponding to date_str</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef convert_str_to_datetime(date_str: str) -&gt; datetime:\n    \"\"\"\n    Convert a datetime to a str\n    :param date_str: the str representing a date\n    :return: the datetime corresponding to date_str\n    \"\"\"\n    date_time_obj = datetime.strptime(date_str, '%Y/%m/%d - %H:%M:%S')\n    return date_time_obj\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_index_query","title":"<code>create_index_query(entity_name, entity_property_name)</code>  <code>staticmethod</code>","text":"<p>Create an index query :param entity_name: the entity name on which you want to define an index :param entity_property_name:  the entity property name on which you want to define an index :return: the create index query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_index_query(entity_name: str, entity_property_name: str) -&gt; str:\n    \"\"\"\n    Create an index query\n    :param entity_name: the entity name on which you want to define an index\n    :param entity_property_name:  the entity property name on which you want to define an index\n    :return: the create index query\n    \"\"\"\n    return f\"CREATE INDEX ON :{entity_name}({entity_property_name})\"\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_relationship_query","title":"<code>create_relationship_query(relationship_type, properties)</code>  <code>staticmethod</code>","text":"<p>Create a relationship query :param relationship_type: the future relationship name :param properties: the properties of the relationship (should contain 'src' and 'dest' properties) :return: the create relationship query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_relationship_query(relationship_type: str, properties: dict) -&gt; str:\n    \"\"\"\n    Create a relationship query\n    :param relationship_type: the future relationship name\n    :param properties: the properties of the relationship (should contain 'src' and 'dest' properties)\n    :return: the create relationship query\n    \"\"\"\n\n    if ModelUtil.src_key in properties and ModelUtil.dest_key in properties:\n        cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n        return f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.src_key)}' \" \\\n               f\"AND m.{ModelUtil.dt_id_key} = '{properties.get(ModelUtil.dest_key)}' \" \\\n               f\"CREATE (n)-[r:{relationship_type} {cypher_params}]-&gt;(m) RETURN r\"\n    raise Exception(\n        f\"When you create a relationship, you should define at least {ModelUtil.src_key} and {ModelUtil.dest_key} properties \"\n    )\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.create_twin_query","title":"<code>create_twin_query(twin_type, properties)</code>  <code>staticmethod</code>","text":"<p>Create a twin query :param twin_type:the future twin name :param properties: the properties of the twin :return: the create twin query</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef create_twin_query(twin_type: str, properties: dict) -&gt; str:\n    \"\"\"\n    Create a twin query\n    :param twin_type:the future twin name\n    :param properties: the properties of the twin\n    :return: the create twin query\n    \"\"\"\n    if ModelUtil.dt_id_key in properties:\n        cypher_params = ModelUtil.dict_to_cypher_parameters(properties)\n        return f\"CREATE (:{twin_type} {cypher_params})\"\n    raise Exception(f\"When you create a twin, you should define at least {ModelUtil.dt_id_key} properties \")\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_cypher_parameters","title":"<code>dict_to_cypher_parameters(parameters)</code>  <code>staticmethod</code>","text":"<p>Convert a dict to usable Cypher parameters object :param parameters: parameters dict :return: string representing parameters as Cyper Parameters</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef dict_to_cypher_parameters(parameters: dict) -&gt; str:\n    \"\"\"\n    Convert a dict to usable Cypher parameters object\n    :param parameters: parameters dict\n    :return: string representing parameters as Cyper Parameters\n    \"\"\"\n\n    cypher_list = []\n    for key, value in parameters.items():\n        formatted_value = stringify_param_value(value)\n        if isinstance(value, str):\n            try:\n                json.loads(value)\n                formatted_value = json.dumps(value)\n            except ValueError:\n                logger.debug(f\"{value} is not a jsonString, use the raw value\")\n        cypher_list.append(f\"{key} : {formatted_value}\")\n    joined_list = ', '.join(cypher_list)\n    return '{' + joined_list + '}'\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.dict_to_json","title":"<code>dict_to_json(obj)</code>  <code>staticmethod</code>","text":"<p>Transform a dict to a json string :param obj: the dict :return: the json string corresponding</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef dict_to_json(obj: dict) -&gt; str:\n    \"\"\"\n    Transform a dict to a json string\n    :param obj: the dict\n    :return: the json string corresponding\n    \"\"\"\n    return json.dumps(obj, indent=2)\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.print_query_result","title":"<code>print_query_result(query_result)</code>  <code>staticmethod</code>","text":"<p>Pretty print a QueryResult :param query_result: the QueryResult to print</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef print_query_result(query_result: QueryResult) -&gt; None:\n    \"\"\"\n    Pretty print a QueryResult\n    :param query_result: the QueryResult to print\n    \"\"\"\n    list_to_print = ModelUtil.result_set_to_json(query_result)\n    for result in list_to_print:\n        print(result)\n</code></pre>"},{"location":"references/Modelops/core/utils/model_util/#CosmoTech_Acceleration_Library.Modelops.core.utils.model_util.ModelUtil.result_set_to_json","title":"<code>result_set_to_json(query_result)</code>  <code>staticmethod</code>","text":"<p>Transform a QueryResult object to a json string list :param query_result: the QueryResult object :return: the json string list</p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/model_util.py</code> <pre><code>@staticmethod\ndef result_set_to_json(query_result: QueryResult) -&gt; list:\n    \"\"\"\n    Transform a QueryResult object to a json string list\n    :param query_result: the QueryResult object\n    :return: the json string list\n    \"\"\"\n    flattened_headers = [item for sublist in query_result.header for item in sublist]\n    headers_without_integers = [x for x in flattened_headers if not isinstance(x, int)]\n    result_list = []\n    for result in query_result.result_set:\n        result_dict = {}\n        for i in range(len(headers_without_integers)):\n            obj = result[i]\n            if isinstance(obj, Edge) or isinstance(obj, Node):\n                result_dict[headers_without_integers[i]] = obj.properties\n            else:\n                result_dict[headers_without_integers[i]] = obj\n        result_list.append(ModelUtil.dict_to_json(result_dict))\n    return result_list\n</code></pre>"},{"location":"references/Modelops/core/utils/tests/model_util_test/","title":"CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test","text":""},{"location":"references/Modelops/core/utils/tests/model_util_test/#CosmoTech_Acceleration_Library.Modelops.core.utils.tests.model_util_test.TestModelUtil","title":"<code>TestModelUtil</code>","text":"<p>               Bases: <code>TestCase</code></p> Source code in <code>CosmoTech_Acceleration_Library/Modelops/core/utils/tests/model_util_test.py</code> <pre><code>class TestModelUtil(unittest.TestCase):\n    # Global variables\n    simple_parameters = {\n        \"id\": \"Twin1\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": {\n            \"property1\": \"toto\",\n            \"property2\": \"tata\",\n        },\n        \"with_quotes\": \"'9999'\",\n        \"with_dbl_quotes\": '\"1234\"',\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    relationship_simple_parameters = {\n        \"src\": \"Node1\",\n        \"dest\": \"Node2\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": {\n            \"property1\": \"toto\",\n            \"property2\": \"tata\",\n        },\n        \"with_quotes\": \"'12345'\",\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    dict_with_simple_json_string = {\n        \"src\": \"Node1\",\n        \"dest\": \"Node2\",\n        \"brand\": \"Ford\",\n        \"electric\": False,\n        \"year\": 1964,\n        \"dict_param\": \"{\\\"property1\\\": \\\"toto\\\", \\\"property2\\\": \\\"tata\\\"}\",\n        \"with_quotes\": \"'12345'\",\n        \"colors\": [\"red\", \"white\", \"blue\"]\n    }\n\n    expected_simple_parameters = '{id : \"Twin1\", ' \\\n                                 'brand : \"Ford\", ' \\\n                                 'electric : False, ' \\\n                                 'year : 1964, ' \\\n                                 'dict_param : {property1:\\\"toto\\\",property2:\\\"tata\\\"}, ' \\\n                                 'with_quotes : \"\\'9999\\'\", ' \\\n                                 'with_dbl_quotes : \"\\\\\"1234\\\\\"\", ' \\\n                                 'colors : [\"red\",\"white\",\"blue\"]}'\n\n    expected_relationship_simple_parameters = '{src : \"Node1\", ' \\\n                                              'dest : \"Node2\", ' \\\n                                              'brand : \"Ford\", ' \\\n                                              'electric : False, ' \\\n                                              'year : 1964, ' \\\n                                              'dict_param : {property1:\\\"toto\\\",property2:\\\"tata\\\"}, ' \\\n                                              'with_quotes : \"\\'12345\\'\", ' \\\n                                              'colors : [\"red\",\"white\",\"blue\"]}'\n\n    def setUp(self):\n        self.model_util = ModelUtil()\n\n    def test_dict_to_cypher_parameters_with_simple_parameters(self):\n        self.assertEqual(self.expected_simple_parameters,\n                         self.model_util.dict_to_cypher_parameters(self.simple_parameters))\n\n    def test_create_index_query(self):\n        expected_result = \"CREATE INDEX ON :Entity_Test(property_name_test)\"\n        self.assertEqual(expected_result, self.model_util.create_index_query(\"Entity_Test\", \"property_name_test\"))\n\n    def test_create_twin_query(self):\n        expected_result = f\"CREATE (:Entity_Test {self.expected_simple_parameters})\"\n        self.assertEqual(expected_result, self.model_util.create_twin_query(\"Entity_Test\", self.simple_parameters))\n\n    def test_create_twin_query_Exception(self):\n        twin_name = 'Twin_name'\n        self.assertRaises(Exception, self.model_util.create_twin_query, twin_name, self.expected_simple_parameters)\n\n    def test_create_relationship_query(self):\n        source_id = 'Node1'\n        destination_id = 'Node2'\n        relation_name = 'Relation_Name'\n        expected_result = f\"MATCH (n), (m) WHERE n.{ModelUtil.dt_id_key} = '{source_id}' AND m.{ModelUtil.dt_id_key} = '{destination_id}' CREATE (n)-[r:{relation_name} {self.expected_relationship_simple_parameters}]-&gt;(m) RETURN r\"\n        self.assertEqual(expected_result,\n                         self.model_util.create_relationship_query(relation_name, self.relationship_simple_parameters))\n\n    def test_create_relationship_query_Exception(self):\n        relation_name = 'Relation_Name'\n        self.assertRaises(Exception, self.model_util.create_relationship_query, relation_name,\n                          self.expected_simple_parameters)\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>A list of tutorials for concepts added to CoAL</p> <p> csm-data</p> <p>Make full use of <code>csm-data</code> commands to connect to services during your orchestration runs</p> <p> csm-data</p> <p> Data store</p> <p>The datastore is your friend to keep data between orchestration steps. It comes with multiple ways to interact with it.</p> <p> Datastore</p>"},{"location":"tutorials/csm-data/","title":"CSM-DATA","text":"<p><code>csm-data</code> is a CLI (Command Line Interface) bundled inside CoAL.</p> <p>It's multiple commands are there to help you go faster in most of your interaction with services used inside a CosmoTech platform.</p> <p>You can get the full help of the commands at that location : csm-data</p>"},{"location":"tutorials/csm-data/#why-should-i-use-csm-data","title":"Why should I use <code>csm-data</code> ?","text":"<p>Use of <code>csm-data</code> is recommended to have fast and tested interactions with the multiple services provided during a CosmoTech simulation.</p> <p>You can make use of the commands bundled inside the CLI to reduce your own development time by not having to recreate the wheel everytime you need to send X or Y data to a service.</p> <p>You are free to look at the code of the commands and use it as a basis for your own specific needs if the commands do not exactly work as you would need (for example some commands only scan single level folders for files while you would want a full recursive look-up)</p>"},{"location":"tutorials/datastore/","title":"Datastore","text":""},{"location":"tutorials/datastore/#what-is-the-datastore","title":"What is the datastore ?","text":"<p>The datastore is an interface to a SQLite database you can use to store and interact with.</p> <p>The idea behind it is to give you a robust system in which you can send data, query data or even create complex interactions.</p> <p>Instead of putting all your data in csvs or json or other heavy file formats you can store them in the datastore and easily get them back later.</p>"},{"location":"tutorials/datastore/#basic-example","title":"Basic example","text":"Basic use of the datastore<pre><code>from cosmotech.coal.store.store import Store\nfrom cosmotech.coal.store.native_python import store_pylist\n\n# We initialize and reset the data store\nmy_datastore = Store(reset=True)\n\n# We create a simple list of dict data\nmy_data = [{\n    \"foo\": \"bar\"\n},{\n    \"foo\": \"barbar\"\n},{\n    \"foo\": \"world\"\n},{\n    \"foo\": \"bar\"\n}]\n\n# We use a bundled method to send the py_list to the store\nstore_pylist(\"my_data\", my_data)\n\n# We can make a sql query over our data\n# Store.execute_query returns a pyarrow.Table object so we can make use of Table.to_pylist to get an equivalent format\nresults = my_datastore.execute_query(\"SELECT foo, count(*) as line_count FROM my_data GROUP BY foo\").to_pylist()\n\n# We can print our results now\nprint(results)\n# &gt; [{'foo': 'bar', 'line_count': 2}, {'foo': 'barbar', 'line_count': 1}, {'foo': 'world', 'line_count': 1}]\n</code></pre>"}]}